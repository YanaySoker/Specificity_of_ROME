{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YanaySoker/Specificity_of_ROME/blob/main/main_experimant.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tHEAPf9DCcwE"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kmeng01/rome/blob/main/notebooks/causal_trace.ipynb\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" align=\"left\"/></a>&nbsp;or in a local notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Ne1lIIKCcwG"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "!(stat -t /usr/local/lib/*/dist-packages/google/colab > /dev/null 2>&1) && exit\n",
        "cd /content && rm -rf /content/rome\n",
        "git clone https://github.com/kmeng01/rome rome > install.log 2>&1\n",
        "pip install -r /content/rome/scripts/colab_reqs/rome.txt >> install.log 2>&1\n",
        "pip install --upgrade google-cloud-storage >> install.log 2>&1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tXNPq7yCuhCb",
        "outputId": "41c5d76a-a7be-4521-f75c-b63c0836aae8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/rome\n"
          ]
        }
      ],
      "source": [
        "%cd rome"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AE1l9gI6vjWE",
        "outputId": "42902b6c-b9cc-4442-e68d-17f33d9bb8b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting ./experiments/py/demo.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile ./experiments/py/demo.py\n",
        "# New demo.py\n",
        "import os\n",
        "from pathlib import Path\n",
        "from typing import Dict, List, Tuple\n",
        "\n",
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "from baselines.ft import FTHyperParams, apply_ft_to_model\n",
        "from rome import ROMEHyperParams, apply_rome_to_model\n",
        "from util import nethook\n",
        "from util.generate import generate_fast\n",
        "from util.globals import *\n",
        "\n",
        "LAYER_IDX = [17]\n",
        "\n",
        "def demo_model_editing(\n",
        "    model: AutoModelForCausalLM,\n",
        "    tok: AutoTokenizer,\n",
        "    requests: List[Dict],\n",
        "    generation_prompts: List[str],\n",
        "    alg_name: str = \"ROME\",\n",
        ") -> Tuple[AutoModelForCausalLM, Dict[str, torch.Tensor]]:\n",
        "    \"\"\"\n",
        "    Applies the selected model editing algorithm. Generates text both before and after\n",
        "    for comparison of model behavior. Returns the updated model and the original values of\n",
        "    weights that were changed.\n",
        "    \"\"\"\n",
        "    print(requests, \"\\n\")\n",
        "    nethook.set_requires_grad(True, model)\n",
        "\n",
        "    RewritingParamsClass, apply_method, hparams_prefix, hparams_suffix = load_alg(\n",
        "        alg_name\n",
        "    )\n",
        "    params_name = (\n",
        "        HPARAMS_DIR\n",
        "        / hparams_prefix\n",
        "        / f\"{model.config._name_or_path.replace('/', '_')}{hparams_suffix}.json\"\n",
        "    )\n",
        "    params_name = \"hparams/ROME/gpt2-xl.json\"\n",
        "    hparams = RewritingParamsClass.from_json(params_name)\n",
        "    hparams.layers=[LEVEL_IDX[0]]   # New\n",
        "    model_new, orig_weights = apply_method(\n",
        "        model, tok, requests, hparams, return_orig_weights=True\n",
        "    )\n",
        "\n",
        "    return model_new, orig_weights\n",
        "\n",
        "def load_alg(alg_name):\n",
        "    \"\"\"\n",
        "    Loads dependencies for the desired algorithm.\n",
        "    Implementation is slightly awkward to prevent unnecessary imports on Colab.\n",
        "\n",
        "    The return value is a tuple of the following:\n",
        "    1. Class for storing hyperparameters\n",
        "    2. Method for applying rewrites\n",
        "    3. Location of parameters\n",
        "    4. Predefined suffix for the param file\n",
        "    \"\"\"\n",
        "    assert alg_name in [\n",
        "        \"FT\",\n",
        "        \"FT-L\",\n",
        "        \"FT-AttnEdit\",\n",
        "        \"KN\",\n",
        "        \"MEND\",\n",
        "        \"MEND-CF\",\n",
        "        \"MEND-zsRE\",\n",
        "        \"KE\",\n",
        "        \"KE-CF\",\n",
        "        \"ROME\",\n",
        "    ]\n",
        "\n",
        "    if alg_name == \"ROME\":\n",
        "        return ROMEHyperParams, apply_rome_to_model, \"ROME\", \"\"\n",
        "    elif \"FT\" in alg_name:\n",
        "        d = {\n",
        "            \"FT\": (FTHyperParams, apply_ft_to_model, \"FT\", \"_unconstr\"),\n",
        "            \"FT-AttnEdit\": (FTHyperParams, apply_ft_to_model, \"FT\", \"_attn\"),\n",
        "            \"FT-L\": (FTHyperParams, apply_ft_to_model, \"FT\", \"_constr\"),\n",
        "        }\n",
        "        return d[alg_name]\n",
        "    else:\n",
        "        from baselines.efk import EFKHyperParams, EfkRewriteExecutor\n",
        "        from baselines.kn import KNHyperParams, apply_kn_to_model\n",
        "        from baselines.mend import MENDHyperParams, MendRewriteExecutor\n",
        "\n",
        "        d = {\n",
        "            \"KN\": (KNHyperParams, apply_kn_to_model, \"KN\", \"\"),\n",
        "            \"MEND\": (MENDHyperParams, MendRewriteExecutor().apply_to_model, \"MEND\", \"\"),\n",
        "            \"KE\": (EFKHyperParams, EfkRewriteExecutor().apply_to_model, \"KE\", \"\"),\n",
        "            \"MEND-CF\": (\n",
        "                MENDHyperParams,\n",
        "                MendRewriteExecutor().apply_to_model,\n",
        "                \"MEND\",\n",
        "                \"_CF\",\n",
        "            ),\n",
        "            \"MEND-zsRE\": (\n",
        "                MENDHyperParams,\n",
        "                MendRewriteExecutor().apply_to_model,\n",
        "                \"MEND\",\n",
        "                \"_zsRE\",\n",
        "            ),\n",
        "            \"KE-CF\": (\n",
        "                EFKHyperParams,\n",
        "                EfkRewriteExecutor().apply_to_model,\n",
        "                \"MEND\",\n",
        "                \"_CF\",\n",
        "            ),\n",
        "        }\n",
        "        return d[alg_name]\n",
        "\n",
        "def print_loud(x, pad=3):\n",
        "    \"\"\"\n",
        "    Prints a string with # box for emphasis.\n",
        "\n",
        "    Example:\n",
        "    ############################\n",
        "    #                          #\n",
        "    #  Applying ROME to model  #\n",
        "    #                          #\n",
        "    ############################\n",
        "    \"\"\"\n",
        "\n",
        "    n = len(x)\n",
        "    print()\n",
        "    print(\"\".join([\"#\" for _ in range(n + 2 * pad)]))\n",
        "    print(\"#\" + \"\".join([\" \" for _ in range(n + 2 * (pad - 1))]) + \"#\")\n",
        "    print(\n",
        "        \"#\"\n",
        "        + \"\".join([\" \" for _ in range(pad - 1)])\n",
        "        + x\n",
        "        + \"\".join([\" \" for _ in range(pad - 1)])\n",
        "        + \"#\"\n",
        "    )\n",
        "    print(\"#\" + \"\".join([\" \" for _ in range(n + 2 * (pad - 1))]) + \"#\")\n",
        "    print(\"\".join([\"#\" for _ in range(n + 2 * pad)]))\n",
        "\n",
        "class StopExecution(Exception):\n",
        "    def _render_traceback_(self):\n",
        "        pass\n",
        "\n",
        "def stop_execution():\n",
        "    raise StopExecution\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mpCM3tVhwA0E",
        "outputId": "e0beaf6d-ad2c-45bb-fef2-716693684f48"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting ./rome/rome_main.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile ./rome/rome_main.py\n",
        "# New rome_main.py\n",
        "from copy import deepcopy\n",
        "from typing import Dict, List, Tuple\n",
        "\n",
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "from util import nethook\n",
        "from util.generate import generate_fast\n",
        "\n",
        "from .compute_u import compute_u\n",
        "from .compute_v import compute_v\n",
        "from .rome_hparams import ROMEHyperParams\n",
        "\n",
        "CONTEXT_TEMPLATES_CACHE = None\n",
        "\n",
        "def apply_rome_to_model(\n",
        "    model: AutoModelForCausalLM,\n",
        "    tok: AutoTokenizer,\n",
        "    requests: List[Dict],\n",
        "    hparams: ROMEHyperParams,\n",
        "    copy=False,\n",
        "    return_orig_weights=False,\n",
        ") -> Tuple[AutoModelForCausalLM, List[str]]:\n",
        "    \"\"\"\n",
        "    Returns a model with the desired changes.\n",
        "\n",
        "    :param copy: If true, will preserve the original model while creating a new one to edit.\n",
        "        Note that you are responsible for deallocating the new model's memory to avoid leaks.\n",
        "\n",
        "    :return: (1) the updated model, (2) an original copy of the weights that changed\n",
        "    \"\"\"\n",
        "\n",
        "    if copy:\n",
        "        model = deepcopy(model)\n",
        "\n",
        "    weights_copy = {}\n",
        "\n",
        "    for i, request in enumerate(requests):\n",
        "        deltas = execute_rome(model, tok, request, hparams)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for w_name, (delta_u, delta_v) in deltas.items():\n",
        "                upd_matrix = delta_u.unsqueeze(1) @ delta_v.unsqueeze(0)\n",
        "                w = nethook.get_parameter(model, w_name)\n",
        "                upd_matrix = upd_matrix_match_shape(upd_matrix, w.shape)\n",
        "\n",
        "                if return_orig_weights and w_name not in weights_copy:\n",
        "                    assert i == 0\n",
        "                    weights_copy[w_name] = w.detach().clone()\n",
        "\n",
        "                w[...] += upd_matrix\n",
        "\n",
        "    return model, weights_copy\n",
        "\n",
        "def execute_rome(\n",
        "    model: AutoModelForCausalLM,\n",
        "    tok: AutoTokenizer,\n",
        "    request: Dict,\n",
        "    hparams: ROMEHyperParams,\n",
        ") -> Dict[str, Tuple[torch.Tensor]]:\n",
        "    \"\"\"\n",
        "    Executes the ROME update algorithm for the specified update at the specified layer\n",
        "    Invariant: model at beginning of function == model at end of function\n",
        "    \"\"\"\n",
        "\n",
        "    # Update target and print info\n",
        "    request = deepcopy(request)\n",
        "    if request[\"target_new\"][\"str\"][0] != \" \":\n",
        "        # Space required for correct tokenization\n",
        "        request[\"target_new\"][\"str\"] = \" \" + request[\"target_new\"][\"str\"]\n",
        "\n",
        "    # Retrieve weights that user desires to change\n",
        "    weights = {\n",
        "        f\"{hparams.rewrite_module_tmp.format(layer)}.weight\": nethook.get_parameter(\n",
        "            model, f\"{hparams.rewrite_module_tmp.format(layer)}.weight\"\n",
        "        )\n",
        "        for layer in hparams.layers\n",
        "    }\n",
        "    # Save old weights for future restoration\n",
        "    weights_copy = {k: v.detach().clone() for k, v in weights.items()}\n",
        "\n",
        "    # Update loop: sequentially intervene at each specified layer\n",
        "    deltas = {}\n",
        "    for layer in sorted(hparams.layers):\n",
        "        # Compute rank-1 update matrix\n",
        "        left_vector: torch.Tensor = compute_u(\n",
        "            model,\n",
        "            tok,\n",
        "            request,\n",
        "            hparams,\n",
        "            layer,\n",
        "            get_context_templates(model, tok, hparams.context_template_length_params),\n",
        "        )\n",
        "        right_vector: torch.Tensor = compute_v(\n",
        "            model,\n",
        "            tok,\n",
        "            request,\n",
        "            hparams,\n",
        "            layer,\n",
        "            left_vector,\n",
        "            get_context_templates(model, tok, hparams.context_template_length_params),\n",
        "        )\n",
        "\n",
        "        with torch.no_grad():\n",
        "            # Determine correct transposition of delta matrix\n",
        "            weight_name = f\"{hparams.rewrite_module_tmp.format(layer)}.weight\"\n",
        "            upd_matrix = left_vector.unsqueeze(1) @ right_vector.unsqueeze(0)\n",
        "            upd_matrix = upd_matrix_match_shape(upd_matrix, weights[weight_name].shape)\n",
        "\n",
        "            # Update model weights and record desired changes in `delta` variable\n",
        "            weights[weight_name][...] += upd_matrix\n",
        "            deltas[weight_name] = (\n",
        "                left_vector.detach(),\n",
        "                right_vector.detach(),\n",
        "            )\n",
        "\n",
        "    # Restore state of original model\n",
        "    with torch.no_grad():\n",
        "        for k, v in weights.items():\n",
        "            v[...] = weights_copy[k]\n",
        "\n",
        "    return deltas\n",
        "\n",
        "def upd_matrix_match_shape(matrix: torch.Tensor, shape: torch.Size) -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    GPT-2 and GPT-J have transposed weight representations.\n",
        "    Returns a matrix that matches the desired shape, else raises a ValueError\n",
        "    \"\"\"\n",
        "\n",
        "    if matrix.shape == shape:\n",
        "        return matrix\n",
        "    elif matrix.T.shape == shape:\n",
        "        return matrix.T\n",
        "    else:\n",
        "        raise ValueError(\n",
        "            \"Update matrix computed by ROME does not match original weight shape. \"\n",
        "            \"Check for bugs in the code?\"\n",
        "        )\n",
        "\n",
        "def get_context_templates(model, tok, length_params):\n",
        "    global CONTEXT_TEMPLATES_CACHE\n",
        "\n",
        "    if CONTEXT_TEMPLATES_CACHE is None:\n",
        "        CONTEXT_TEMPLATES_CACHE = [\"{}\"] + [\n",
        "            x + \". {}\"\n",
        "            for x in sum(\n",
        "                (\n",
        "                    generate_fast(\n",
        "                        model,\n",
        "                        tok,\n",
        "                        [\"<|endoftext|>\"],\n",
        "                        n_gen_per_prompt=n_gen,\n",
        "                        max_out_len=length,\n",
        "                    )\n",
        "                    for length, n_gen in length_params\n",
        "                ),\n",
        "                [],\n",
        "            )\n",
        "        ]\n",
        "\n",
        "        print(f\"Cached context templates {CONTEXT_TEMPLATES_CACHE}\")\n",
        "\n",
        "    return CONTEXT_TEMPLATES_CACHE\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from experiments.py.demo import LAYER_IDX"
      ],
      "metadata": {
        "id": "zccfie4VK7Vg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mxRjzaCjCcwH"
      },
      "outputs": [],
      "source": [
        "IS_COLAB = False\n",
        "ALL_DEPS = False\n",
        "try:\n",
        "    import google.colab, torch, os\n",
        "\n",
        "    IS_COLAB = True\n",
        "    os.chdir(\"/content/rome\")\n",
        "    if not torch.cuda.is_available():\n",
        "        raise Exception(\"Change runtime type to include a GPU.\")\n",
        "except ModuleNotFoundError as _:\n",
        "    pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZyjQLxx847Nk"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vXHm-5oJCcwI"
      },
      "source": [
        "## Causal Tracing\n",
        "\n",
        "A demonstration of the double-intervention causal tracing method.\n",
        "\n",
        "The strategy used by causal tracing is to understand important\n",
        "states within a transfomer by doing two interventions simultaneously:\n",
        "\n",
        "1. Corrupt a subset of the input.  In our paper, we corrupt the subject tokens\n",
        "   to frustrate the ability of the transformer to accurately complete factual\n",
        "   prompts about the subject.\n",
        "2. Restore a subset of the internal hidden states.  In our paper, we scan\n",
        "   hidden states at all layers and all tokens, searching for individual states\n",
        "   that carry the necessary information for the transformer to recover its\n",
        "   capability to complete the factual prompt.\n",
        "\n",
        "The traces of decisive states can be shown on a heatmap.  This notebook\n",
        "demonstrates the code for conducting causal traces and creating these heatmaps."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "snQ_Ro4sCcwJ",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "acfDBlVnCcwJ"
      },
      "source": [
        "The `experiments.causal_trace` module contains a set of functions for running causal traces.\n",
        "\n",
        "In this notebook, we reproduce, demonstrate and discuss the interesting functions.\n",
        "\n",
        "We begin by importing several utility functions that deal with tokens and transformer models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bLd3YhHcEIJz"
      },
      "outputs": [],
      "source": [
        "# from rome file\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "from util.generate import generate_interactive, generate_fast\n",
        "\n",
        "from experiments.py.demo import demo_model_editing, stop_execution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CUc6jgJoCcwK",
        "outputId": "a742999f-dcb4-45b8-d0a9-c38b2cbb33d4",
        "scrolled": false
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch.autograd.grad_mode.set_grad_enabled at 0x7ff12b6c3190>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "import os, re, json\n",
        "import torch, numpy\n",
        "from collections import defaultdict\n",
        "from util import nethook\n",
        "from util.globals import DATA_DIR\n",
        "from experiments.causal_trace import (\n",
        "    ModelAndTokenizer,\n",
        "    layername,\n",
        "    guess_subject,\n",
        "    plot_trace_heatmap,\n",
        ")\n",
        "from experiments.causal_trace import (\n",
        "    make_inputs,\n",
        "    decode_tokens,\n",
        "    find_token_range,\n",
        "    # predict_token,\n",
        "    predict_from_input,\n",
        "    collect_embedding_std,\n",
        ")\n",
        "from dsets import KnownsDataset\n",
        "\n",
        "torch.set_grad_enabled(True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GcnrnozPEXUF",
        "outputId": "88c70468-6757-4215-aec7-afe13e3fb806"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7ff1c8137370>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "import random\n",
        "_seed = 1\n",
        "random.seed(_seed)\n",
        "numpy.random.seed(seed=_seed)\n",
        "torch.manual_seed(_seed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xg05HbO1CcwL"
      },
      "source": [
        "Now we load a model and tokenizer, and show that it can complete a couple factual statements correctly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tLbsMGHuCcwL",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 177,
          "referenced_widgets": [
            "b7f2a24de0a54ea18ff66b7cc6ddb160",
            "2109f027a5ad492ba2cb250166294357",
            "1d77b10f2a2b41db8e16b27c0abeb7fc",
            "28a2d28dea8d47b1877905c819ac7e8a",
            "673901a3e74547f8855a35783c6d0ddf",
            "49d3d83a2d1e443b83fa9d7b59c66dd5",
            "afa1b74d81204b2db391c909e1d9937e",
            "fd96b2f4bc0f4393a76a22552714e263",
            "d8c6cd56446a4d70b4c9dc3dcf1a1024",
            "6a482ec5c5d642be9a73f3e4d11655af",
            "f4b3a90d9c5045a7bc233d4eec377c62",
            "445f2c1c83b94c89a2699cc85b432a71",
            "071ec9484e8b4c12a5e8a0f305b817f4",
            "4f9a967df9084eed9a1f1be7795ec56f",
            "f0e8df4b30734610ac7e80d02ada0300",
            "330c808c946e4c27a9111d404ba322bc",
            "45a3012505ab4073b2822c7213965466",
            "b7913f3d59774bf792ef0282598c18e1",
            "588ba947d816455ca311ad17281d6d81",
            "a533bbd56a73426d8540f7ab15ac7e5f",
            "2e679ecd3e924f1f8866f3ac25318e44",
            "6c0ab0bfde514482a5db9e4f0a581668",
            "5c6f0071426941e78fc813caea56e55a",
            "d9bbf0f6d1ff42bfa32b56748f2f377e",
            "411cf607037f4323ab27c9c7d7443ab8",
            "16af56de9ad641689846f3a9ba67e154",
            "d4f0ec0b24ae4c49a193c1267d2a621b",
            "b3896e92759a4ebaba981f0f5014ee0e",
            "3734df75a9244dd4848937032bb2f58f",
            "702345ab2aee49dcbf3ce542ea64f79a",
            "8ec6e975b2184bd1b5c1d744b7828aa2",
            "e2c8bc8c6ef74a359f3ca040397b95b5",
            "4e1ada8ea4c14467a870f2ac46ede6cb",
            "8d66261cbd4c4742a4ef65221b9ddcc3",
            "c5f56f6f8ed741deb4dd7efa5d994563",
            "d41315e0ae4b4484a6e153ec0a06351b",
            "832c0aefb05e4f22a863268ebd9f8b6d",
            "b59e3904ecc348809b2934ca53280dd0",
            "514bb3c2d2b4487289ea949a6ec149bf",
            "11a910a6a47b43d9a30e2cdb6255e2f7",
            "dfeae7365ee649c3945b10cf71aa419a",
            "135a59513a184e22b3230ff4ea87e69a",
            "8454faf815bc417b89c78df89da30370",
            "8c86ce15b271462aa7c5e262c67a35a7",
            "ceb5e7bb3e494969ac9d47d9f8818f66",
            "7206e01c27e7440ea31b3dece8602dbc",
            "ddaee7d4cdc74af5b3352ecf7a8d9107",
            "978884306d6e4173b16e2ae0b2819a77",
            "a65c2ea348704fd2ab35447a2a8b0445",
            "4d6d8839c86549d384fe1533e3a9ee61",
            "a0032de8cd3b4755958999c2e549048e",
            "2b12ca7a2d934787811ac3d5389e513d",
            "cde563814dc34e70918cc4ac3026ee51",
            "02461e71cce6474ea4084f91e8b21fc3",
            "375954b11a3e481aa16d3a243f8afcf8"
          ]
        },
        "outputId": "eddc21e9-492f-4cda-d15b-0fb630843178"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/689 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b7f2a24de0a54ea18ff66b7cc6ddb160"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/0.99M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "445f2c1c83b94c89a2699cc85b432a71"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/446k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5c6f0071426941e78fc813caea56e55a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.29M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8d66261cbd4c4742a4ef65221b9ddcc3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/5.99G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ceb5e7bb3e494969ac9d47d9f8818f66"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "model_name = \"gpt2-xl\"  # or \"EleutherAI/gpt-j-6B\" or \"EleutherAI/gpt-neox-20b\"\n",
        "mt = ModelAndTokenizer(\n",
        "    model_name,\n",
        "    low_cpu_mem_usage=IS_COLAB,\n",
        "    torch_dtype=(torch.float16 if \"20b\" in model_name else None),\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nT_r5LVZCcwN"
      },
      "source": [
        "To obfuscate the subject during Causal Tracing, we use noise sampled from a zero-centered spherical Gaussian, whose stddev is 3 times the $\\sigma$ stddev the model's embeddings. Let's compute that value."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121,
          "referenced_widgets": [
            "c9aa0fc5b5bd4dc18c955248b8cf58e3",
            "e774c3cad264423889ffa67d5a75682d",
            "cb54e02ce29642919cfac38030aaa326",
            "10d3a73fedb74498b2f59a2c6fba3d25",
            "f159463eb7cc43dfb832c3c5033edfdb",
            "b87de7a23f1146bd898b91a8c1fc02e7",
            "1c29ad40dd9b478780c943f295e14111",
            "c8c5575eecf946e282918611d7d1799d",
            "db085af196f94c3badc7e138dc5b9cb2",
            "aa4bc5bae7a948fe87d0f291bb91d715",
            "0e3b956effc14d6f9b4456ffe031bb7e"
          ]
        },
        "id": "zqgjFQrNCcwN",
        "outputId": "b98d1f16-b75a-4f71-b68c-c32442c5453a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data/known_1000.json does not exist. Downloading from https://rome.baulab.info/data/dsets/known_1000.json\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0.00/335k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c9aa0fc5b5bd4dc18c955248b8cf58e3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded dataset with 1209 elements\n",
            "Using noise level 0.13462981581687927\n"
          ]
        }
      ],
      "source": [
        "knowns = KnownsDataset(DATA_DIR)  # Dataset of known facts\n",
        "noise_level = 3 * collect_embedding_std(mt, [k[\"subject\"] for k in knowns])\n",
        "print(f\"Using noise level {noise_level}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yk3J-Ww2CcwO"
      },
      "source": [
        "## Tracing a single location\n",
        "\n",
        "The core intervention in causal tracing is captured in this function:\n",
        "\n",
        "`trace_with_patch` a single causal trace.\n",
        "\n",
        "It enables running a batch of inferences with two interventions.\n",
        "\n",
        "  1. Random noise can be added to corrupt the inputs of some of the batch.\n",
        "  2. At any point, clean non-noised state can be copied over from an\n",
        "     uncorrupted batch member to other batch members.\n",
        "  \n",
        "The convention used by this function is that the zeroth element of the\n",
        "batch is the uncorrupted run, and the subsequent elements of the batch\n",
        "are the corrupted runs.  The argument tokens_to_mix specifies an\n",
        "be corrupted by adding Gaussian noise to the embedding for the batch\n",
        "inputs other than the first element in the batch.  Alternately,\n",
        "subsequent runs could be corrupted by simply providing different\n",
        "input tokens via the passed input batch.\n",
        "\n",
        "To ensure that corrupted behavior is representative, in practice, we\n",
        "will actually run several (ten) corrupted runs in the same batch,\n",
        "each with its own sample of noise.\n",
        "\n",
        "Then when running, a specified set of hidden states will be uncorrupted\n",
        "by restoring their values to the same vector that they had in the\n",
        "zeroth uncorrupted run.  This set of hidden states is listed in\n",
        "states_to_patch, by listing [(token_index, layername), ...] pairs.\n",
        "To trace the effect of just a single state, this can be just a single\n",
        "token/layer pair.  To trace the effect of restoring a set of states,\n",
        "any number of token indices and layers can be listed.\n",
        "\n",
        "Note that this function is also in experiments.causal_trace; the code\n",
        "is shown here to show the logic."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jZMesaAzCcwO"
      },
      "outputs": [],
      "source": [
        "def trace_with_patch(\n",
        "    model,  # The model\n",
        "    inp,  # A set of inputs\n",
        "    states_to_patch,  # A list of (token index, layername) triples to restore\n",
        "    answers_t,  # Answer probabilities to collect\n",
        "    tokens_to_mix,  # Range of tokens to corrupt (begin, end)\n",
        "    noise=0.1,  # Level of noise to add\n",
        "    trace_layers=None,  # List of traced outputs to return\n",
        "):\n",
        "    prng = numpy.random.RandomState()  ### For reproducibility, use pseudorandom noise\n",
        "    patch_spec = defaultdict(list)\n",
        "    for t, l in states_to_patch:\n",
        "        patch_spec[l].append(t)\n",
        "    embed_layername = layername(model, 0, \"embed\")\n",
        "\n",
        "    def untuple(x):\n",
        "        return x[0] if isinstance(x, tuple) else x\n",
        "\n",
        "    # Define the model-patching rule.\n",
        "    def patch_rep(x, layer):\n",
        "        if layer == embed_layername:\n",
        "            # If requested, we corrupt a range of token embeddings on batch items x[1:]\n",
        "            if tokens_to_mix is not None:\n",
        "                b, e = tokens_to_mix\n",
        "                x[1:, b:e] += noise * torch.from_numpy(\n",
        "                    prng.randn(x.shape[0] - 1, e - b, x.shape[2])\n",
        "                ).to(x.device)\n",
        "            return x\n",
        "        if layer not in patch_spec:\n",
        "            return x\n",
        "        # If this layer is in the patch_spec, restore the uncorrupted hidden state\n",
        "        # for selected tokens.\n",
        "        h = untuple(x)\n",
        "        for t in patch_spec[layer]:\n",
        "            h[1:, t] = h[0, t]\n",
        "        return x\n",
        "\n",
        "    # With the patching rules defined, run the patched model in inference.\n",
        "    additional_layers = [] if trace_layers is None else trace_layers\n",
        "    with torch.no_grad(), nethook.TraceDict(\n",
        "        model,\n",
        "        [embed_layername] + list(patch_spec.keys()) + additional_layers,\n",
        "        edit_output=patch_rep,\n",
        "    ) as td:\n",
        "        outputs_exp = model(**inp)\n",
        "\n",
        "    # We report softmax probabilities for the answers_t token predictions of interest.\n",
        "    probs = torch.softmax(outputs_exp.logits[1:, -1, :], dim=1).mean(dim=0)[answers_t]\n",
        "\n",
        "    # If tracing all layers, collect all activations together to return.\n",
        "    if trace_layers is not None:\n",
        "        all_traced = torch.stack(\n",
        "            [untuple(td[layer].output).detach().cpu() for layer in trace_layers], dim=2\n",
        "        )\n",
        "        return probs, all_traced\n",
        "\n",
        "    return probs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oy2paTu5CcwO"
      },
      "source": [
        "## Scanning all locations\n",
        "\n",
        "A causal flow heatmap is created by repeating `trace_with_patch` at every individual hidden state, and measuring the impact of restoring state at each location.\n",
        "\n",
        "The `calculate_hidden_flow` function does this loop.  It handles both the case of restoring a single hidden state, and also restoring MLP or attention states.  Because MLP and attention make small residual contributions, to observe a causal effect in those cases, we need to restore several layers of contributions at once, which is done by `trace_important_window`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L_Y-0Xy7CcwP"
      },
      "outputs": [],
      "source": [
        "def calculate_hidden_flow(\n",
        "    mt, prompt, subject, samples=10, noise=0.1, window=10, kind=None\n",
        "):\n",
        "    \"\"\"\n",
        "    Runs causal tracing over every token/layer combination in the network\n",
        "    and returns a dictionary numerically summarizing the results.\n",
        "    \"\"\"\n",
        "    inp = make_inputs(mt.tokenizer, [prompt] * (samples + 1))\n",
        "    with torch.no_grad():\n",
        "        answer_t, base_score = [d[0] for d in predict_from_input(mt.model, inp)]\n",
        "    [answer] = decode_tokens(mt.tokenizer, [answer_t])\n",
        "    e_range = find_token_range(mt.tokenizer, inp[\"input_ids\"][0], subject)\n",
        "    low_score = trace_with_patch(\n",
        "        mt.model, inp, [], answer_t, e_range, noise=noise\n",
        "    ).item()\n",
        "    if not kind:\n",
        "        differences = trace_important_states(\n",
        "            mt.model, mt.num_layers, inp, e_range, answer_t, noise=noise\n",
        "        )\n",
        "    else:\n",
        "        differences = trace_important_window(\n",
        "            mt.model,\n",
        "            mt.num_layers,\n",
        "            inp,\n",
        "            e_range,\n",
        "            answer_t,\n",
        "            noise=noise,\n",
        "            window=window,\n",
        "            kind=kind,\n",
        "        )\n",
        "    differences = differences.detach().cpu()\n",
        "    return dict(\n",
        "        scores=differences,\n",
        "        low_score=low_score,\n",
        "        high_score=base_score,\n",
        "        input_ids=inp[\"input_ids\"][0],\n",
        "        input_tokens=decode_tokens(mt.tokenizer, inp[\"input_ids\"][0]),\n",
        "        subject_range=e_range,\n",
        "        answer=answer,\n",
        "        window=window,\n",
        "        kind=kind or \"\",\n",
        "    )\n",
        "\n",
        "\n",
        "def trace_important_states(model, num_layers, inp, e_range, answer_t, noise=0.1):\n",
        "    ntoks = inp[\"input_ids\"].shape[1]\n",
        "    table = []\n",
        "    for tnum in range(ntoks):\n",
        "        row = []\n",
        "        for layer in range(0, num_layers):\n",
        "            r = trace_with_patch(\n",
        "                model,\n",
        "                inp,\n",
        "                [(tnum, layername(model, layer))],\n",
        "                answer_t,\n",
        "                tokens_to_mix=e_range,\n",
        "                noise=noise,\n",
        "            )\n",
        "            row.append(r)\n",
        "        table.append(torch.stack(row))\n",
        "    return torch.stack(table)\n",
        "\n",
        "\n",
        "def trace_important_window(\n",
        "    model, num_layers, inp, e_range, answer_t, kind, window=10, noise=0.1\n",
        "):\n",
        "    ntoks = inp[\"input_ids\"].shape[1]\n",
        "    table = []\n",
        "    for tnum in range(ntoks):\n",
        "        row = []\n",
        "        for layer in range(0, num_layers):\n",
        "            layerlist = [\n",
        "                (tnum, layername(model, L, kind))\n",
        "                for L in range(\n",
        "                    max(0, layer - window // 2), min(num_layers, layer - (-window // 2))\n",
        "                )\n",
        "            ]\n",
        "            r = trace_with_patch(\n",
        "                model, inp, layerlist, answer_t, tokens_to_mix=e_range, noise=noise\n",
        "            )\n",
        "            row.append(r)\n",
        "        table.append(torch.stack(row))\n",
        "    return torch.stack(table)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mclYJ7pjCcwP"
      },
      "source": [
        "## Plotting the results\n",
        "\n",
        "The `plot_trace_heatmap` function draws the data on a heatmap.  That function is not shown here; it is in `experiments.causal_trace`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0fuLjkBSFHgq"
      },
      "outputs": [],
      "source": [
        "## bdika\n",
        "# model, tok = (\n",
        "#     AutoModelForCausalLM.from_pretrained(model_name, low_cpu_mem_usage=IS_COLAB).to(\n",
        "#         \"cuda\"\n",
        "#     ),\n",
        "#     AutoTokenizer.from_pretrained(model_name),\n",
        "# )\n",
        "tok = AutoTokenizer.from_pretrained(model_name)\n",
        "tok.pad_token = tok.eos_token"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fvPaqv8TFM3H"
      },
      "outputs": [],
      "source": [
        "# from rome file\n",
        "\n",
        "ALG_NAME = \"ROME\"\n",
        "# Colab-only: install deps for MEND* and KE*\n",
        "if IS_COLAB and not ALL_DEPS and any(x in ALG_NAME for x in [\"MEND\", \"KE\"]):\n",
        "    print(\"Installing additional dependencies required for MEND and KE\")\n",
        "    !pip install -r /content/rome/scripts/colab_reqs/additional.txt >> /content/install.log 2>&1\n",
        "    print(\"Finished installing\")\n",
        "    ALL_DEPS = True\n",
        "\n",
        "import copy\n",
        "model = mt.model\n",
        "mt2 = copy.deepcopy(mt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_f-te1OhFYSh"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c4gGNV_GCcwP"
      },
      "outputs": [],
      "source": [
        "def plot_hidden_flow(\n",
        "    mt,\n",
        "    prompt,\n",
        "    subject=None,\n",
        "    samples=10,\n",
        "    noise=0.1,\n",
        "    window=10,\n",
        "    kind=None,\n",
        "    modelname=None,\n",
        "    savepdf=None,\n",
        "):\n",
        "    if subject is None:\n",
        "        subject = guess_subject(prompt)\n",
        "    result = calculate_hidden_flow(\n",
        "        mt, prompt, subject, samples=samples, noise=noise, window=window, kind=kind\n",
        "    )\n",
        "    print(\"result:\\n\",result)\n",
        "    plot_trace_heatmap(result, savepdf, modelname=modelname)\n",
        "\n",
        "\n",
        "def plot_all_flow(mt, prompt, subject=None, noise=0.1, modelname=None):\n",
        "    for kind in [\"mlp\"]:\n",
        "        plot_hidden_flow(\n",
        "            mt, prompt, subject, modelname=modelname, noise=noise, kind=kind\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ocb0dxNUGbUV"
      },
      "outputs": [],
      "source": [
        "mt2.model = model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **New Code**"
      ],
      "metadata": {
        "id": "HxgRyXKu46BC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def combine_prompt(subject, relation):\n",
        "  if relation is not None:\n",
        "    pref, suff = relation.split(\"{}\")\n",
        "    prompt = f\"{pref}{subject}{suff}\"\n",
        "  else:\n",
        "    prompt = subject\n",
        "  return prompt"
      ],
      "metadata": {
        "id": "vdNl1Y-VJoVY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def is_in_prompt(prompt, sentence):\n",
        "  pref, suff = prompt.split(\"{}\")\n",
        "  return pref==sentence[:len(pref)] and suff==sentence[-len(suff):]\n"
      ],
      "metadata": {
        "id": "7MpkDeo3EzEX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_subject(prompt, relation):\n",
        "  pref, suff = relation.split(\"{}\")\n",
        "  start = len(pref)\n",
        "  end = len(prompt)-len(suff)\n",
        "  subject = prompt[start:end]\n",
        "  return subject\n"
      ],
      "metadata": {
        "id": "EOTJG3YbMxj9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sum_matrices(A, B, alpha):\n",
        "  # adding alpha*B to A:\n",
        "  for i in range(len(A)):\n",
        "    row = A[i]\n",
        "    for j in range(len(row)):\n",
        "      to_add = alpha * B[i][j] \n",
        "      row[j]+=to_add"
      ],
      "metadata": {
        "id": "FP5p13M8m73Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## predict_token\n",
        "def predict_all_from_input(model, inp):\n",
        "    out = model(**inp)[\"logits\"]\n",
        "    probs = torch.softmax(out[:, -1], dim=1)\n",
        "    return probs\n",
        "\n",
        "def predict_token(mt, prompts, return_p=False, return_idx = False):\n",
        "    inp = make_inputs(mt.tokenizer, prompts)\n",
        "    preds, p = predict_from_input(mt.model, inp)\n",
        "    result = [mt.tokenizer.decode(c) for c in preds]\n",
        "    if return_p:\n",
        "        result = (result, p)\n",
        "    elif return_idx:\n",
        "        preds = preds[0]\n",
        "        result = (result, preds)\n",
        "    return result\n",
        "\n",
        "def predict_by_idx(mt, prompt, idx):\n",
        "  # model, str, int --> float\n",
        "  # idx: index of object we want to know its probability\n",
        "  inp = make_inputs(mt.tokenizer, [prompt])\n",
        "  preds = predict_all_from_input(mt.model, inp)\n",
        "  return preds[0][idx].item"
      ],
      "metadata": {
        "id": "baz8lhJAJqGS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def naiv_predict(subject, relation = None, return_idx = False):\n",
        "  prompt = combine_prompt(subject, relation)\n",
        "\n",
        "  t = predict_token(\n",
        "    mt2,\n",
        "    [prompt],\n",
        "    return_p=False,\n",
        "    return_idx = return_idx\n",
        "  )\n",
        "  \n",
        "  if return_idx:\n",
        "    return t[0][0][1:], t[1]\n",
        "  return t[0][1:]\n",
        "  \n",
        "\n",
        "def predict(subject, relation=None, return_idx = False):\n",
        "  if return_idx:\n",
        "    next_tok, idx = naiv_predict(subject, relation, return_idx)\n",
        "  else:\n",
        "    next_tok = naiv_predict(subject, relation, return_idx)\n",
        "\n",
        "  if next_tok not in [\"the\", \"a\"]:\n",
        "    if return_idx:\n",
        "      return next_tok, idx.item\n",
        "    else:\n",
        "      return next_tok\n",
        "\n",
        "  # prompt = prompt + \" \" + next_tok\n",
        "  # if count==8:\n",
        "  #   if return_idx:\n",
        "  #     return f\"[{next_tok}]\", idx.item\n",
        "  #   else:\n",
        "  #     return f\"[{next_tok}]\"\n",
        "  \n",
        "  try:\n",
        "    if return_idx:\n",
        "      next_next, idx = naiv_predict(subject, relation, return_idx)\n",
        "    else:\n",
        "      next_next = naiv_predict(subject, relation, return_idx)\n",
        "  except:\n",
        "    if return_idx:\n",
        "      return f\"[{next_tok}]\", idx.item\n",
        "    else:\n",
        "      return f\"[{next_tok}]\"\n",
        "  \n",
        "  if return_idx:\n",
        "    return f\"[{next_tok}] {next_next}\", idx.item\n",
        "  else:\n",
        "    return f\"[{next_tok}] {next_next}\""
      ],
      "metadata": {
        "id": "4x5VSKpwJy4c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# NEW_REMOTE_ROOT_URL = \"https://rome.baulab.info\"\n",
        "# NEW_REMOTE_URL = f\"{NEW_REMOTE_ROOT_URL}/data/dsets/zsre_mend_eval.json\""
      ],
      "metadata": {
        "id": "fO6CvNt15Nmv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " import urllib, json"
      ],
      "metadata": {
        "id": "ulbIQi7p6wm6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file1_name = \"base_neighbors.py\"   # All dictionaries, without splitting\n",
        "file2_name = \"new_neighborhood.py\"   # Final dataset\n",
        "minimal_neighborhood_len = 5"
      ],
      "metadata": {
        "id": "nmYZUmviUXVj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "counterfacts_url = \"https://rome.baulab.info/data/dsets/counterfact.json\"\n",
        "response = urllib.request.urlopen(counterfacts_url)\n",
        "data = json.loads(response.read())"
      ],
      "metadata": {
        "id": "_RRPUTAL4-fq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def print_dict(dict, file_name=None):\n",
        "  func = print\n",
        "  if file_name:\n",
        "    file = open(file_name, \"w\", encoding=\"utf-8\")\n",
        "    func = file.write\n",
        "\n",
        "  func(\"d = {\\n\")\n",
        "  for key in dict.keys():\n",
        "    func(f\"\\t\\\"{key}\\\": {dict[key]},\\n\")\n",
        "  func(\"}\")\n",
        "\n",
        "  if file_name:\n",
        "    file.close()\n",
        "\n",
        "def print_list(list_input, file_name=None):\n",
        "  func = print\n",
        "  if file_name:\n",
        "    file = open(file_name, \"w\", encoding=\"utf-8\")\n",
        "    func = file.write\n",
        "\n",
        "  func(\"d = [\\n\")\n",
        "  for item in list_input:\n",
        "    func(f\"\\t{item},\\n\")\n",
        "  func(\"]\")\n",
        "\n",
        "  if file_name:\n",
        "    file.close()"
      ],
      "metadata": {
        "id": "jM0X74g3EbT4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def subset(sorted_list):\n",
        "  # count_list.sort()\n",
        "  S = sum(sorted_list)\n",
        "  start, end = 0, 0\n",
        "  while sum(sorted_list[start:end])<S/2:\n",
        "    end+=1\n",
        "  while sum(sorted_list[start:end])>S/2:\n",
        "    start+=1\n",
        "  if start==end:\n",
        "    return range(end-1)\n",
        "  return range(start,end)"
      ],
      "metadata": {
        "id": "60NQE2i-MVdA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Version 1: unfiltered, with known objects"
      ],
      "metadata": {
        "id": "6wIDgCnrX6uO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Collect all the relations as keys: \n",
        "neighborhood_dict = dict()   # neighborhood_dict: dictionary in form {ralation: {object: [subjects]}}:\n",
        "count=0\n",
        "temp_counterfact = data\n",
        "for fact in temp_counterfact:\n",
        "  if fact[\"requested_rewrite\"]['prompt'] not in neighborhood_dict.keys():\n",
        "    neighborhood_dict[fact[\"requested_rewrite\"]['prompt']]=dict()\n",
        "\n",
        "print(\"keys: done\")\n",
        "\n",
        "# Collect, for every relation, its subjects that the model can predict, grouping by objects:\n",
        "for fact in temp_counterfact:\n",
        "  o_true = fact[\"requested_rewrite\"][\"target_true\"][\"str\"]\n",
        "  for neighbor in fact[\"neighborhood_prompts\"]:\n",
        "    o_pred = naiv_predict(neighbor)\n",
        "    if o_true==o_pred:\n",
        "      for prompt in neighborhood_dict.keys():\n",
        "        if is_in_prompt(prompt, neighbor):\n",
        "          if o_true not in neighborhood_dict[prompt].keys():\n",
        "            neighborhood_dict[prompt][o_true] = []\n",
        "          neighbor_subject = get_subject(neighbor, prompt)\n",
        "          if neighbor_subject not in neighborhood_dict[prompt][o_true]:\n",
        "            neighborhood_dict[prompt][o_true].append(neighbor_subject)\n",
        "          break\n",
        "  count+=1\n",
        "  if count%100==0:\n",
        "    print(count)\n",
        "\n",
        "print_dict(neighborhood_dict, file1_name)"
      ],
      "metadata": {
        "id": "E-LHlE0bGAdW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "131b7134-bd2e-4112-bf56-eff0565a352d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "keys: done\n",
            "100\n",
            "200\n",
            "300\n",
            "400\n",
            "500\n",
            "600\n",
            "700\n",
            "800\n",
            "900\n",
            "1000\n",
            "1100\n",
            "1200\n",
            "1300\n",
            "1400\n",
            "1500\n",
            "1600\n",
            "1700\n",
            "1800\n",
            "1900\n",
            "2000\n",
            "2100\n",
            "2200\n",
            "2300\n",
            "2400\n",
            "2500\n",
            "2600\n",
            "2700\n",
            "2800\n",
            "2900\n",
            "3000\n",
            "3100\n",
            "3200\n",
            "3300\n",
            "3400\n",
            "3500\n",
            "3600\n",
            "3700\n",
            "3800\n",
            "3900\n",
            "4000\n",
            "4100\n",
            "4200\n",
            "4300\n",
            "4400\n",
            "4500\n",
            "4600\n",
            "4700\n",
            "4800\n",
            "4900\n",
            "5000\n",
            "5100\n",
            "5200\n",
            "5300\n",
            "5400\n",
            "5500\n",
            "5600\n",
            "5700\n",
            "5800\n",
            "5900\n",
            "6000\n",
            "6100\n",
            "6200\n",
            "6300\n",
            "6400\n",
            "6500\n",
            "6600\n",
            "6700\n",
            "6800\n",
            "6900\n",
            "7000\n",
            "7100\n",
            "7200\n",
            "7300\n",
            "7400\n",
            "7500\n",
            "7600\n",
            "7700\n",
            "7800\n",
            "7900\n",
            "8000\n",
            "8100\n",
            "8200\n",
            "8300\n",
            "8400\n",
            "8500\n",
            "8600\n",
            "8700\n",
            "8800\n",
            "8900\n",
            "9000\n",
            "9100\n",
            "9200\n",
            "9300\n",
            "9400\n",
            "9500\n",
            "9600\n",
            "9700\n",
            "9800\n",
            "9900\n",
            "10000\n",
            "10100\n",
            "10200\n",
            "10300\n",
            "10400\n",
            "10500\n",
            "10600\n",
            "10700\n",
            "10800\n",
            "10900\n",
            "11000\n",
            "11100\n",
            "11200\n",
            "11300\n",
            "11400\n",
            "11500\n",
            "11600\n",
            "11700\n",
            "11800\n",
            "11900\n",
            "12000\n",
            "12100\n",
            "12200\n",
            "12300\n",
            "12400\n",
            "12500\n",
            "12600\n",
            "12700\n",
            "12800\n",
            "12900\n",
            "13000\n",
            "13100\n",
            "13200\n",
            "13300\n",
            "13400\n",
            "13500\n",
            "13600\n",
            "13700\n",
            "13800\n",
            "13900\n",
            "14000\n",
            "14100\n",
            "14200\n",
            "14300\n",
            "14400\n",
            "14500\n",
            "14600\n",
            "14700\n",
            "14800\n",
            "14900\n",
            "15000\n",
            "15100\n",
            "15200\n",
            "15300\n",
            "15400\n",
            "15500\n",
            "15600\n",
            "15700\n",
            "15800\n",
            "15900\n",
            "16000\n",
            "16100\n",
            "16200\n",
            "16300\n",
            "16400\n",
            "16500\n",
            "16600\n",
            "16700\n",
            "16800\n",
            "16900\n",
            "17000\n",
            "17100\n",
            "17200\n",
            "17300\n",
            "17400\n",
            "17500\n",
            "17600\n",
            "17700\n",
            "17800\n",
            "17900\n",
            "18000\n",
            "18100\n",
            "18200\n",
            "18300\n",
            "18400\n",
            "18500\n",
            "18600\n",
            "18700\n",
            "18800\n",
            "18900\n",
            "19000\n",
            "19100\n",
            "19200\n",
            "19300\n",
            "19400\n",
            "19500\n",
            "19600\n",
            "19700\n",
            "19800\n",
            "19900\n",
            "20000\n",
            "20100\n",
            "20200\n",
            "20300\n",
            "20400\n",
            "20500\n",
            "20600\n",
            "20700\n",
            "20800\n",
            "20900\n",
            "21000\n",
            "21100\n",
            "21200\n",
            "21300\n",
            "21400\n",
            "21500\n",
            "21600\n",
            "21700\n",
            "21800\n",
            "21900\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from base_neighbors import d as nbrs\n",
        "new_nbrs = {k: nbrs[k] for k in nbrs.keys() if sum([len(v) for v in nbrs[k].values()])>=minimal_neighborhood_len}"
      ],
      "metadata": {
        "id": "85nswqKpVh5j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DO8a2YRSVkBZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_dataset = []"
      ],
      "metadata": {
        "id": "XfSGje-FTv_e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Ks = list(new_nbrs.keys())    # Ks: relations\n",
        "\n",
        "\n",
        "# split every relation-gruop\n",
        "for i in range(len(Ks)):  \n",
        "  k = Ks[i]   # relation\n",
        "  objects = new_nbrs[k] # {object: [subject]}\n",
        "\n",
        "  o_list = list(objects.keys())\n",
        "  o_counts = {ob: len(objects[ob]) for ob in o_list}\n",
        "  sorted_counts = dict(sorted(o_counts.items(), key=lambda x:x[1]))\n",
        "  subset_indices = subset(list(sorted_counts.values()))\n",
        "  subset1_objects = [o_list[i] for i in subset_indices]\n",
        "  subset2_objects = [ob for ob in o_list if ob not in subset1_objects]\n",
        "\n",
        "  subset1_subjects = []\n",
        "  for object in subset1_objects:\n",
        "    subset1_subjects += objects[object]\n",
        "\n",
        "  subset2_subjects = []\n",
        "  for object in subset2_objects:\n",
        "    subset2_subjects += objects[object]\n",
        "\n",
        "  if len(subset1_subjects)>=minimal_neighborhood_len and len(subset2_subjects)>=minimal_neighborhood_len:\n",
        "    dataset1 = (k, subset1_subjects, subset1_objects, subset2_objects)\n",
        "    dataset2 = (k, subset2_subjects, subset2_objects, subset1_objects)\n",
        "    new_dataset.append(dataset1)\n",
        "    new_dataset.append(dataset2)\n",
        "  else:\n",
        "    dataset = (k, subset1_subjects+subset2_subjects, o_list, [])\n",
        "    new_dataset.append(dataset)"
      ],
      "metadata": {
        "id": "2MLKBilxqEgd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print_list(new_dataset, file2_name)"
      ],
      "metadata": {
        "id": "cUW-QKXzTyqi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Version 2: filtered with unknown objects"
      ],
      "metadata": {
        "id": "Nt_-By8dXREj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from source import nbrs "
      ],
      "metadata": {
        "id": "sRNp39Q0bFrT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_dataset = []"
      ],
      "metadata": {
        "id": "xJpbg1xEecGx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Ks = list(nbrs.keys())    # Ks: relations\n",
        "\n",
        "# k = Ks[0]  #\n",
        "# L = nbrs[k]  #\n",
        "\n",
        "for i in range(len(Ks)):\n",
        "  k = Ks[i]\n",
        "  L = nbrs[k]\n",
        "\n",
        "  objects = dict()      # objects = {object: [prompts]}\n",
        "  for p in L:           # p: entire prompt (subject + relation)\n",
        "    o = naiv_predict(p)\n",
        "    if o not in objects.keys():\n",
        "      objects[o]=[]\n",
        "    s = get_subject(p, k)\n",
        "    if s not in objects[o]:\n",
        "      objects[o].append(s)\n",
        "\n",
        "  o_list = list(objects.keys())\n",
        "  o_counts = {ob: len(objects[ob]) for ob in o_list}\n",
        "  sorted_counts = dict(sorted(o_counts.items(), key=lambda x:x[1]))\n",
        "  subset_indices = subset(list(sorted_counts.values()))\n",
        "  subset1_objects = [o_list[i] for i in subset_indices]\n",
        "  subset2_objects = [ob for ob in o_list if ob not in subset1_objects]\n",
        "\n",
        "  subset1_subjects = []\n",
        "  for object in subset1_objects:\n",
        "    subset1_subjects += objects[object]\n",
        "\n",
        "  subset2_subjects = []\n",
        "  for object in subset2_objects:\n",
        "    subset2_subjects += objects[object]\n",
        "\n",
        "\n",
        "  if len(subset1_subjects)>=minimal_neighborhood_len and len(subset2_subjects)>=minimal_neighborhood_len:\n",
        "    dataset1 = (k, subset1_subjects, subset1_objects, subset2_objects)\n",
        "    dataset2 = (k, subset2_subjects, subset2_objects, subset1_objects)\n",
        "    new_dataset.append(dataset1)\n",
        "    new_dataset.append(dataset2)\n",
        "  else:\n",
        "    dataset = (k, subset1_subjects+subset2_subjects, o_list, [])\n",
        "    new_dataset.append(dataset)"
      ],
      "metadata": {
        "id": "RPClNRMBdWmd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print_list(new_dataset, file2_name)"
      ],
      "metadata": {
        "id": "QlpHTLq8o5_z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# new_neighborhood_list = dict()   # neighborhood_dict: dictionary in form {ralation: {object: [subjects]}}:\n",
        "\n",
        "# for relation, prompts, objects in nbrs:\n",
        "#   subjects = []\n",
        "#   for prompt in prompts:\n",
        "#     new_subject = get_subject(prompt, relation)\n",
        "#     subjects.append(new_subject)\n",
        "#   dataset = (relation, subjects, objects)\n",
        "#   new_neighborhood_list.append(dataset)"
      ],
      "metadata": {
        "id": "aUIH-rJYqO6X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LZYkB98gtOxY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Validation"
      ],
      "metadata": {
        "id": "mohWjYX5qWk4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# check:\n",
        "dataset_semple = [2,3,6,7,11,12,15,16]\n",
        "promts_sample = [1,2,6,42,43,45,51,93,120]\n",
        "\n",
        "for i in  dataset_semple:\n",
        "  ds = new_dataset[i]\n",
        "  objects = ds[2]\n",
        "  prompts = ds[1]\n",
        "  relation = ds[0]\n",
        "  for j in promts_sample:\n",
        "    if j<len(prompts):\n",
        "      subject = prompts[j]\n",
        "      pmpt = combine_prompt(subject, relation)\n",
        "      pred = naiv_predict(pmpt)\n",
        "      print(pred in objects)\n",
        "      if not pred in objects:\n",
        "        print(f\"\\ti={i}, j={j}, prompt={pmpt}, pred={pred}\")"
      ],
      "metadata": {
        "id": "vV4q6Vr8NMEW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check length:\n",
        "for relation, subjects, objects in new_dataset:\n",
        "  print(len(prompts))\n",
        "\n",
        "print()\n",
        "\n",
        "print(len([x for x in new_dataset if len(x[1])>5]))"
      ],
      "metadata": {
        "id": "1_4ey5mKWH5W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Trials**"
      ],
      "metadata": {
        "id": "RxS-vKDEK2w8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# New\n",
        "LEVEL_IDX[0] = 5\n",
        "\n",
        "request = [\n",
        "      {\n",
        "          \"prompt\": \"{} is \",\n",
        "          \"subject\": \"Yanay\",\n",
        "          \"target_new\": {\"str\": \"genius\"},\n",
        "      }\n",
        "  ]\n",
        "\n",
        "    \n",
        "M[\"model_new\"], M[\"orig_weights\"] = demo_model_editing(mt2.model, tok, request, [\"a\"], alg_name=ALG_NAME)\n",
        "mt2.model = M[\"model_new\"]\n",
        "\n",
        "clean()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "3c88c2318583433cb44475eeb4907567",
            "f5907f0d59fb4b459456eea5b07c0f8f",
            "ef832d03f6a04d599c66052c78555900",
            "a238a4559acf4217afccf6412f2e3456",
            "4c8ceca4ba244d75a53329760ab97dea",
            "47981e7230ac4841b528a95fe492f1ff",
            "cb9888f4b21a4313bc7a45ca423279b9",
            "2f08757f1ce04016bc3fa6a36d2a7817",
            "7944c5892ef84396b4852031de935684",
            "bbd2a1fb8bf049898abaf50c8bd5aa28",
            "98fbc9e36a5049da853acdce2d037d0c",
            "517499f4d3e940929096a89ffa7e9846",
            "be516558c0664eaf85c609ead4fe65a1",
            "cd6e2880ec194fb29c2d0a95d6e145db",
            "7c7332758ee647588b7c49dc7713baeb",
            "dc43a5ce6e784b87966d2e7e61ad0191",
            "071f36caf6bf42728454b1673ebaeed1",
            "c9d93e1bd2b64625b4ce7a31b46a50e7",
            "68d0cd5577594fb1aa40f0f90197213a",
            "f8344790ad604559b42ddd2ed0dff8ee",
            "a42c3193558e4cc6a62f2cb789a5f067",
            "d2d2c5cb2beb43a995bcc2f1316f0d4c"
          ]
        },
        "id": "-Lb485DWMMwq",
        "outputId": "614c01a7-f37e-43a0-be01-b98354d9ad08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'prompt': '{} is ', 'subject': 'Yanay', 'target_new': {'str': 'genius'}}] \n",
            "\n",
            "\n",
            "&&&\n",
            "&&&\n",
            "&&&\n",
            "&&& hparams/ROME/gpt2-xl.json \n",
            "&&&\n",
            "&&&\n",
            "&&&\n",
            "&&&\n",
            "5\n",
            "\n",
            "###hparams:\n",
            " [5] \n",
            "$$$\n",
            "$$$\n",
            "Cached context templates ['{}', 'The new season of. {}', 'The new generation of. {}', 'The first time you. {}', 'A man has been. {}', 'The U.S. {}', 'In the wake of. {}', 'The U.S. {}', '\"The only thing. {}', '\"I have been. {}', 'The first time you. {}', 'In an exclusive interview with Breitbart News, a. {}', 'I have to admit, I am not the. {}', 'I have a lot of experience with the Raspberry. {}', '\"The only thing we have to fear is. {}', 'A man was shot dead in the city centre. {}', 'The U.S. Supreme Court ruled Thursday. {}', 'The first thing to understand about the new,. {}', '\"I have a dream.\" That. {}', '\"It\\'s not about the money, it. {}', 'The UESPWiki – Your source for. {}']\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Yanay\n",
            "Retrieving inverse covariance statistics for gpt2-xl @ transformer.h.5.mlp.c_proj. The result will be cached to avoid repetitive computation.\n",
            "Attempting to download gpt2-xl/wikipedia_stats/transformer.h.5.mlp.c_proj_float32_mom2_100000.npz from https://rome.baulab.info/data/stats/gpt2-xl/wikipedia_stats/transformer.h.5.mlp.c_proj_float32_mom2_100000.npz.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0.00/156M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3c88c2318583433cb44475eeb4907567"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully downloaded.\n",
            "Loading cached data/stats/gpt2-xl/wikipedia_stats/transformer.h.5.mlp.c_proj_float32_mom2_100000.npz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1000 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "517499f4d3e940929096a89ffa7e9846"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Computing right vector (v)\n",
            "Lookup index found: 1 | Sentence: Yanay is  | Token: ay\n",
            "Rewrite layer is 5\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 14.749 = 14.749 + 0.0 + 0.0 avg prob of [ genius] 6.15194721831358e-07\n",
            "loss 13.928 = 13.816 + 0.025 + 0.087 avg prob of [ genius] 1.5049603234729148e-06\n",
            "loss 13.067 = 12.867 + 0.057 + 0.143 avg prob of [ genius] 3.52335723619035e-06\n",
            "loss 11.929 = 11.671 + 0.071 + 0.187 avg prob of [ genius] 1.1593338967941236e-05\n",
            "loss 10.407 = 10.151 + 0.069 + 0.187 avg prob of [ genius] 5.442638212116435e-05\n",
            "loss 7.996 = 7.743 + 0.066 + 0.187 avg prob of [ genius] 0.0006433093803934753\n",
            "loss 6.325 = 6.011 + 0.126 + 0.187 avg prob of [ genius] 0.005619416479021311\n",
            "loss 3.311 = 3.001 + 0.123 + 0.187 avg prob of [ genius] 0.08348087966442108\n",
            "loss 0.858 = 0.533 + 0.137 + 0.187 avg prob of [ genius] 0.6867366433143616\n",
            "loss 0.464 = 0.131 + 0.146 + 0.187 avg prob of [ genius] 0.8853286504745483\n",
            "loss 0.438 = 0.098 + 0.153 + 0.187 avg prob of [ genius] 0.9107215404510498\n",
            "loss 0.381 = 0.055 + 0.139 + 0.187 avg prob of [ genius] 0.9471979141235352\n",
            "loss 0.342 = 0.035 + 0.121 + 0.187 avg prob of [ genius] 0.9664132595062256\n",
            "loss 0.348 = 0.038 + 0.123 + 0.187 avg prob of [ genius] 0.9639680981636047\n",
            "loss 0.334 = 0.028 + 0.119 + 0.187 avg prob of [ genius] 0.9732202887535095\n",
            "loss 0.317 = 0.017 + 0.113 + 0.187 avg prob of [ genius] 0.9833023548126221\n",
            "loss 0.308 = 0.012 + 0.108 + 0.187 avg prob of [ genius] 0.9877758026123047\n",
            "loss 0.299 = 0.01 + 0.102 + 0.187 avg prob of [ genius] 0.9902876019477844\n",
            "loss 0.292 = 0.008 + 0.097 + 0.187 avg prob of [ genius] 0.9918632507324219\n",
            "loss 0.289 = 0.007 + 0.095 + 0.187 avg prob of [ genius] 0.9929609298706055\n",
            "Delta norm: 42.77944564819336\n",
            "Change in target norm: 10.694860458374023 to 43.75038528442383 => 33.05552673339844\n",
            "Division Factor: 2.8285791873931885\n",
            "Right vector norm: 15.124004364013672\n",
            "Original model restored\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "relation, subjects, _, _ = \t('The original language of {} was', [\"L'Atlantide\", 'Şarkıcı', 'Zärtliche Chaoten', 'Moordwijven', 'Los Olvidados', 'Tel Aviv-Los Angeles', 'Adi Shankaracharya'], ['a', 'written', 'Dutch', 'Spanish', 'Sanskrit'], [])\n",
        "for subject in subjects:\n",
        "  prompt = combine_prompt(subject, relation)\n",
        "  print(prompt,\"  :  \", naiv_predict(prompt))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cGjD-kwuoG4O",
        "outputId": "0485ceb5-1406-49af-f1eb-5dd81b9edb83"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The original language of L'Atlantide was   :   written\n",
            "The original language of Şarkıcı was   :   written\n",
            "The original language of Zärtliche Chaoten was   :   written\n",
            "The original language of Moordwijven was   :   Dutch\n",
            "The original language of Los Olvidados was   :   Spanish\n",
            "The original language of Tel Aviv-Los Angeles was   :   a\n",
            "The original language of Adi Shankaracharya was   :   Sanskrit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mt2.tokenizer.encode(\"the\")[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JSv4eZ-aM4f7",
        "outputId": "943eaff7-c232-4b38-906d-ff81664e46dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1169"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "naiv_predict(\"\", \"The native language of Raymond Barre is\")"
      ],
      "metadata": {
        "id": "gdbeoI44K2Dn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "f9f47a0e-ecf7-4ade-f9d3-3801cf24f00a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'French'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "naiv_predict(\"Alan Turing\", \"is a kind of\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "DD4hkZ4rbR11",
        "outputId": "deb350f0-d60f-4b97-d942-2ac3f3dc5077"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'hero'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "naiv_predict(\"Alan Turing\", \"is not a cat, but a\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "1I7L1hZ5bsCM",
        "outputId": "6d4864d6-1965-4898-d9dd-b4f547fc77ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'computer'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7mnQ99o3DsUp"
      },
      "source": [
        "# **Updates experiment**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wrY4w_1Ovgfh"
      },
      "outputs": [],
      "source": [
        "NUM_OF_LAYERS = 48\n",
        "M = dict()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def neighbors_probs(main_subject, relation, neighbors, target_id):\n",
        "  # str, list(str), int --> list(float)\n",
        "  probs = []\n",
        "  for neighbor in neighbors:\n",
        "    if main_subject is None or neighbor!=main_subject:\n",
        "      prompt = combine_prompt(neighbor, relation)\n",
        "      probs.append(predict_by_idx(mt2, prompt, target_id))\n",
        "  return probs\n",
        "\n",
        "def neighboring(probs1, probs2):\n",
        "  # list(float), list(float) --> float\n",
        "  m = len(probs1)\n",
        "  f = []\n",
        "  for i in range(m):\n",
        "    numerator = abs(probs1[i]-probs2[i])\n",
        "    denominator = 0.5+abs(probs1[i]-0.5)\n",
        "    ngbring = 1 - numerator / denominator\n",
        "    f.append(ngbring)\n",
        "  return sum(f) / m"
      ],
      "metadata": {
        "id": "GQSmTxxJglrJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N43XmzUL_JAC"
      },
      "outputs": [],
      "source": [
        "def plot_all_flow(mt, prompt, subject=None, noise=0.1, modelname=None):\n",
        "    for kind in [\"mlp\"]:\n",
        "        plot_hidden_flow(\n",
        "            mt, prompt, subject, modelname=modelname, noise=noise, kind=kind\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-V5ngQq0-dw1"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "def return_map(\n",
        "    prompt,\n",
        "    subject,\n",
        "    mt=mt2,\n",
        "    samples=10,\n",
        "    noise=noise_level,\n",
        "    window=10,\n",
        "    kind=\"mlp\",\n",
        "    modelname=None,\n",
        "    savepdf=None,\n",
        "):\n",
        "    if subject is None:\n",
        "        subject = guess_subject(prompt)\n",
        "    result = calculate_hidden_flow(\n",
        "        mt, prompt, subject, samples=samples, noise=noise, window=window, kind=kind\n",
        "    )\n",
        "    return result\n",
        "\n",
        "\n",
        "def generate_city_prompt(city):\n",
        "  prompt = \"is the capital city of\"\n",
        "  word=naiv_predict(city, prompt)\n",
        "  while word in [\"the\", \"state\", \"State\", \"of\", \"Republic\", \"province\", \"Province\"]:\n",
        "    prompt = prompt+ \" \" + word\n",
        "    word=naiv_predict(city, prompt)\n",
        "  return prompt\n",
        "\n",
        "\n",
        "def entropy(tens):\n",
        "    tens_norm = tens / tens.sum()\n",
        "    logs = torch.log2(tens_norm)\n",
        "    logs = torch.where(logs==-float(\"inf\"),0,logs)\n",
        "    y = logs * tens_norm\n",
        "    return -y.sum().item() / math.log2(len(tens))\n",
        "\n",
        "\n",
        "def max_layer_and_entropy(prompt, subject, max_neighbors=[1], effect_idx=[]):\n",
        "  print(f\"prompt: {prompt}, subject: {subject}\")\n",
        "  result = return_map(prompt, subject)\n",
        "  scores = result['scores']\n",
        "  a, b = result['subject_range']\n",
        "  argmax = scores[a:b].argmax().item()\n",
        "\n",
        "  relevant_token_idx = int(argmax / len(scores[0])) + a\n",
        "  relevant_token = scores[relevant_token_idx]\n",
        "\n",
        "  _max = scores[a:b].max().item()\n",
        "  _min = scores[a:b].min().item()\n",
        "  avrg = relevant_token.sum().item() / (len(scores[0]))\n",
        "  effs = []\n",
        "  for idx in effect_idx: \n",
        "    effs.append(relevant_token[idx].item())\n",
        "\n",
        "  layer = argmax % len(scores[0])\n",
        "  cent = []\n",
        "  for i in max_neighbors:\n",
        "    if layer+i>=0:\n",
        "      cent.append(((relevant_token[layer] - relevant_token[layer+1]) / relevant_token[layer]).item())\n",
        "    else:\n",
        "      cent.append(-1)\n",
        "  return layer, entropy(relevant_token), cent, _max, _min, avrg, effs\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "  def clean():\n",
        "    if \"orig_weights\" in M.keys():\n",
        "        with torch.no_grad():\n",
        "            for k, v in M[\"orig_weights\"].items():\n",
        "                nethook.get_parameter(mt2.model, k)[...] = v\n",
        "        print(\"Original model restored\")\n",
        "    else:\n",
        "        print(f\"No model weights to restore\")\n",
        "    \n",
        "    M.clear()"
      ],
      "metadata": {
        "id": "ztg1qwXESVF2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def change_and_check_ser(_subject, prompt, targets, affected, set_affected=None, count_flag=False):\n",
        "\n",
        "def change_and_check(main_subject_idx, relation, new_target, neighborhood, orig_probs=None, orig_final=None, to_target_flag=False):\n",
        "  # If orig_probs is not None: return list of the probability for new_target, for each neighbor. \n",
        "  # In this case: orig_ouputs = list of original probs (for all subjects including main_subject_idx)\n",
        "  # If orig_final is not None: count and return the number of changed final-outputs of neighbors.\n",
        "  # In this case: orig_ouputs = list of final outputs (tokens. For all subjects including main_subject_idx)\n",
        "\n",
        "  # if to_target_flag: count only changes to new_target. else: all change.\n",
        "\n",
        "  # neighborhood: list(subjects). incluuding main_subject\n",
        "\n",
        "  clean()\n",
        "\n",
        "  main_subject = neighborhood[main_subject_idx]\n",
        "\n",
        "  random.seed(_seed)\n",
        "  numpy.random.seed(seed=_seed)\n",
        "  torch.manual_seed(_seed)\n",
        "\n",
        "  tok_id = mt2.tokenizer.encode(new_target)[0]\n",
        "\n",
        "  request = [\n",
        "      {\n",
        "          \"prompt\": relation,\n",
        "          \"subject\": main_subject,\n",
        "          \"target_new\": {\"str\": new_target},\n",
        "      }\n",
        "  ]\n",
        "\n",
        "    \n",
        "  M[\"model_new\"], M[\"orig_weights\"] = demo_model_editing(mt2.model, tok, request, [\"a\"], alg_name=ALG_NAME)\n",
        "  mt2.model = M[\"model_new\"]\n",
        "\n",
        "  results = []\n",
        "\n",
        "  if orig_probs is not None:\n",
        "    filtered_orig_probs = orig_probs[:main_subject_idx]+orig_probs[main_subject_idx+1:]\n",
        "    post_probs = neighbors_probs(main_prompt, neighborhood, tok_id)\n",
        "    neighboring_score = neighboring(filtered_orig_probs, post_probs)\n",
        "    results.append(neighboring_score)\n",
        "  \n",
        "  if orig_final is not None:\n",
        "    count = 0\n",
        "    for i in range(len(neighborhood)):\n",
        "      if i!=main_subject_idx:\n",
        "        pred = naiv_predict(neighborhood[i])\n",
        "        if to_target_flag:\n",
        "          count+= 1*(pred==new_target)\n",
        "        else:\n",
        "          count+= 1*(pred!=oirg_final[i])\n",
        "    results.append(count / (len(neighborhood)-1))\n",
        "\n",
        "  # results: [single float] or [single float, single float]\n",
        "  return results"
      ],
      "metadata": {
        "id": "hoKFTEZXSC-b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def neighborhood_score_by_object(neighborhood_data, target, orig_probs=None, orig_final=None, to_target_flag=False):\n",
        "  # Calculate lists (one or two) of neighborhood_score of specific target (object) (given specific relation) over all subjects.\n",
        "  # neighborhood_data: (relation: str, subjects: list(str), orig_objects: list(str), new_objects: list(str))\n",
        "\n",
        "  relation, subjects, _, _ = neighborhood_data\n",
        "\n",
        "  neighborhood_scores = []\n",
        "  if orig_probs is not None:\n",
        "    neighborhood_scores.append([])\n",
        "  if orig_final is not None:\n",
        "    neighborhood_scores.append([])\n",
        "\n",
        "  for subject_idx in range(len(subjects)):\n",
        "    current_scores = change_and_check(subject_idx, relation, target, subjects, orig_probs, orig_final, to_target_flag)\n",
        "    if orig_probs is not None:\n",
        "      neighborhood_scores[0].append(current_scores[0])\n",
        "    if orig_final is not None:\n",
        "      neighborhood_scores[-1].append(current_scores[-1])\n",
        "  \n",
        "  # neighborhood_scores: [[floats]] or [[floats], [floats]]\n",
        "  # len of each [floats] is: |subjects| \n",
        "  return neighborhood_scores\n",
        "\n",
        "\n",
        "def neighboring_score_of_neighborhood(neighborhood_data, orig_probs_flag=True, orig_final_flag=True, to_target_flag=False):\n",
        "  relation, subjects, _, new_objects = neighborhood_data\n",
        "  n_subjects = len(subjects)\n",
        "\n",
        "  if orig_final_flag:\n",
        "    orig_final = []\n",
        "    for subject in subjects:\n",
        "      orig_final.append(naiv_predict(subject, relation))\n",
        "  else:\n",
        "    orig_final = None\n",
        "  \n",
        "  neighborhood_scores = []\n",
        "  if orig_probs_flag:\n",
        "    neighborhood_scores.append([0]*n_subjects)\n",
        "  if orig_final_flag:\n",
        "    neighborhood_scores.append([0]*n_subjects)\n",
        "\n",
        "  for target in new_objects:  \n",
        "    if orig_probs_flag:\n",
        "      target_id = mt2.tokenizer.encode(target)[0]\n",
        "      orig_probs = neighbors_probs(main_subject=None, relation=neighborhood_data[0], neighbors=subjects, target_id=target_id)\n",
        "    else:\n",
        "      orig_probs = None\n",
        "    \n",
        "    current_scores = neighborhood_score_by_object(neighborhood_data, target, orig_probs, orig_final, to_target_flag)\n",
        "    sum_matrices(neighborhood_scores, current_scores, alpha=1/n_subjects)\n",
        "\n",
        "  # neighborhood_scores: [[floats]] or [[floats], [floats]]\n",
        "  return neighborhood_scores"
      ],
      "metadata": {
        "id": "T33KE_lRm7AA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def neighborhood_results(neighborhood_data, orig_probs_flag=True, orig_final_flag=True, to_target_flag=False, num_of_layers=48):\n",
        "  causal_features = {\"max layers\": [], \"entropies\": [], \"maxs\": [], \"mins\": [], \"avrgs\": [], \"effs\": []}\n",
        "  results = {\"causal_features\": causal_features, \"neighborhood_scores\": []}\n",
        "  relation, subjects, _, new_objects = neighborhood_data\n",
        "  for subject in subjects:\n",
        "    prompt = combine_prompt(subject, relation)\n",
        "    max_layer, entropy, _, _max, _min, avrg, effs = max_layer_and_entropy(prompt, subject, max_neighbors=[], effect_idx=range(num_of_layers))\n",
        "    \n",
        "    causal_features[\"max layers\"].append(max_layer)\n",
        "    causal_features[\"entropies\"].append(entropy)\n",
        "    causal_features[\"maxs\"].append(_max)\n",
        "    causal_features[\"mins\"].append(_min)\n",
        "    causal_features[\"avrgs\"].append(avrg)\n",
        "    causal_features[\"effs\"].append(effs)\n",
        "\n",
        "  for layer_idx in range(num_of_layers):\n",
        "    LAYER_IDX[0] = layer_idx\n",
        "    neighboring = neighboring_score_of_neighborhood(neighborhood_data, orig_probs_flag, orig_final_flag, to_target_flag)\n",
        "    results[\"neighborhood_scores\"].append(neighboring)"
      ],
      "metadata": {
        "id": "XUTs3QWrQbEW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def all_results(neighborhood_list, orig_probs_flag=True, orig_final_flag=True, to_target_flag=False, num_of_layers=NUM_OF_LAYERS):\n",
        "  results = []\n",
        "  idx = 0\n",
        "  for neighborhood_data in neighborhood_list:\n",
        "    print(idx)\n",
        "    idx+=1\n",
        "    new_results = neighborhood_results(neighborhood_data, orig_probs_flag, orig_final_flag, to_target_flag, num_of_layers)\n",
        "    results.append(new_results)\n",
        "  return results"
      ],
      "metadata": {
        "id": "VWGMf6P3dfvV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from neighborhood import d\n",
        "\n",
        "results = all_results(d)\n",
        "print_list(list_input = results, file_name=\"attractions_and_features.py\")"
      ],
      "metadata": {
        "id": "xi9RwOS1eWlR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 956
        },
        "outputId": "b91e05dc-c649-438e-f137-4184c8d9bcbc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "prompt: The mother tongue of Odysseas Elytis is, subject: Odysseas Elytis\n",
            "prompt: The mother tongue of Andreas Papandreou is, subject: Andreas Papandreou\n",
            "prompt: The mother tongue of Konstantinos Karamanlis is, subject: Konstantinos Karamanlis\n",
            "prompt: The mother tongue of Georgios Rallis is, subject: Georgios Rallis\n",
            "prompt: The mother tongue of Alexandros Papadiamantis is, subject: Alexandros Papadiamantis\n",
            "prompt: The mother tongue of Yannis Kounellis is, subject: Yannis Kounellis\n",
            "prompt: The mother tongue of Charlie Chaplin is, subject: Charlie Chaplin\n",
            "prompt: The mother tongue of George Washington is, subject: George Washington\n",
            "prompt: The mother tongue of Cyndi Lauper is, subject: Cyndi Lauper\n",
            "prompt: The mother tongue of Elton John is, subject: Elton John\n",
            "prompt: The mother tongue of Bob Dylan is, subject: Bob Dylan\n",
            "prompt: The mother tongue of Paul McCartney is, subject: Paul McCartney\n",
            "prompt: The mother tongue of George Orwell is, subject: George Orwell\n",
            "prompt: The mother tongue of Michael Jackson is, subject: Michael Jackson\n",
            "prompt: The mother tongue of Douglas Adams is, subject: Douglas Adams\n",
            "prompt: The mother tongue of Meryl Streep is, subject: Meryl Streep\n",
            "prompt: The mother tongue of Bill Clinton is, subject: Bill Clinton\n",
            "prompt: The mother tongue of Abraham Lincoln is, subject: Abraham Lincoln\n",
            "prompt: The mother tongue of Patricio Manns is, subject: Patricio Manns\n",
            "prompt: The mother tongue of Pilar López de Ayala is, subject: Pilar López de Ayala\n",
            "prompt: The mother tongue of Antonio Prieto is, subject: Antonio Prieto\n",
            "prompt: The mother tongue of Ignacio Manuel Altamirano Basilio is, subject: Ignacio Manuel Altamirano Basilio\n",
            "prompt: The mother tongue of Iker Jiménez Elizari is, subject: Iker Jiménez Elizari\n",
            "prompt: The mother tongue of Antonio Vega is, subject: Antonio Vega\n",
            "prompt: The mother tongue of Cristian Gamboa is, subject: Cristian Gamboa\n",
            "prompt: The mother tongue of Paco Ignacio Taibo II is, subject: Paco Ignacio Taibo II\n",
            "prompt: The mother tongue of Armando Palacio Valdés is, subject: Armando Palacio Valdés\n",
            "prompt: The mother tongue of Jorge Ubico is, subject: Jorge Ubico\n",
            "prompt: The mother tongue of Kany García is, subject: Kany García\n",
            "prompt: The mother tongue of Antonio Fontán is, subject: Antonio Fontán\n",
            "prompt: The mother tongue of Elisa Brătianu is, subject: Elisa Brătianu\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-40-a43fec475618>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mneighborhood\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"attractions_and_features.py\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-39-0a0b85035469>\u001b[0m in \u001b[0;36mall_results\u001b[0;34m(neighborhood_list, orig_probs_flag, orig_final_flag, to_target_flag, num_of_layers)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0midx\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mnew_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mneighborhood_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneighborhood_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morig_probs_flag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morig_final_flag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_target_flag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_of_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_results\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-38-abf49d54ff59>\u001b[0m in \u001b[0;36mneighborhood_results\u001b[0;34m(neighborhood_data, orig_probs_flag, orig_final_flag, to_target_flag, num_of_layers)\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0msubject\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msubjects\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mprompt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcombine_prompt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubject\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrelation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mmax_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mentropy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_min\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mavrg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meffs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax_layer_and_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubject\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_neighbors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meffect_idx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_of_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mcausal_features\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"max layers\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_layer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-34-251356698eba>\u001b[0m in \u001b[0;36mmax_layer_and_entropy\u001b[0;34m(prompt, subject, max_neighbors, effect_idx)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmax_layer_and_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubject\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_neighbors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meffect_idx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"prompt: {prompt}, subject: {subject}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m   \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturn_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m   \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'scores'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m   \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'subject_range'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-34-251356698eba>\u001b[0m in \u001b[0;36mreturn_map\u001b[0;34m(prompt, subject, mt, samples, noise, window, kind, modelname, savepdf)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msubject\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0msubject\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mguess_subject\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     result = calculate_hidden_flow(\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mmt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubject\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoise\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnoise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwindow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwindow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkind\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     )\n",
            "\u001b[0;32m<ipython-input-14-77b2ca3e4c3a>\u001b[0m in \u001b[0;36mcalculate_hidden_flow\u001b[0;34m(mt, prompt, subject, samples, noise, window, kind)\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0manswer_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbase_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpredict_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;34m[\u001b[0m\u001b[0manswer\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecode_tokens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0manswer_t\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0me_range\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_token_range\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"input_ids\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     low_score = trace_with_patch(\n\u001b[1;32m     14\u001b[0m         \u001b[0mmt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manswer_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me_range\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoise\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnoise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/rome/experiments/causal_trace.py\u001b[0m in \u001b[0;36mfind_token_range\u001b[0;34m(tokenizer, token_array, substring)\u001b[0m\n\u001b[1;32m    616\u001b[0m     \u001b[0mtoks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecode_tokens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m     \u001b[0mwhole_string\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 618\u001b[0;31m     \u001b[0mchar_loc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwhole_string\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubstring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    619\u001b[0m     \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    620\u001b[0m     \u001b[0mtok_start\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtok_end\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: substring not found"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Results Analysis**"
      ],
      "metadata": {
        "id": "apF1SokjwP7-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from attractions_and_features import d as results_list \n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "itwndj2Fwd9q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "neighboring_by_logits = True\n",
        "neighboring_by_finals = True\n",
        "\n",
        "correlations = []\n",
        "\n",
        "for results_dict in results_list:\n",
        "  max_layers = results_dict[\"causal_features\"][\"max layers\"]  # [ints]\n",
        "  effect_values = results_dict[\"causal_features\"][\"effs\"]     # [[floats], [floats]...]\n",
        "  mins = results_dict[\"causal_features\"][\"mins\"]              # [floats]\n",
        "  maxs = results_dict[\"causal_features\"][\"maxs\"]              # [floats]\n",
        "  n_neighbors = len(mins)\n",
        "\n",
        "  scores = results_dict[\"neighborhood_scores\"]  # [[[floats]], [[floats]]...] or [[[floats], [floats]], [[floats], [floats]]...]\n",
        "\n",
        "  correlation_dict = dict()   # {4* key: [floats]}\n",
        "  if neighboring_by_logits:\n",
        "    correlation_dict[\"logits and distance\"] = []\n",
        "    correlation_dict[\"logits and relative effect\"] = []\n",
        "  if neighboring_by_finals:\n",
        "    correlation_dict[\"finals and distance\"] = []\n",
        "    correlation_dict[\"finals and relative effect\"] = []\n",
        "  \n",
        "  # Calculate correlations\n",
        "  for layer_idx in range(NUM_OF_LAYERS):\n",
        "    current_scores = scores[layer_idx]  # [[floats]] or [[floats], [floats]]\n",
        "    distances = [abs(layer_idx-max_layer) for max_layer in max_layers]\n",
        "    relative_effects = [(effect_values[i][layer_idx] - mins[i]) / (maxs[i] - mins[i]) for i in range(n_neighbors)]\n",
        "\n",
        "    if neighboring_by_logits:\n",
        "      correlation_dict[\"logits and distance\"].append(np.corrcoef(scores[layer_idx][0], distances)[0][1])\n",
        "      correlation_dict[\"logits and relative effect\"].append(np.corrcoef(scores[layer_idx][0], relative_effects)[0][1])\n",
        "      \n",
        "    if neighboring_by_finals:\n",
        "      correlation_dict[\"finals and distance\"].append(np.corrcoef(scores[layer_idx][-1], distances)[0][1])\n",
        "      correlation_dict[\"finals and relative effect\"].append(np.corrcoef(scores[layer_idx][-1], relative_effects)[0][1])\n",
        "\n",
        "  correlations.append(correlation_dict)"
      ],
      "metadata": {
        "id": "mt41pTSkzADK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print_list(list_input = correlations, file_name=\"correlations.py\")"
      ],
      "metadata": {
        "id": "UYC0oT3EBJbW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from correlations import d as correlations_list\n",
        "\n",
        "if neighboring_by_logits:\n",
        "  for data_set_cor in correlations_list:\n",
        "    plt.plot(correlation_dict[\"logits and distance\"])\n",
        "  plt.title(f\"Correlation Between neighboring_by_logits and Distances\")\n",
        "  plt.xlabel(\"updated layer\")\n",
        "  plt.ylabel(\"correlation\")\n",
        "  plt.show()\n",
        "  \n",
        "  for data_set_cor in correlations_list:\n",
        "    plt.plot(correlation_dict[\"logits and relative effect\"])\n",
        "  plt.title(f\"Correlation Between neighboring_by_logits and Relative Effects\")\n",
        "  plt.xlabel(\"updated layer\")\n",
        "  plt.ylabel(\"correlation\")\n",
        "  plt.show()\n",
        "\n",
        "if neighboring_by_finals:\n",
        "  for data_set_cor in correlations_list:\n",
        "    plt.plot(correlation_dict[\"finals and distance\"])\n",
        "  plt.title(f\"Correlation Between neighboring_by_finals and Distances\")\n",
        "  plt.xlabel(\"updated layer\")\n",
        "  plt.ylabel(\"correlation\")\n",
        "  plt.show()\n",
        "  \n",
        "  for data_set_cor in correlations_list:\n",
        "    plt.plot(correlation_dict[\"finals and relative effect\"])\n",
        "  plt.title(f\"Correlation Between neighboring_by_finals and Relative Effects\")\n",
        "  plt.xlabel(\"updated layer\")\n",
        "  plt.ylabel(\"correlation\")\n",
        "  plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "Ufxfk3ACBeqk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Old code: serial update"
      ],
      "metadata": {
        "id": "FbYYQJVBmx5v"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oXegn1SrgXQA"
      },
      "outputs": [],
      "source": [
        "def change_and_check_ser(_subject, prompt, targets, affected, set_affected=None, count_flag=False):\n",
        "  clean()\n",
        "  \n",
        "  temp_name = \"orig_weights\"\n",
        "\n",
        "  if set_affected is not None:\n",
        "    print(\"Change affected:\")\n",
        "    for word in affected:\n",
        "      print(\"changing\", word)\n",
        "      random.seed(_seed)\n",
        "      numpy.random.seed(seed=_seed)\n",
        "      torch.manual_seed(_seed)\n",
        "\n",
        "      request = [\n",
        "        {\n",
        "            \"prompt\": f\"\\u007b\\u007d {prompt}\",\n",
        "            \"subject\": word,\n",
        "            \"target_new\": {\"str\": set_affected},\n",
        "        }\n",
        "      ]\n",
        "\n",
        "    \n",
        "      M[\"model_new\"], M[temp_name] = demo_model_editing(mt2.model, tok, request, [\"a\"], alg_name=ALG_NAME)\n",
        "      mt2.model = M[\"model_new\"]\n",
        "\n",
        "      temp_name = \"_\"\n",
        "\n",
        "  orig_object = predict(_subject, prompt)\n",
        "  print(f\"Pre check:\\n{_subject} {prompt} {orig_object}\")\n",
        "\n",
        "  change_index = 1\n",
        "\n",
        "  all_answers = []\n",
        "\n",
        "  if count_flag:\n",
        "    counts = []\n",
        "    prev_line = {}\n",
        "    for word in affected:\n",
        "      prev_line[word]=predict(word, prompt)\n",
        "\n",
        "  for t in targets:\n",
        "    target=orig_object if t==\"origin\" else t\n",
        "\n",
        "    random.seed(_seed)\n",
        "    numpy.random.seed(seed=_seed)\n",
        "    torch.manual_seed(_seed)\n",
        "\n",
        "    tok_id = mt2.tokenizer.encode(target)\n",
        "    pre_probs = neighbors_probs(_subject, prompt, neighborhood, tok_id)\n",
        "\n",
        "    if count_flag:\n",
        "      drag_count = 0\n",
        "      conf_count = 0\n",
        "\n",
        "    new_line = []\n",
        "    new_line.append(target)\n",
        "\n",
        "    print(\"CHANGE:\", change_index, \":\", target)\n",
        "    change_index+=1\n",
        "\n",
        "    request = [\n",
        "        {\n",
        "            \"prompt\": f\"\\u007b\\u007d {prompt}\",\n",
        "            \"subject\": _subject,\n",
        "            \"target_new\": {\"str\": target},\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    \n",
        "    M[\"model_new\"], M[temp_name] = demo_model_editing(mt2.model, tok, request, [\"a\"], alg_name=ALG_NAME)\n",
        "\n",
        "    mt2.model = M[\"model_new\"]\n",
        "\n",
        "    temp_name = \"_\"\n",
        "\n",
        "    post_probs = neighbors_probs(_subject, prompt, neighborhood, tok_id)\n",
        "    counts.append(neighboring(pre_probs, post_probs))\n",
        "  \n",
        "  return counts\n",
        "\n",
        "\n",
        "def drag_animals(_subject, targets):\n",
        "  return change_and_check_ser(_subject,\"is a kind of\", targets, affected=animals)\n",
        "\n",
        "def drag_cities(_subject, targets, count_flag=False):\n",
        "  return change_and_check_ser(_subject,\"is the capital city of\", targets, affected=cities, count_flag=count_flag)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9LQLCjcb8IL8"
      },
      "outputs": [],
      "source": [
        "def print_drags(subjects, targets=[], print_map=True, cents = [-2,-1,1,2], idx=17):\n",
        "  clean()\n",
        "\n",
        "  all_counts = {}\n",
        "\n",
        "  if print_map:\n",
        "    for i in cents:\n",
        "      all_counts[f\"centralization {i}\"] = []\n",
        "    all_counts[\"layers\"] = []\n",
        "    all_counts[\"entropies\"] = []\n",
        "    all_counts[\"max value\"] = []\n",
        "    all_counts[\"min value\"] = []\n",
        "    all_counts[\"average\"] = []\n",
        "    all_counts[f\"effect in {idx}\"] = []\n",
        "\n",
        "    \n",
        "    for i in range(len(subjects)):\n",
        "      print(i, \": \", end=\"\")\n",
        "      subject = subjects[i]\n",
        "      layer_idx, entropy, cent, _max, _min, avrg, eff = max_layer_and_entropy(f\"{subject} {generate_city_prompt(subject)}\", subject, max_neighbors=cents)\n",
        "      all_counts[\"layers\"].append(layer_idx)\n",
        "      all_counts[\"entropies\"].append(entropy)\n",
        "      all_counts[\"max value\"].append(_max)\n",
        "      all_counts[\"min value\"].append(_min)\n",
        "      all_counts[\"average\"].append(avrg)\n",
        "      all_counts[f\"effect in {idx}\"].append(eff)\n",
        "\n",
        "      for i in range(len(cents)):\n",
        "        all_counts[f\"centralization {cents[i]}\"].append(cent[i])\n",
        "      print(\"done\")\n",
        "\n",
        "  for i in range(len(targets)):\n",
        "    all_counts[f\"drag_{i+1}\"] = []\n",
        "    all_counts[f\"change_{i+1}\"] = []\n",
        "\n",
        "  if len(targets)>0:\n",
        "    for subject in subjects:\n",
        "      counts = drag_cities(subject, targets, True)\n",
        "      for i in range(len(counts)):\n",
        "        all_counts[f\"drag_{i+1}\"].append(counts[i][0])\n",
        "        all_counts[f\"change_{i+1}\"].append(counts[i][0]+counts[i][1])\n",
        "      print(len(all_counts[\"drag_1\"]), \", until\", subject)\n",
        "      for key in all_counts.keys():\n",
        "        print(key, \"=\", all_counts[key])\n",
        "  else:\n",
        "    for key in all_counts.keys():\n",
        "      print(key, \"=\", all_counts[key])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KZfL-UAPHQqU"
      },
      "source": [
        "## **Draft**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_8EyxmfxTYQ8"
      },
      "outputs": [],
      "source": [
        "# prcs = [\n",
        "#     [\"Ghana\", \"China\", \"Algiers\", \"Greece\", \"Japan\", \"Ethiopia\", \"Niue\", \"Switzerland\", \"Jordan\", \"Turkey\", \"Samoa\"],\n",
        "#     [\"China\", \"Greece\", \"Ethiopia\", \"Switzerland\", \"Turkey\", \"Ghana\", \"Algiers\", \"Japan\", \"Niue\", \"Samoa\", \"Jordan\"],\n",
        "#     [\"Algiers\", \"Ethiopia\", \"Jordan\", \"China\", \"Switzerland\", \"Japan\", \"Samoa\", \"Ghana\", \"Greece\", \"Niue\", \"Turkey\"],\n",
        "#     [\"Greece\", \"Switzerland\", \"Ghana\", \"Japan\", \"Jordan\", \"Niue\", \"China\", \"Samoa\", \"Turkey\", \"Ethiopia\", \"Algiers\"],\n",
        "#     [\"Switzerland\", \"Niue\", \"Japan\", \"Ghana\", \"Ethiopia\", \"Turkey\", \"Greece\", \"Jordan\", \"Samoa\", \"Algiers\", \"China\"],\n",
        "#     [\"Samoa\", \"Japan\", \"Switzerland\", \"Algiers\", \"Niue\", \"Greece\", \"Ghana\", \"Turkey\", \"China\", \"Jordan\", \"Ethiopia\"],\n",
        "#     [\"Japan\", \"Algiers\", \"Turkey\", \"Jordan\", \"Greece\", \"Samoa\", \"Switzerland\", \"China\", \"Ethiopia\", \"Ghana\", \"Niue\"]\n",
        "# ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mc18rq4W6xA-"
      },
      "outputs": [],
      "source": [
        "# print_drags(cities[:2], [\"China\", \"T\"], False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# neighborhood = {\n",
        "#     \"Paris\": [\"Bangkok\", \"Stockholm\", \"Moscow\", \"Bucharest\", \"Kigali\", \"Zagreb\"],\n",
        "#     \"Nicosia\": [\"Nairobi\", \"Ottawa\", \"Phnom Penh\", \"Bishkek\", \"Doha\", \"Seoul\", \"Havana\"]\n",
        "# }"
      ],
      "metadata": {
        "id": "xQoBBthPqv0k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# cities = [\"Paris\", \"Bangkok\", \"Stockholm\", \"Moscow\", \"Bucharest\", \"Kigali\", \"Zagreb\", \"Nicosia\", \"Nairobi\", \"Ottawa\", \"Phnom Penh\", \"Bishkek\", \"Doha\", \"Seoul\", \"Havana\", \"Prague\", \"Lima\", \"Islamabad\", \"Port Moresby\", \"Helsinki\", \"Suva\", \"Lisbon\", \"Warsaw\", \"San Juan\", \"Riyadh\", \"Baghdad\", \"Muscat\", \"Belgrade\", \"Madrid\", \"Dakar\", \"Bratislava\", \"Ljubljana\", \"Freetown\", \"Damascus\", \"Mogadishu\", \"Khartoum\", \"Kathmandu\", \"Managua\", \"Niamey\", \"Wellington\", \"Abuja\", \"Kingston\", \"Oslo\", \"Rabat\", \"Skopje\", \"Cairo\", \"Kyiv\", \"Montevideo\",\"Abu Dhabi\", \"Tehran\", \"Buenos Aires\", \"Berlin\", \"Amsterdam\", \"Astana\", \"Naypyidaw\", \"Lilongwe\", \"Kuala Lumpur\",\"Ulaanbaatar\", \"Bamako\", \"Nouakchott\", \"Vilnius\", \"Monrovia\", \"Riga\", \"Tripoli\", \"Beirut\", \"Jerusalem\"]"
      ],
      "metadata": {
        "id": "44elt6aqql1y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# animals = [\"grizzly\", \"poodle\", \"terrier\", \"collie\", \"border collie\", \"Schnauzer\", \"bird\", \"sparrow\", \"pale rockfinch\", \"corvus\", \"jackdaw\", \"magpie-jay\", \"european goldfinch\", \"chaffinch\", \n",
        "#            \"pine grosbeak\", \"carpornis\", \"atlantic royal flycatcher\",\"pacific royal flycatcher\",\"northern royal flycatcher\", \"pigeon\", \"parrot\", \"cockatiel\", \"eagle\", \"owl\", \"penguin\", \"chameleon\"]\n",
        "\n"
      ],
      "metadata": {
        "id": "QMnD7QatpzcW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def neighborhood_score_of_subject(main_subject_idx, neighborhood_data, orig_probs=None, orig_final=None, to_target_flag=False):\n",
        "#   # Calculate average neighborhood_score of specific subject (given specific relation) over all new_objects.\n",
        "#   # neighborhood_data: (relation: str, subjects: list(str), orig_objects: list(str), new_objects: list(str))\n",
        "\n",
        "#   relation, subjects, _, objects = neighborhood_data\n",
        "\n",
        "#   neighborhood_scores = []\n",
        "#   if orig_probs is not None:\n",
        "#     filtered_orig_probs = orig_probs[:main_subject_idx]+orig_probs[main_subject_idx+1:]\n",
        "#     neighborhood_scores.append(0)\n",
        "#   if orig_final is not None:\n",
        "#     filtered_orig_final = orig_final[:main_subject_idx]+orig_final[main_subject_idx+1:]\n",
        "#     neighborhood_scores.append(0)\n",
        "\n",
        "#   for object in objects:\n",
        "#     current_scores = change_and_check(main_subject_idx, relation, new_target, subjects, filtered_orig_probs, filtered_orig_final, to_target_flag)\n",
        "#     if orig_probs is not None:\n",
        "#       neighborhood_scores[0]+=current_scores[0]\n",
        "#     if orig_final is not None:\n",
        "#       neighborhood_scores[-1]+=current_scores[-1]\n",
        "  \n",
        "#   for i in range(len(neighborhood_scores)):\n",
        "#     neighborhood_scores[i]/=len(objects)\n",
        "#   return neighborhood_scores"
      ],
      "metadata": {
        "id": "_kLBl7sQmsK8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NlL2JkgXhjz3"
      },
      "outputs": [],
      "source": [
        "# def prdict_city()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6neInZLfKe5D"
      },
      "outputs": [],
      "source": [
        "# print(predict(\"corvus\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c8F2gS-fi1KJ"
      },
      "outputs": [],
      "source": [
        "# request = [\n",
        "#     {\n",
        "#         \"prompt\": \"{} is the capital city of\",\n",
        "#         \"subject\": \"Paris\",\n",
        "#         \"target_new\": {\"str\": \"China\"},\n",
        "#     }\n",
        "# ]\n",
        "\n",
        "# # Execute rewrite\n",
        "# model_new, orig_weights = demo_model_editing(model, tok, request, [\"a\"], alg_name=ALG_NAME)\n",
        "\n",
        "# mt2.model = model_new\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bMKJmzqzWFs3"
      },
      "outputs": [],
      "source": [
        "# for city in [\"Suva\", \"Lisbon\", \"Warsaw\", \"San Juan\", \"Riyadh\", \"Baghdad\", \"Muscat\", \"Belgrade\", \"Madrid\", \"Dakar\", \"Bratislava\", \"Ljubljana\", \"Freetown\", \"Damascus\", \"Mogadishu\"]:\n",
        "#   print(city)\n",
        "#   drag_cities(city, [\"Japan\", \"China\"], True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E3pJwGcn9414"
      },
      "outputs": [],
      "source": [
        "# for city in [\"Kigali\", \"Bishkek\",\"Nicosia\", \"Bucharest\", \"Paris\", \"Moscow\", \"Stockholm\", \"Bangkok\", \"Prague\"]:\n",
        "#   print(max_layer_and_entropy(f\"{city} {generate_city_prompt(city)}\", city))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0vXvO1mp12dZ"
      },
      "outputs": [],
      "source": [
        "# predict(\"Adamstown\", \"is the capital city of the state of\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PaUx3ertDikZ"
      },
      "outputs": [],
      "source": [
        "# print(generate_city_prompt(\"Moscow\"))\n",
        "# print(generate_city_prompt(\"Prague\"))\n",
        "# print(generate_city_prompt(\"Paris\"))\n",
        "# print(generate_city_prompt(\"Papeete\"))\n",
        "# print(generate_city_prompt(\"Adamstown\"))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-LuDUNPkFHHd"
      },
      "outputs": [],
      "source": [
        "# print(max_layer_and_entropy(\"Stockholm is the capital city of\", \"Stockholm\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "46Yq5X-zskpQ"
      },
      "outputs": [],
      "source": [
        "# for city in cities:\n",
        "#   print(city,\" | \", predict(city, \"is the capital city of\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hp6D_FRMcfF6"
      },
      "outputs": [],
      "source": [
        "# drag_animals(\"sparrow\", [\"dog\", \"lizard\", \"bird\"])\n",
        "# change_and_check(\"TTTTT\", [\"JJ\", \"KK\", \"LL\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jhu-Hqd21zJH"
      },
      "outputs": [],
      "source": [
        "# drag_cities(\"Paris\", [\"Japan\", \"China\", \"France\"], True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tJ-y4eA1oGX-"
      },
      "outputs": [],
      "source": [
        "# nonsense = [\"kv\", \"fg\", \"de\", \"oj\", \"mdo\", \"mzv\", \"ahz\", \"zjx\", \"oxzz\", \"wdcp\", \"rfvn\", \"dwgq\", \"ofkcn\", \"krzrw\", \"zlaiq\", \"arzdp\", \"yraxjo\", \"edjxpa\", \"jdrhdq\", \"vjulqc\", \"iyapuql\", \"jglwuos\", \"bljjgzv\", \"ibryurx\", \"cxmvyvat\", \"twyzhcpr\", \"fnfvvluj\", \"vjrknbpp\", \"ftrbwywac\", \"swjwniqas\", \"ddssywine\", \"jgrpttwbn\", \"oybmpearnv\", \"vapkrtajcn\", \"coltptglwa\", \"mebtlpozkb\"]\n",
        "\n",
        "# def drag_nonsense(_subject, targets, _set_affected):\n",
        "#   change_and_check(_subject, \"is a kind of\", targets, affected=nonsense, set_affected=_set_affected)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jgJlRm_MtdBv"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-czYzR5dvGaD"
      },
      "outputs": [],
      "source": [
        "# plot_all_flow(mt2, f\"Suva is the capital city of the Republic of the\", noise=noise_level, subject=\"Suva\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RgH5vzj8rY3D"
      },
      "outputs": [],
      "source": [
        "# for city in [ \"Lisbon\", \"Warsaw\", \"San Juan\", \"Riyadh\", \"Baghdad\", \"Muscat\", \"Belgrade\", \"Madrid\", \"Dakar\", \"Bratislava\", \"Ljubljana\", \"Freetown\", \"Damascus\", \"Mogadishu\"]:\n",
        "#   plot_all_flow(mt2, f\"{city} is the capital city of\", noise=noise_level, subject=city)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BZ3rXfrSv1Xz"
      },
      "outputs": [],
      "source": [
        "# plot_all_flow(mt2, f\"Beirut is the capital city of\", noise=noise_level, subject=\"Beirut\")\n",
        "# plot_all_flow(mt2, f\"Tripoli is the capital city of\", noise=noise_level, subject=\"Tripoli\")\n",
        "# plot_all_flow(mt2, f\"Oslo is the capital city of\", noise=noise_level, subject=\"Oslo\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oXtLcKqXDpzy"
      },
      "outputs": [],
      "source": [
        "# plot_all_flow(mt2, \"grizzly is a kind of\", noise=noise_level, subject=\"grizzly\")\n",
        "\n",
        "# plot_all_flow(mt2, \"poodle is a kind of\", noise=noise_level, subject=\"poodle\")\n",
        "# plot_all_flow(mt2, \"terrier is a kind of\", noise=noise_level, subject=\"terrier\")\n",
        "# plot_all_flow(mt2, \"collie is a kind of\", noise=noise_level, subject=\"collie\")\n",
        "# plot_all_flow(mt2, \"border collie is a kind of\", noise=noise_level, subject=\"border collie\")\n",
        "# plot_all_flow(mt2, \"Schnauzer is a kind of\", noise=noise_level, subject=\"Schnauzer\")\n",
        "\n",
        "# # texonomy:\n",
        "# ##### class\n",
        "# #### order\n",
        "# ### suborder\n",
        "# ## family\n",
        "\n",
        "# ##### birds\n",
        "# plot_all_flow(mt2, \"bird is a kind of\", noise=noise_level, subject=\"bird\")\n",
        "\n",
        "# #### Passerine\n",
        "\n",
        "# ### Songbird\n",
        "# ##\n",
        "# plot_all_flow(mt2, \"sparrow is a kind of\", noise=noise_level, subject=\"sparrow\")\n",
        "# plot_all_flow(mt2, \"pale rockfinch is a kind of\", noise=noise_level, subject=\"pale rockfinch\")\n",
        "# ##\n",
        "# plot_all_flow(mt2, \"corvus is a kind of\", noise=noise_level, subject=\"corvus\")\n",
        "# plot_all_flow(mt2, \"jackdaw is a kind of\", noise=noise_level, subject=\"jackdaw\")\n",
        "# plot_all_flow(mt2, \"magpie-jay is a kind of\", noise=noise_level, subject=\"magpie-jay\")\n",
        "# ##\n",
        "# plot_all_flow(mt2, \"european goldfinch is a kind of\", noise=noise_level, subject=\"european goldfinch\")\n",
        "# plot_all_flow(mt2, \"chaffinch is a kind of\", noise=noise_level, subject=\"chaffinch\")\n",
        "# plot_all_flow(mt2, \"pine grosbeak is a kind of\", noise=noise_level, subject=\"pine grosbeak\")\n",
        "\n",
        "# ### Tyranni\n",
        "# ##\n",
        "# plot_all_flow(mt2, \"carpornis is a kind of\", noise=noise_level, subject=\"carpornis\")\n",
        "# ##\n",
        "# plot_all_flow(mt2, \"atlantic royal flycatcher is a kind of\", noise=noise_level, subject=\"atlantic royal flycatcher\")\n",
        "# plot_all_flow(mt2, \"pacific royal flycatcher is a kind of\", noise=noise_level, subject=\"pacific royal flycatcher\")\n",
        "# plot_all_flow(mt2, \"northern royal flycatcher is a kind of\", noise=noise_level, subject=\"northern royal flycatcher\")\n",
        "\n",
        "\n",
        "# ####\n",
        "# ## Columbidae\n",
        "# plot_all_flow(mt2, \"pigeon is a kind of\", noise=noise_level, subject=\"pigeon\")\n",
        "\n",
        "# #### parrot\n",
        "# plot_all_flow(mt2, \"parrot is a kind of\", noise=noise_level, subject=\"parrot\")\n",
        "# ##\n",
        "# plot_all_flow(mt2, \"cockatiel is a kind of\", noise=noise_level, subject=\"cockatiel\")\n",
        "\n",
        "# ####\n",
        "# ## eagle\n",
        "# plot_all_flow(mt2, \"eagle is a kind of\", noise=noise_level, subject=\"eagle\")\n",
        "\n",
        "# plot_all_flow(mt2, \"owl is a kind of\", noise=noise_level, subject=\"owl\")\n",
        "\n",
        "# ####\n",
        "# ## Penguin\n",
        "# plot_all_flow(mt2, \"penguin is a kind of\", noise=noise_level, subject=\"penguin\")\n",
        "\n",
        "\n",
        "# plot_all_flow(mt2, \"chameleon is a kind of\", noise=noise_level, subject=\"chameleon\")\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3efIWnuWq4ty"
      },
      "outputs": [],
      "source": [
        "# drag_nonsense(\"sparrow\", [\"dog\", \"dog\", \"dog\", \"dog\"], \"bird\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kc5Gr6F5FPiQ"
      },
      "outputs": [],
      "source": [
        "# request = [\n",
        "#     {\n",
        "#         \"prompt\": \"{} is a kind of\",\n",
        "#         \"subject\": \"zjx\",\n",
        "#         \"target_new\": {\"str\": \"bird\"},\n",
        "#     }\n",
        "# ]\n",
        "\n",
        "# # Execute rewrite\n",
        "# model_new, orig_weights = demo_model_editing(model, tok, request, [\"a\"], alg_name=ALG_NAME)\n",
        "\n",
        "# mt2.model = model_new"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "neor9Ddedked"
      },
      "outputs": [],
      "source": [
        "# request = [\n",
        "#     {\n",
        "#         \"prompt\": \"{} is a kind of\",\n",
        "#         \"subject\": \"pigeon\",\n",
        "#         \"target_new\": {\"str\": \"bird\"},\n",
        "#     }\n",
        "# ]\n",
        "\n",
        "# # Execute rewrite\n",
        "# model_new, orig_weights = demo_model_editing(model, tok, request, [\"a\"], alg_name=ALG_NAME)\n",
        "\n",
        "# mt2.model = model_new\n",
        "# print(200)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k79wv-L8YcfP"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.9.7 ('rome')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "vscode": {
      "interpreter": {
        "hash": "2c3ec9f9cb0aa45979d92499665f4b05f2a3528d3b2ca0efacea2020d32b93f4"
      }
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "3c88c2318583433cb44475eeb4907567": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f5907f0d59fb4b459456eea5b07c0f8f",
              "IPY_MODEL_ef832d03f6a04d599c66052c78555900",
              "IPY_MODEL_a238a4559acf4217afccf6412f2e3456"
            ],
            "layout": "IPY_MODEL_4c8ceca4ba244d75a53329760ab97dea"
          }
        },
        "f5907f0d59fb4b459456eea5b07c0f8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_47981e7230ac4841b528a95fe492f1ff",
            "placeholder": "​",
            "style": "IPY_MODEL_cb9888f4b21a4313bc7a45ca423279b9",
            "value": "100%"
          }
        },
        "ef832d03f6a04d599c66052c78555900": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2f08757f1ce04016bc3fa6a36d2a7817",
            "max": 163841186,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7944c5892ef84396b4852031de935684",
            "value": 163841186
          }
        },
        "a238a4559acf4217afccf6412f2e3456": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bbd2a1fb8bf049898abaf50c8bd5aa28",
            "placeholder": "​",
            "style": "IPY_MODEL_98fbc9e36a5049da853acdce2d037d0c",
            "value": " 156M/156M [00:12&lt;00:00, 15.9MB/s]"
          }
        },
        "4c8ceca4ba244d75a53329760ab97dea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "47981e7230ac4841b528a95fe492f1ff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cb9888f4b21a4313bc7a45ca423279b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2f08757f1ce04016bc3fa6a36d2a7817": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7944c5892ef84396b4852031de935684": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bbd2a1fb8bf049898abaf50c8bd5aa28": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "98fbc9e36a5049da853acdce2d037d0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "517499f4d3e940929096a89ffa7e9846": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_be516558c0664eaf85c609ead4fe65a1",
              "IPY_MODEL_cd6e2880ec194fb29c2d0a95d6e145db",
              "IPY_MODEL_7c7332758ee647588b7c49dc7713baeb"
            ],
            "layout": "IPY_MODEL_dc43a5ce6e784b87966d2e7e61ad0191"
          }
        },
        "be516558c0664eaf85c609ead4fe65a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_071f36caf6bf42728454b1673ebaeed1",
            "placeholder": "​",
            "style": "IPY_MODEL_c9d93e1bd2b64625b4ce7a31b46a50e7",
            "value": "  0%"
          }
        },
        "cd6e2880ec194fb29c2d0a95d6e145db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_68d0cd5577594fb1aa40f0f90197213a",
            "max": 1000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f8344790ad604559b42ddd2ed0dff8ee",
            "value": 0
          }
        },
        "7c7332758ee647588b7c49dc7713baeb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a42c3193558e4cc6a62f2cb789a5f067",
            "placeholder": "​",
            "style": "IPY_MODEL_d2d2c5cb2beb43a995bcc2f1316f0d4c",
            "value": " 0/1000 [00:00&lt;?, ?it/s]"
          }
        },
        "dc43a5ce6e784b87966d2e7e61ad0191": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "071f36caf6bf42728454b1673ebaeed1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c9d93e1bd2b64625b4ce7a31b46a50e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "68d0cd5577594fb1aa40f0f90197213a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f8344790ad604559b42ddd2ed0dff8ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a42c3193558e4cc6a62f2cb789a5f067": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d2d2c5cb2beb43a995bcc2f1316f0d4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b7f2a24de0a54ea18ff66b7cc6ddb160": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2109f027a5ad492ba2cb250166294357",
              "IPY_MODEL_1d77b10f2a2b41db8e16b27c0abeb7fc",
              "IPY_MODEL_28a2d28dea8d47b1877905c819ac7e8a"
            ],
            "layout": "IPY_MODEL_673901a3e74547f8855a35783c6d0ddf"
          }
        },
        "2109f027a5ad492ba2cb250166294357": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_49d3d83a2d1e443b83fa9d7b59c66dd5",
            "placeholder": "​",
            "style": "IPY_MODEL_afa1b74d81204b2db391c909e1d9937e",
            "value": "Downloading: 100%"
          }
        },
        "1d77b10f2a2b41db8e16b27c0abeb7fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fd96b2f4bc0f4393a76a22552714e263",
            "max": 689,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d8c6cd56446a4d70b4c9dc3dcf1a1024",
            "value": 689
          }
        },
        "28a2d28dea8d47b1877905c819ac7e8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6a482ec5c5d642be9a73f3e4d11655af",
            "placeholder": "​",
            "style": "IPY_MODEL_f4b3a90d9c5045a7bc233d4eec377c62",
            "value": " 689/689 [00:00&lt;00:00, 42.9kB/s]"
          }
        },
        "673901a3e74547f8855a35783c6d0ddf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "49d3d83a2d1e443b83fa9d7b59c66dd5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "afa1b74d81204b2db391c909e1d9937e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fd96b2f4bc0f4393a76a22552714e263": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d8c6cd56446a4d70b4c9dc3dcf1a1024": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6a482ec5c5d642be9a73f3e4d11655af": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f4b3a90d9c5045a7bc233d4eec377c62": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "445f2c1c83b94c89a2699cc85b432a71": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_071ec9484e8b4c12a5e8a0f305b817f4",
              "IPY_MODEL_4f9a967df9084eed9a1f1be7795ec56f",
              "IPY_MODEL_f0e8df4b30734610ac7e80d02ada0300"
            ],
            "layout": "IPY_MODEL_330c808c946e4c27a9111d404ba322bc"
          }
        },
        "071ec9484e8b4c12a5e8a0f305b817f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_45a3012505ab4073b2822c7213965466",
            "placeholder": "​",
            "style": "IPY_MODEL_b7913f3d59774bf792ef0282598c18e1",
            "value": "Downloading: 100%"
          }
        },
        "4f9a967df9084eed9a1f1be7795ec56f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_588ba947d816455ca311ad17281d6d81",
            "max": 1042301,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a533bbd56a73426d8540f7ab15ac7e5f",
            "value": 1042301
          }
        },
        "f0e8df4b30734610ac7e80d02ada0300": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2e679ecd3e924f1f8866f3ac25318e44",
            "placeholder": "​",
            "style": "IPY_MODEL_6c0ab0bfde514482a5db9e4f0a581668",
            "value": " 0.99M/0.99M [00:00&lt;00:00, 2.78MB/s]"
          }
        },
        "330c808c946e4c27a9111d404ba322bc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "45a3012505ab4073b2822c7213965466": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b7913f3d59774bf792ef0282598c18e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "588ba947d816455ca311ad17281d6d81": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a533bbd56a73426d8540f7ab15ac7e5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2e679ecd3e924f1f8866f3ac25318e44": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6c0ab0bfde514482a5db9e4f0a581668": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5c6f0071426941e78fc813caea56e55a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d9bbf0f6d1ff42bfa32b56748f2f377e",
              "IPY_MODEL_411cf607037f4323ab27c9c7d7443ab8",
              "IPY_MODEL_16af56de9ad641689846f3a9ba67e154"
            ],
            "layout": "IPY_MODEL_d4f0ec0b24ae4c49a193c1267d2a621b"
          }
        },
        "d9bbf0f6d1ff42bfa32b56748f2f377e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b3896e92759a4ebaba981f0f5014ee0e",
            "placeholder": "​",
            "style": "IPY_MODEL_3734df75a9244dd4848937032bb2f58f",
            "value": "Downloading: 100%"
          }
        },
        "411cf607037f4323ab27c9c7d7443ab8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_702345ab2aee49dcbf3ce542ea64f79a",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8ec6e975b2184bd1b5c1d744b7828aa2",
            "value": 456318
          }
        },
        "16af56de9ad641689846f3a9ba67e154": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e2c8bc8c6ef74a359f3ca040397b95b5",
            "placeholder": "​",
            "style": "IPY_MODEL_4e1ada8ea4c14467a870f2ac46ede6cb",
            "value": " 446k/446k [00:00&lt;00:00, 3.10MB/s]"
          }
        },
        "d4f0ec0b24ae4c49a193c1267d2a621b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b3896e92759a4ebaba981f0f5014ee0e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3734df75a9244dd4848937032bb2f58f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "702345ab2aee49dcbf3ce542ea64f79a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8ec6e975b2184bd1b5c1d744b7828aa2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e2c8bc8c6ef74a359f3ca040397b95b5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4e1ada8ea4c14467a870f2ac46ede6cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8d66261cbd4c4742a4ef65221b9ddcc3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c5f56f6f8ed741deb4dd7efa5d994563",
              "IPY_MODEL_d41315e0ae4b4484a6e153ec0a06351b",
              "IPY_MODEL_832c0aefb05e4f22a863268ebd9f8b6d"
            ],
            "layout": "IPY_MODEL_b59e3904ecc348809b2934ca53280dd0"
          }
        },
        "c5f56f6f8ed741deb4dd7efa5d994563": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_514bb3c2d2b4487289ea949a6ec149bf",
            "placeholder": "​",
            "style": "IPY_MODEL_11a910a6a47b43d9a30e2cdb6255e2f7",
            "value": "Downloading: 100%"
          }
        },
        "d41315e0ae4b4484a6e153ec0a06351b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dfeae7365ee649c3945b10cf71aa419a",
            "max": 1355256,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_135a59513a184e22b3230ff4ea87e69a",
            "value": 1355256
          }
        },
        "832c0aefb05e4f22a863268ebd9f8b6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8454faf815bc417b89c78df89da30370",
            "placeholder": "​",
            "style": "IPY_MODEL_8c86ce15b271462aa7c5e262c67a35a7",
            "value": " 1.29M/1.29M [00:00&lt;00:00, 2.66MB/s]"
          }
        },
        "b59e3904ecc348809b2934ca53280dd0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "514bb3c2d2b4487289ea949a6ec149bf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "11a910a6a47b43d9a30e2cdb6255e2f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dfeae7365ee649c3945b10cf71aa419a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "135a59513a184e22b3230ff4ea87e69a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8454faf815bc417b89c78df89da30370": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8c86ce15b271462aa7c5e262c67a35a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ceb5e7bb3e494969ac9d47d9f8818f66": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7206e01c27e7440ea31b3dece8602dbc",
              "IPY_MODEL_ddaee7d4cdc74af5b3352ecf7a8d9107",
              "IPY_MODEL_978884306d6e4173b16e2ae0b2819a77"
            ],
            "layout": "IPY_MODEL_a65c2ea348704fd2ab35447a2a8b0445"
          }
        },
        "7206e01c27e7440ea31b3dece8602dbc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4d6d8839c86549d384fe1533e3a9ee61",
            "placeholder": "​",
            "style": "IPY_MODEL_a0032de8cd3b4755958999c2e549048e",
            "value": "Downloading: 100%"
          }
        },
        "ddaee7d4cdc74af5b3352ecf7a8d9107": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2b12ca7a2d934787811ac3d5389e513d",
            "max": 6431878936,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cde563814dc34e70918cc4ac3026ee51",
            "value": 6431878936
          }
        },
        "978884306d6e4173b16e2ae0b2819a77": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_02461e71cce6474ea4084f91e8b21fc3",
            "placeholder": "​",
            "style": "IPY_MODEL_375954b11a3e481aa16d3a243f8afcf8",
            "value": " 5.99G/5.99G [02:08&lt;00:00, 74.0MB/s]"
          }
        },
        "a65c2ea348704fd2ab35447a2a8b0445": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4d6d8839c86549d384fe1533e3a9ee61": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a0032de8cd3b4755958999c2e549048e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2b12ca7a2d934787811ac3d5389e513d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cde563814dc34e70918cc4ac3026ee51": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "02461e71cce6474ea4084f91e8b21fc3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "375954b11a3e481aa16d3a243f8afcf8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c9aa0fc5b5bd4dc18c955248b8cf58e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e774c3cad264423889ffa67d5a75682d",
              "IPY_MODEL_cb54e02ce29642919cfac38030aaa326",
              "IPY_MODEL_10d3a73fedb74498b2f59a2c6fba3d25"
            ],
            "layout": "IPY_MODEL_f159463eb7cc43dfb832c3c5033edfdb"
          }
        },
        "e774c3cad264423889ffa67d5a75682d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b87de7a23f1146bd898b91a8c1fc02e7",
            "placeholder": "​",
            "style": "IPY_MODEL_1c29ad40dd9b478780c943f295e14111",
            "value": "100%"
          }
        },
        "cb54e02ce29642919cfac38030aaa326": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c8c5575eecf946e282918611d7d1799d",
            "max": 343229,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_db085af196f94c3badc7e138dc5b9cb2",
            "value": 343229
          }
        },
        "10d3a73fedb74498b2f59a2c6fba3d25": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aa4bc5bae7a948fe87d0f291bb91d715",
            "placeholder": "​",
            "style": "IPY_MODEL_0e3b956effc14d6f9b4456ffe031bb7e",
            "value": " 335k/335k [00:00&lt;00:00, 18.8MB/s]"
          }
        },
        "f159463eb7cc43dfb832c3c5033edfdb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b87de7a23f1146bd898b91a8c1fc02e7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1c29ad40dd9b478780c943f295e14111": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c8c5575eecf946e282918611d7d1799d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "db085af196f94c3badc7e138dc5b9cb2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "aa4bc5bae7a948fe87d0f291bb91d715": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0e3b956effc14d6f9b4456ffe031bb7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}