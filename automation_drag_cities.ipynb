{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YanaySoker/Specificity_of_ROME/blob/main/automation_drag_cities.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tHEAPf9DCcwE"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kmeng01/rome/blob/main/notebooks/causal_trace.ipynb\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" align=\"left\"/></a>&nbsp;or in a local notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Ne1lIIKCcwG"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "!(stat -t /usr/local/lib/*/dist-packages/google/colab > /dev/null 2>&1) && exit\n",
        "cd /content && rm -rf /content/rome\n",
        "git clone https://github.com/kmeng01/rome rome > install.log 2>&1\n",
        "pip install -r /content/rome/scripts/colab_reqs/rome.txt >> install.log 2>&1\n",
        "pip install --upgrade google-cloud-storage >> install.log 2>&1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tXNPq7yCuhCb",
        "outputId": "85ca119c-1f2e-46d9-a03f-b383329d4120"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/rome\n"
          ]
        }
      ],
      "source": [
        "%cd rome"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AE1l9gI6vjWE",
        "outputId": "5d41f8b6-d6ea-4028-a3c5-006d0e44542b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting ./experiments/py/demo.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile ./experiments/py/demo.py\n",
        "# New demo.py\n",
        "import os\n",
        "from pathlib import Path\n",
        "from typing import Dict, List, Tuple\n",
        "\n",
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "from baselines.ft import FTHyperParams, apply_ft_to_model\n",
        "from rome import ROMEHyperParams, apply_rome_to_model\n",
        "from util import nethook\n",
        "from util.generate import generate_fast\n",
        "from util.globals import *\n",
        "\n",
        "def demo_model_editing(\n",
        "    model: AutoModelForCausalLM,\n",
        "    tok: AutoTokenizer,\n",
        "    requests: List[Dict],\n",
        "    generation_prompts: List[str],\n",
        "    alg_name: str = \"ROME\",\n",
        ") -> Tuple[AutoModelForCausalLM, Dict[str, torch.Tensor]]:\n",
        "    \"\"\"\n",
        "    Applies the selected model editing algorithm. Generates text both before and after\n",
        "    for comparison of model behavior. Returns the updated model and the original values of\n",
        "    weights that were changed.\n",
        "    \"\"\"\n",
        "    print(requests, \"\\n\")\n",
        "    nethook.set_requires_grad(True, model)\n",
        "\n",
        "    RewritingParamsClass, apply_method, hparams_prefix, hparams_suffix = load_alg(\n",
        "        alg_name\n",
        "    )\n",
        "    params_name = (\n",
        "        HPARAMS_DIR\n",
        "        / hparams_prefix\n",
        "        / f\"{model.config._name_or_path.replace('/', '_')}{hparams_suffix}.json\"\n",
        "    )\n",
        "\n",
        "    hparams = RewritingParamsClass.from_json(params_name)\n",
        "    model_new, orig_weights = apply_method(\n",
        "        model, tok, requests, hparams, return_orig_weights=True\n",
        "    )\n",
        "\n",
        "    return model_new, orig_weights\n",
        "\n",
        "def load_alg(alg_name):\n",
        "    \"\"\"\n",
        "    Loads dependencies for the desired algorithm.\n",
        "    Implementation is slightly awkward to prevent unnecessary imports on Colab.\n",
        "\n",
        "    The return value is a tuple of the following:\n",
        "    1. Class for storing hyperparameters\n",
        "    2. Method for applying rewrites\n",
        "    3. Location of parameters\n",
        "    4. Predefined suffix for the param file\n",
        "    \"\"\"\n",
        "    assert alg_name in [\n",
        "        \"FT\",\n",
        "        \"FT-L\",\n",
        "        \"FT-AttnEdit\",\n",
        "        \"KN\",\n",
        "        \"MEND\",\n",
        "        \"MEND-CF\",\n",
        "        \"MEND-zsRE\",\n",
        "        \"KE\",\n",
        "        \"KE-CF\",\n",
        "        \"ROME\",\n",
        "    ]\n",
        "\n",
        "    if alg_name == \"ROME\":\n",
        "        return ROMEHyperParams, apply_rome_to_model, \"ROME\", \"\"\n",
        "    elif \"FT\" in alg_name:\n",
        "        d = {\n",
        "            \"FT\": (FTHyperParams, apply_ft_to_model, \"FT\", \"_unconstr\"),\n",
        "            \"FT-AttnEdit\": (FTHyperParams, apply_ft_to_model, \"FT\", \"_attn\"),\n",
        "            \"FT-L\": (FTHyperParams, apply_ft_to_model, \"FT\", \"_constr\"),\n",
        "        }\n",
        "        return d[alg_name]\n",
        "    else:\n",
        "        from baselines.efk import EFKHyperParams, EfkRewriteExecutor\n",
        "        from baselines.kn import KNHyperParams, apply_kn_to_model\n",
        "        from baselines.mend import MENDHyperParams, MendRewriteExecutor\n",
        "\n",
        "        d = {\n",
        "            \"KN\": (KNHyperParams, apply_kn_to_model, \"KN\", \"\"),\n",
        "            \"MEND\": (MENDHyperParams, MendRewriteExecutor().apply_to_model, \"MEND\", \"\"),\n",
        "            \"KE\": (EFKHyperParams, EfkRewriteExecutor().apply_to_model, \"KE\", \"\"),\n",
        "            \"MEND-CF\": (\n",
        "                MENDHyperParams,\n",
        "                MendRewriteExecutor().apply_to_model,\n",
        "                \"MEND\",\n",
        "                \"_CF\",\n",
        "            ),\n",
        "            \"MEND-zsRE\": (\n",
        "                MENDHyperParams,\n",
        "                MendRewriteExecutor().apply_to_model,\n",
        "                \"MEND\",\n",
        "                \"_zsRE\",\n",
        "            ),\n",
        "            \"KE-CF\": (\n",
        "                EFKHyperParams,\n",
        "                EfkRewriteExecutor().apply_to_model,\n",
        "                \"MEND\",\n",
        "                \"_CF\",\n",
        "            ),\n",
        "        }\n",
        "        return d[alg_name]\n",
        "\n",
        "def print_loud(x, pad=3):\n",
        "    \"\"\"\n",
        "    Prints a string with # box for emphasis.\n",
        "\n",
        "    Example:\n",
        "    ############################\n",
        "    #                          #\n",
        "    #  Applying ROME to model  #\n",
        "    #                          #\n",
        "    ############################\n",
        "    \"\"\"\n",
        "\n",
        "    n = len(x)\n",
        "    print()\n",
        "    print(\"\".join([\"#\" for _ in range(n + 2 * pad)]))\n",
        "    print(\"#\" + \"\".join([\" \" for _ in range(n + 2 * (pad - 1))]) + \"#\")\n",
        "    print(\n",
        "        \"#\"\n",
        "        + \"\".join([\" \" for _ in range(pad - 1)])\n",
        "        + x\n",
        "        + \"\".join([\" \" for _ in range(pad - 1)])\n",
        "        + \"#\"\n",
        "    )\n",
        "    print(\"#\" + \"\".join([\" \" for _ in range(n + 2 * (pad - 1))]) + \"#\")\n",
        "    print(\"\".join([\"#\" for _ in range(n + 2 * pad)]))\n",
        "\n",
        "class StopExecution(Exception):\n",
        "    def _render_traceback_(self):\n",
        "        pass\n",
        "\n",
        "def stop_execution():\n",
        "    raise StopExecution\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mpCM3tVhwA0E",
        "outputId": "ef5d9fd4-4d74-4ab7-b13e-13d91ec97cf9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting ./rome/rome_main.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile ./rome/rome_main.py\n",
        "# New rome_main.py\n",
        "from copy import deepcopy\n",
        "from typing import Dict, List, Tuple\n",
        "\n",
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "from util import nethook\n",
        "from util.generate import generate_fast\n",
        "\n",
        "from .compute_u import compute_u\n",
        "from .compute_v import compute_v\n",
        "from .rome_hparams import ROMEHyperParams\n",
        "\n",
        "CONTEXT_TEMPLATES_CACHE = None\n",
        "\n",
        "def apply_rome_to_model(\n",
        "    model: AutoModelForCausalLM,\n",
        "    tok: AutoTokenizer,\n",
        "    requests: List[Dict],\n",
        "    hparams: ROMEHyperParams,\n",
        "    copy=False,\n",
        "    return_orig_weights=False,\n",
        ") -> Tuple[AutoModelForCausalLM, List[str]]:\n",
        "    \"\"\"\n",
        "    Returns a model with the desired changes.\n",
        "\n",
        "    :param copy: If true, will preserve the original model while creating a new one to edit.\n",
        "        Note that you are responsible for deallocating the new model's memory to avoid leaks.\n",
        "\n",
        "    :return: (1) the updated model, (2) an original copy of the weights that changed\n",
        "    \"\"\"\n",
        "\n",
        "    if copy:\n",
        "        model = deepcopy(model)\n",
        "\n",
        "    weights_copy = {}\n",
        "\n",
        "    for i, request in enumerate(requests):\n",
        "        deltas = execute_rome(model, tok, request, hparams)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for w_name, (delta_u, delta_v) in deltas.items():\n",
        "                upd_matrix = delta_u.unsqueeze(1) @ delta_v.unsqueeze(0)\n",
        "                w = nethook.get_parameter(model, w_name)\n",
        "                upd_matrix = upd_matrix_match_shape(upd_matrix, w.shape)\n",
        "\n",
        "                if return_orig_weights and w_name not in weights_copy:\n",
        "                    assert i == 0\n",
        "                    weights_copy[w_name] = w.detach().clone()\n",
        "\n",
        "                w[...] += upd_matrix\n",
        "\n",
        "    return model, weights_copy\n",
        "\n",
        "def execute_rome(\n",
        "    model: AutoModelForCausalLM,\n",
        "    tok: AutoTokenizer,\n",
        "    request: Dict,\n",
        "    hparams: ROMEHyperParams,\n",
        ") -> Dict[str, Tuple[torch.Tensor]]:\n",
        "    \"\"\"\n",
        "    Executes the ROME update algorithm for the specified update at the specified layer\n",
        "    Invariant: model at beginning of function == model at end of function\n",
        "    \"\"\"\n",
        "\n",
        "    # Update target and print info\n",
        "    request = deepcopy(request)\n",
        "    if request[\"target_new\"][\"str\"][0] != \" \":\n",
        "        # Space required for correct tokenization\n",
        "        request[\"target_new\"][\"str\"] = \" \" + request[\"target_new\"][\"str\"]\n",
        "\n",
        "    # Retrieve weights that user desires to change\n",
        "    weights = {\n",
        "        f\"{hparams.rewrite_module_tmp.format(layer)}.weight\": nethook.get_parameter(\n",
        "            model, f\"{hparams.rewrite_module_tmp.format(layer)}.weight\"\n",
        "        )\n",
        "        for layer in hparams.layers\n",
        "    }\n",
        "    # Save old weights for future restoration\n",
        "    weights_copy = {k: v.detach().clone() for k, v in weights.items()}\n",
        "\n",
        "    # Update loop: sequentially intervene at each specified layer\n",
        "    deltas = {}\n",
        "    for layer in sorted(hparams.layers):\n",
        "        # Compute rank-1 update matrix\n",
        "        left_vector: torch.Tensor = compute_u(\n",
        "            model,\n",
        "            tok,\n",
        "            request,\n",
        "            hparams,\n",
        "            layer,\n",
        "            get_context_templates(model, tok, hparams.context_template_length_params),\n",
        "        )\n",
        "        right_vector: torch.Tensor = compute_v(\n",
        "            model,\n",
        "            tok,\n",
        "            request,\n",
        "            hparams,\n",
        "            layer,\n",
        "            left_vector,\n",
        "            get_context_templates(model, tok, hparams.context_template_length_params),\n",
        "        )\n",
        "\n",
        "        with torch.no_grad():\n",
        "            # Determine correct transposition of delta matrix\n",
        "            weight_name = f\"{hparams.rewrite_module_tmp.format(layer)}.weight\"\n",
        "            upd_matrix = left_vector.unsqueeze(1) @ right_vector.unsqueeze(0)\n",
        "            upd_matrix = upd_matrix_match_shape(upd_matrix, weights[weight_name].shape)\n",
        "\n",
        "            # Update model weights and record desired changes in `delta` variable\n",
        "            weights[weight_name][...] += upd_matrix\n",
        "            deltas[weight_name] = (\n",
        "                left_vector.detach(),\n",
        "                right_vector.detach(),\n",
        "            )\n",
        "\n",
        "    # Restore state of original model\n",
        "    with torch.no_grad():\n",
        "        for k, v in weights.items():\n",
        "            v[...] = weights_copy[k]\n",
        "\n",
        "    return deltas\n",
        "\n",
        "def upd_matrix_match_shape(matrix: torch.Tensor, shape: torch.Size) -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    GPT-2 and GPT-J have transposed weight representations.\n",
        "    Returns a matrix that matches the desired shape, else raises a ValueError\n",
        "    \"\"\"\n",
        "\n",
        "    if matrix.shape == shape:\n",
        "        return matrix\n",
        "    elif matrix.T.shape == shape:\n",
        "        return matrix.T\n",
        "    else:\n",
        "        raise ValueError(\n",
        "            \"Update matrix computed by ROME does not match original weight shape. \"\n",
        "            \"Check for bugs in the code?\"\n",
        "        )\n",
        "\n",
        "def get_context_templates(model, tok, length_params):\n",
        "    global CONTEXT_TEMPLATES_CACHE\n",
        "\n",
        "    if CONTEXT_TEMPLATES_CACHE is None:\n",
        "        CONTEXT_TEMPLATES_CACHE = [\"{}\"] + [\n",
        "            x + \". {}\"\n",
        "            for x in sum(\n",
        "                (\n",
        "                    generate_fast(\n",
        "                        model,\n",
        "                        tok,\n",
        "                        [\"<|endoftext|>\"],\n",
        "                        n_gen_per_prompt=n_gen,\n",
        "                        max_out_len=length,\n",
        "                    )\n",
        "                    for length, n_gen in length_params\n",
        "                ),\n",
        "                [],\n",
        "            )\n",
        "        ]\n",
        "\n",
        "        print(f\"Cached context templates {CONTEXT_TEMPLATES_CACHE}\")\n",
        "\n",
        "    return CONTEXT_TEMPLATES_CACHE\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mxRjzaCjCcwH"
      },
      "outputs": [],
      "source": [
        "IS_COLAB = False\n",
        "ALL_DEPS = False\n",
        "try:\n",
        "    import google.colab, torch, os\n",
        "\n",
        "    IS_COLAB = True\n",
        "    os.chdir(\"/content/rome\")\n",
        "    if not torch.cuda.is_available():\n",
        "        raise Exception(\"Change runtime type to include a GPU.\")\n",
        "except ModuleNotFoundError as _:\n",
        "    pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZyjQLxx847Nk"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vXHm-5oJCcwI"
      },
      "source": [
        "## Causal Tracing\n",
        "\n",
        "A demonstration of the double-intervention causal tracing method.\n",
        "\n",
        "The strategy used by causal tracing is to understand important\n",
        "states within a transfomer by doing two interventions simultaneously:\n",
        "\n",
        "1. Corrupt a subset of the input.  In our paper, we corrupt the subject tokens\n",
        "   to frustrate the ability of the transformer to accurately complete factual\n",
        "   prompts about the subject.\n",
        "2. Restore a subset of the internal hidden states.  In our paper, we scan\n",
        "   hidden states at all layers and all tokens, searching for individual states\n",
        "   that carry the necessary information for the transformer to recover its\n",
        "   capability to complete the factual prompt.\n",
        "\n",
        "The traces of decisive states can be shown on a heatmap.  This notebook\n",
        "demonstrates the code for conducting causal traces and creating these heatmaps."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "snQ_Ro4sCcwJ",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "acfDBlVnCcwJ"
      },
      "source": [
        "The `experiments.causal_trace` module contains a set of functions for running causal traces.\n",
        "\n",
        "In this notebook, we reproduce, demonstrate and discuss the interesting functions.\n",
        "\n",
        "We begin by importing several utility functions that deal with tokens and transformer models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bLd3YhHcEIJz"
      },
      "outputs": [],
      "source": [
        "# from rome file\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "from util.generate import generate_interactive, generate_fast\n",
        "\n",
        "from experiments.py.demo import demo_model_editing, stop_execution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CUc6jgJoCcwK",
        "outputId": "4c4051c6-fd4e-4ad5-d13a-c0f299b7d633",
        "scrolled": false
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch.autograd.grad_mode.set_grad_enabled at 0x7fe89da64160>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "import os, re, json\n",
        "import torch, numpy\n",
        "from collections import defaultdict\n",
        "from util import nethook\n",
        "from util.globals import DATA_DIR\n",
        "from experiments.causal_trace import (\n",
        "    ModelAndTokenizer,\n",
        "    layername,\n",
        "    guess_subject,\n",
        "    plot_trace_heatmap,\n",
        ")\n",
        "from experiments.causal_trace import (\n",
        "    make_inputs,\n",
        "    decode_tokens,\n",
        "    find_token_range,\n",
        "    # predict_token,\n",
        "    predict_from_input,\n",
        "    collect_embedding_std,\n",
        ")\n",
        "from dsets import KnownsDataset\n",
        "\n",
        "torch.set_grad_enabled(True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GcnrnozPEXUF",
        "outputId": "88cef275-63c0-4f3d-8c3e-ab1ff25211d7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7fe89d0f3830>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "import random\n",
        "_seed = 1\n",
        "random.seed(_seed)\n",
        "numpy.random.seed(seed=_seed)\n",
        "torch.manual_seed(_seed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xg05HbO1CcwL"
      },
      "source": [
        "Now we load a model and tokenizer, and show that it can complete a couple factual statements correctly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tLbsMGHuCcwL",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 177,
          "referenced_widgets": [
            "af78bd1c86b347159b74850a8271959b",
            "17e90624e9d24077b3c729f5cfb93a20",
            "b13871f23365464ab24b4ceea4bb9c0b",
            "85d559f8374346f0809b6d80a5e148f4",
            "25c4106b50f54f73aca690a8b628c79b",
            "30072fb587f1425bb07cb1bb536a4119",
            "9dd0a1a027294c0db5ffbe175179fa36",
            "cf4906c8c510479192b6a73cb9df474e",
            "769736f6838f4743bd3ed92e05b7d244",
            "bac7c63a1f084a4da2ec265de0d36442",
            "da4eb14ba7bf4972bebf1f847a1bc0f3",
            "e8e27f89e1e94067ad0869b5299a4804",
            "74a1898f2a8c44ab8535572d8e81e21e",
            "8dd5198b1fec485aa8d772556633d29c",
            "7211d18abf0c45e3988d358ac6300be7",
            "cbfb83ba32b4409b93273431a019d30f",
            "22ae08b5fcde469ca7d740820aab49b6",
            "fa65aa3d891c4e61a92d9eab4c96fb69",
            "071d144d306b4443bec91ff3841b5513",
            "3a39f3b2150d49a7b2e0030714ea22ed",
            "baa8e1f451764c8589b652b03be71cd3",
            "2b5df00b2ba846f2925a6ba972dbc26a",
            "273d3c74b0e6439aa3aeb762eafc24be",
            "3dc029fb665e49648680c5ba6b096c6f",
            "8323163ea5674103a6b1753a51b93a32",
            "63e996fef9374984aa1f0ed0f2198291",
            "9f410122763246ab86b334b605fa3244",
            "ece5015842ce4fe3af9c60932c966e63",
            "fd2b8b9d17c64ce3aea96d8de3b2bce3",
            "38c0df56ef0d4482b9faaee4ea81f4a0",
            "202adbfabea24012a84532f3bf791000",
            "dbf9021542774cef8ecd1e2910848224",
            "7066e0cf65694216ab0f3195d1b19c34",
            "7bd0022ef39e47a09e18c68bb7bdcd8b",
            "ff49ba52d00245fcacdbe80b732c9992",
            "fd3398da3bda49219b7cc79ffee67b1d",
            "66191ef894f84f44a5a88ad04dfe522c",
            "47309717772e46c7a01383e5bcc292e3",
            "09826ff535fd406ba50c5f0d1ef2168c",
            "ca39da35c8ee4fe4841a50161715665c",
            "e706965620274a8a9c5c23c704267afb",
            "aed8d6e223b744aaa0e3e4886825b535",
            "f52603e076af4deeb47c44611178e5f4",
            "868c2b5cb90f4c5dbd2501227b258896",
            "7dd30419e7d04ff78e782974a07e1b05",
            "8cfd1239e19a40e28faa9ace4f7c8458",
            "1a3599c70464483bbc6d5c8233498983",
            "36390357dc2a49ad92b1525efae20ba5",
            "c664fdd45ce546e1a8fa41740e47ef69",
            "45cda447eeee410cbed69243af074721",
            "9dceba6fef5a479281b378bca1b35489",
            "d77efc30a153430f853b192021598f73",
            "dc3b3492f76b49a7bb7c9d7c78376a7e",
            "be618fb7f904483fa4d53ead04e659a6",
            "4dd9358ba7584ef48d2cdf93064d7e9b"
          ]
        },
        "outputId": "06023789-89be-4354-bfd6-20ef444dea6f"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/689 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "af78bd1c86b347159b74850a8271959b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/0.99M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e8e27f89e1e94067ad0869b5299a4804"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/446k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "273d3c74b0e6439aa3aeb762eafc24be"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.29M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7bd0022ef39e47a09e18c68bb7bdcd8b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/5.99G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7dd30419e7d04ff78e782974a07e1b05"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "model_name = \"gpt2-xl\"  # or \"EleutherAI/gpt-j-6B\" or \"EleutherAI/gpt-neox-20b\"\n",
        "mt = ModelAndTokenizer(\n",
        "    model_name,\n",
        "    low_cpu_mem_usage=IS_COLAB,\n",
        "    torch_dtype=(torch.float16 if \"20b\" in model_name else None),\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nT_r5LVZCcwN"
      },
      "source": [
        "To obfuscate the subject during Causal Tracing, we use noise sampled from a zero-centered spherical Gaussian, whose stddev is 3 times the $\\sigma$ stddev the model's embeddings. Let's compute that value."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103,
          "referenced_widgets": [
            "25fb0d1350f7470f856f421f10496e74",
            "a0c0fb435dab4fb9a6331475c0a81a17",
            "9d744de0f7294291849046126c07069c",
            "4b4037eb1a284719ad81368a8f0714f0",
            "ba73f1b1df644716a914a1e2df358f1c",
            "47b52c878bff40f9b81e92160d770a7f",
            "a183455bf3e44b2481d9e339611c6d97",
            "36bce55c8166499d87352409934c5cef",
            "d9169bb55f034a6997e4c1a3c70638ac",
            "b8158c344a4046f3a2cdbac2a3f51309",
            "56fe93b0ba54432095aca826e59417f4"
          ]
        },
        "id": "zqgjFQrNCcwN",
        "outputId": "dd9e3443-4259-4261-e082-53ac8799258c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data/known_1000.json does not exist. Downloading from https://rome.baulab.info/data/dsets/known_1000.json\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0.00/335k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "25fb0d1350f7470f856f421f10496e74"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded dataset with 1209 elements\n",
            "Using noise level 0.13462981581687927\n"
          ]
        }
      ],
      "source": [
        "knowns = KnownsDataset(DATA_DIR)  # Dataset of known facts\n",
        "noise_level = 3 * collect_embedding_std(mt, [k[\"subject\"] for k in knowns])\n",
        "print(f\"Using noise level {noise_level}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yk3J-Ww2CcwO"
      },
      "source": [
        "## Tracing a single location\n",
        "\n",
        "The core intervention in causal tracing is captured in this function:\n",
        "\n",
        "`trace_with_patch` a single causal trace.\n",
        "\n",
        "It enables running a batch of inferences with two interventions.\n",
        "\n",
        "  1. Random noise can be added to corrupt the inputs of some of the batch.\n",
        "  2. At any point, clean non-noised state can be copied over from an\n",
        "     uncorrupted batch member to other batch members.\n",
        "  \n",
        "The convention used by this function is that the zeroth element of the\n",
        "batch is the uncorrupted run, and the subsequent elements of the batch\n",
        "are the corrupted runs.  The argument tokens_to_mix specifies an\n",
        "be corrupted by adding Gaussian noise to the embedding for the batch\n",
        "inputs other than the first element in the batch.  Alternately,\n",
        "subsequent runs could be corrupted by simply providing different\n",
        "input tokens via the passed input batch.\n",
        "\n",
        "To ensure that corrupted behavior is representative, in practice, we\n",
        "will actually run several (ten) corrupted runs in the same batch,\n",
        "each with its own sample of noise.\n",
        "\n",
        "Then when running, a specified set of hidden states will be uncorrupted\n",
        "by restoring their values to the same vector that they had in the\n",
        "zeroth uncorrupted run.  This set of hidden states is listed in\n",
        "states_to_patch, by listing [(token_index, layername), ...] pairs.\n",
        "To trace the effect of just a single state, this can be just a single\n",
        "token/layer pair.  To trace the effect of restoring a set of states,\n",
        "any number of token indices and layers can be listed.\n",
        "\n",
        "Note that this function is also in experiments.causal_trace; the code\n",
        "is shown here to show the logic."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jZMesaAzCcwO"
      },
      "outputs": [],
      "source": [
        "def trace_with_patch(\n",
        "    model,  # The model\n",
        "    inp,  # A set of inputs\n",
        "    states_to_patch,  # A list of (token index, layername) triples to restore\n",
        "    answers_t,  # Answer probabilities to collect\n",
        "    tokens_to_mix,  # Range of tokens to corrupt (begin, end)\n",
        "    noise=0.1,  # Level of noise to add\n",
        "    trace_layers=None,  # List of traced outputs to return\n",
        "):\n",
        "    prng = numpy.random.RandomState()  ### For reproducibility, use pseudorandom noise\n",
        "    patch_spec = defaultdict(list)\n",
        "    for t, l in states_to_patch:\n",
        "        patch_spec[l].append(t)\n",
        "    embed_layername = layername(model, 0, \"embed\")\n",
        "\n",
        "    def untuple(x):\n",
        "        return x[0] if isinstance(x, tuple) else x\n",
        "\n",
        "    # Define the model-patching rule.\n",
        "    def patch_rep(x, layer):\n",
        "        if layer == embed_layername:\n",
        "            # If requested, we corrupt a range of token embeddings on batch items x[1:]\n",
        "            if tokens_to_mix is not None:\n",
        "                b, e = tokens_to_mix\n",
        "                x[1:, b:e] += noise * torch.from_numpy(\n",
        "                    prng.randn(x.shape[0] - 1, e - b, x.shape[2])\n",
        "                ).to(x.device)\n",
        "            return x\n",
        "        if layer not in patch_spec:\n",
        "            return x\n",
        "        # If this layer is in the patch_spec, restore the uncorrupted hidden state\n",
        "        # for selected tokens.\n",
        "        h = untuple(x)\n",
        "        for t in patch_spec[layer]:\n",
        "            h[1:, t] = h[0, t]\n",
        "        return x\n",
        "\n",
        "    # With the patching rules defined, run the patched model in inference.\n",
        "    additional_layers = [] if trace_layers is None else trace_layers\n",
        "    with torch.no_grad(), nethook.TraceDict(\n",
        "        model,\n",
        "        [embed_layername] + list(patch_spec.keys()) + additional_layers,\n",
        "        edit_output=patch_rep,\n",
        "    ) as td:\n",
        "        outputs_exp = model(**inp)\n",
        "\n",
        "    # We report softmax probabilities for the answers_t token predictions of interest.\n",
        "    probs = torch.softmax(outputs_exp.logits[1:, -1, :], dim=1).mean(dim=0)[answers_t]\n",
        "\n",
        "    # If tracing all layers, collect all activations together to return.\n",
        "    if trace_layers is not None:\n",
        "        all_traced = torch.stack(\n",
        "            [untuple(td[layer].output).detach().cpu() for layer in trace_layers], dim=2\n",
        "        )\n",
        "        return probs, all_traced\n",
        "\n",
        "    return probs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oy2paTu5CcwO"
      },
      "source": [
        "## Scanning all locations\n",
        "\n",
        "A causal flow heatmap is created by repeating `trace_with_patch` at every individual hidden state, and measuring the impact of restoring state at each location.\n",
        "\n",
        "The `calculate_hidden_flow` function does this loop.  It handles both the case of restoring a single hidden state, and also restoring MLP or attention states.  Because MLP and attention make small residual contributions, to observe a causal effect in those cases, we need to restore several layers of contributions at once, which is done by `trace_important_window`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L_Y-0Xy7CcwP"
      },
      "outputs": [],
      "source": [
        "def calculate_hidden_flow(\n",
        "    mt, prompt, subject, samples=10, noise=0.1, window=10, kind=None\n",
        "):\n",
        "    \"\"\"\n",
        "    Runs causal tracing over every token/layer combination in the network\n",
        "    and returns a dictionary numerically summarizing the results.\n",
        "    \"\"\"\n",
        "    inp = make_inputs(mt.tokenizer, [prompt] * (samples + 1))\n",
        "    with torch.no_grad():\n",
        "        answer_t, base_score = [d[0] for d in predict_from_input(mt.model, inp)]\n",
        "    [answer] = decode_tokens(mt.tokenizer, [answer_t])\n",
        "    e_range = find_token_range(mt.tokenizer, inp[\"input_ids\"][0], subject)\n",
        "    low_score = trace_with_patch(\n",
        "        mt.model, inp, [], answer_t, e_range, noise=noise\n",
        "    ).item()\n",
        "    if not kind:\n",
        "        differences = trace_important_states(\n",
        "            mt.model, mt.num_layers, inp, e_range, answer_t, noise=noise\n",
        "        )\n",
        "    else:\n",
        "        differences = trace_important_window(\n",
        "            mt.model,\n",
        "            mt.num_layers,\n",
        "            inp,\n",
        "            e_range,\n",
        "            answer_t,\n",
        "            noise=noise,\n",
        "            window=window,\n",
        "            kind=kind,\n",
        "        )\n",
        "    differences = differences.detach().cpu()\n",
        "    return dict(\n",
        "        scores=differences,\n",
        "        low_score=low_score,\n",
        "        high_score=base_score,\n",
        "        input_ids=inp[\"input_ids\"][0],\n",
        "        input_tokens=decode_tokens(mt.tokenizer, inp[\"input_ids\"][0]),\n",
        "        subject_range=e_range,\n",
        "        answer=answer,\n",
        "        window=window,\n",
        "        kind=kind or \"\",\n",
        "    )\n",
        "\n",
        "\n",
        "def trace_important_states(model, num_layers, inp, e_range, answer_t, noise=0.1):\n",
        "    ntoks = inp[\"input_ids\"].shape[1]\n",
        "    table = []\n",
        "    for tnum in range(ntoks):\n",
        "        row = []\n",
        "        for layer in range(0, num_layers):\n",
        "            r = trace_with_patch(\n",
        "                model,\n",
        "                inp,\n",
        "                [(tnum, layername(model, layer))],\n",
        "                answer_t,\n",
        "                tokens_to_mix=e_range,\n",
        "                noise=noise,\n",
        "            )\n",
        "            row.append(r)\n",
        "        table.append(torch.stack(row))\n",
        "    return torch.stack(table)\n",
        "\n",
        "\n",
        "def trace_important_window(\n",
        "    model, num_layers, inp, e_range, answer_t, kind, window=10, noise=0.1\n",
        "):\n",
        "    ntoks = inp[\"input_ids\"].shape[1]\n",
        "    table = []\n",
        "    for tnum in range(ntoks):\n",
        "        row = []\n",
        "        for layer in range(0, num_layers):\n",
        "            layerlist = [\n",
        "                (tnum, layername(model, L, kind))\n",
        "                for L in range(\n",
        "                    max(0, layer - window // 2), min(num_layers, layer - (-window // 2))\n",
        "                )\n",
        "            ]\n",
        "            r = trace_with_patch(\n",
        "                model, inp, layerlist, answer_t, tokens_to_mix=e_range, noise=noise\n",
        "            )\n",
        "            row.append(r)\n",
        "        table.append(torch.stack(row))\n",
        "    return torch.stack(table)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mclYJ7pjCcwP"
      },
      "source": [
        "## Plotting the results\n",
        "\n",
        "The `plot_trace_heatmap` function draws the data on a heatmap.  That function is not shown here; it is in `experiments.causal_trace`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0fuLjkBSFHgq"
      },
      "outputs": [],
      "source": [
        "## bdika\n",
        "# model, tok = (\n",
        "#     AutoModelForCausalLM.from_pretrained(model_name, low_cpu_mem_usage=IS_COLAB).to(\n",
        "#         \"cuda\"\n",
        "#     ),\n",
        "#     AutoTokenizer.from_pretrained(model_name),\n",
        "# )\n",
        "tok = AutoTokenizer.from_pretrained(model_name)\n",
        "tok.pad_token = tok.eos_token"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fvPaqv8TFM3H"
      },
      "outputs": [],
      "source": [
        "# from rome file\n",
        "\n",
        "ALG_NAME = \"ROME\"\n",
        "# Colab-only: install deps for MEND* and KE*\n",
        "if IS_COLAB and not ALL_DEPS and any(x in ALG_NAME for x in [\"MEND\", \"KE\"]):\n",
        "    print(\"Installing additional dependencies required for MEND and KE\")\n",
        "    !pip install -r /content/rome/scripts/colab_reqs/additional.txt >> /content/install.log 2>&1\n",
        "    print(\"Finished installing\")\n",
        "    ALL_DEPS = True\n",
        "\n",
        "import copy\n",
        "model = mt.model\n",
        "mt2 = copy.deepcopy(mt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_f-te1OhFYSh"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c4gGNV_GCcwP"
      },
      "outputs": [],
      "source": [
        "def plot_hidden_flow(\n",
        "    mt,\n",
        "    prompt,\n",
        "    subject=None,\n",
        "    samples=10,\n",
        "    noise=0.1,\n",
        "    window=10,\n",
        "    kind=None,\n",
        "    modelname=None,\n",
        "    savepdf=None,\n",
        "):\n",
        "    if subject is None:\n",
        "        subject = guess_subject(prompt)\n",
        "    result = calculate_hidden_flow(\n",
        "        mt, prompt, subject, samples=samples, noise=noise, window=window, kind=kind\n",
        "    )\n",
        "    print(\"result:\\n\",result)\n",
        "    plot_trace_heatmap(result, savepdf, modelname=modelname)\n",
        "\n",
        "\n",
        "def plot_all_flow(mt, prompt, subject=None, noise=0.1, modelname=None):\n",
        "    for kind in [\"mlp\"]:\n",
        "        plot_hidden_flow(\n",
        "            mt, prompt, subject, modelname=modelname, noise=noise, kind=kind\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ocb0dxNUGbUV"
      },
      "outputs": [],
      "source": [
        "mt2.model = model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **New Code**"
      ],
      "metadata": {
        "id": "HxgRyXKu46BC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# NEW_REMOTE_ROOT_URL = \"https://rome.baulab.info\"\n",
        "# NEW_REMOTE_URL = f\"{NEW_REMOTE_ROOT_URL}/data/dsets/zsre_mend_eval.json\""
      ],
      "metadata": {
        "id": "fO6CvNt15Nmv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " import urllib, json"
      ],
      "metadata": {
        "id": "ulbIQi7p6wm6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "counterfacts_url = \"https://rome.baulab.info/data/dsets/counterfact.json\"\n",
        "response = urllib.request.urlopen(counterfacts_url)\n",
        "data = json.loads(response.read())\n",
        "\n",
        "print(data[0][\"requested_rewrite\"]['subject'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_RRPUTAL4-fq",
        "outputId": "3b7ad4b9-9e80-4c1e-fac3-2ecefce42a6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Danielle Darrieux\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Trials**"
      ],
      "metadata": {
        "id": "RxS-vKDEK2w8"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gdbeoI44K2Dn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7mnQ99o3DsUp"
      },
      "source": [
        "# **proccess 1**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wrY4w_1Ovgfh"
      },
      "outputs": [],
      "source": [
        "M = dict()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## predict_token\n",
        "def predict_all_from_input(model, inp):\n",
        "    out = model(**inp)[\"logits\"]\n",
        "    probs = torch.softmax(out[:, -1], dim=1)\n",
        "    return probs\n",
        "\n",
        "def predict_token(mt, prompts, return_p=False, return_idx = False):\n",
        "    inp = make_inputs(mt.tokenizer, prompts)\n",
        "    preds, p = predict_from_input(mt.model, inp)\n",
        "    result = [mt.tokenizer.decode(c) for c in preds]\n",
        "    if return_p:\n",
        "        result = (result, p)\n",
        "    elif return_idx:\n",
        "        preds = preds[0]\n",
        "        result = (result, preds)\n",
        "    return result\n",
        "\n",
        "def predict_by_idx(mt, prompt, idx):\n",
        "  inp = make_inputs(mt.tokenizer, [prompt])\n",
        "  preds = predict_all_from_input(mt.model, inp)\n",
        "  return preds[0][idx].item"
      ],
      "metadata": {
        "id": "BJA0FwqdPvFU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lwypOBBKKd5O"
      },
      "outputs": [],
      "source": [
        "def naiv_predict(word, prompt, return_idx = False):\n",
        "  t = predict_token(\n",
        "    mt2,\n",
        "    [f\"{word} {prompt}\"],\n",
        "    return_p=False,\n",
        "    return_idx = return_idx\n",
        "  )\n",
        "  \n",
        "  if return_idx:\n",
        "    return t[0][0][1:], t[1]\n",
        "  return t[0][1:]\n",
        "  \n",
        "\n",
        "def predict(word, prompt, count=0, return_idx = False):\n",
        "  if return_idx:\n",
        "    next_tok, idx = naiv_predict(word, prompt, return_idx)\n",
        "  else:\n",
        "    next_tok = naiv_predict(word, prompt, return_idx)\n",
        "\n",
        "  if next_tok not in [\"the\", \"state\", \"State\", \"of\", \"Republic\", \"province\", \"Province\"]:\n",
        "    if return_idx:\n",
        "      return next_tok, idx.item\n",
        "    else:\n",
        "      return next_tok\n",
        "\n",
        "  prompt = prompt + \" \" + next_tok\n",
        "  if count==8:\n",
        "    if return_idx:\n",
        "      return f\"[{next_tok}]\", idx.item\n",
        "    else:\n",
        "      return f\"[{next_tok}]\"\n",
        "  \n",
        "  try:\n",
        "    if return_idx:\n",
        "      next_next, idx = naiv_predict(word, prompt, return_idx)\n",
        "    else:\n",
        "      next_next = naiv_predict(word, prompt, return_idx)\n",
        "  except:\n",
        "    if return_idx:\n",
        "      return f\"[{next_tok}]\", idx.item\n",
        "    else:\n",
        "      return f\"[{next_tok}]\"\n",
        "  \n",
        "  if return_idx:\n",
        "    return f\"[{next_tok}] {next_next}\", idx.item\n",
        "  else:\n",
        "    return f\"[{next_tok}] {next_next}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KzzZB7nzKfwR"
      },
      "outputs": [],
      "source": [
        "animals = [\"grizzly\", \"poodle\", \"terrier\", \"collie\", \"border collie\", \"Schnauzer\", \"bird\", \"sparrow\", \"pale rockfinch\", \"corvus\", \"jackdaw\", \"magpie-jay\", \"european goldfinch\", \"chaffinch\", \n",
        "           \"pine grosbeak\", \"carpornis\", \"atlantic royal flycatcher\",\"pacific royal flycatcher\",\"northern royal flycatcher\", \"pigeon\", \"parrot\", \"cockatiel\", \"eagle\", \"owl\", \"penguin\", \"chameleon\"]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ag1slmcoKe83"
      },
      "outputs": [],
      "source": [
        "cities = [\"Paris\", \"Bangkok\", \"Stockholm\", \"Moscow\", \"Bucharest\", \"Kigali\", \"Zagreb\", \"Nicosia\", \"Nairobi\", \"Ottawa\", \"Phnom Penh\", \"Bishkek\", \"Doha\", \"Seoul\", \"Havana\", \"Prague\", \"Lima\", \"Islamabad\", \"Port Moresby\", \"Helsinki\", \"Suva\", \"Lisbon\", \"Warsaw\", \"San Juan\", \"Riyadh\", \"Baghdad\", \"Muscat\", \"Belgrade\", \"Madrid\", \"Dakar\", \"Bratislava\", \"Ljubljana\", \"Freetown\", \"Damascus\", \"Mogadishu\", \"Khartoum\", \"Kathmandu\", \"Managua\", \"Niamey\", \"Wellington\", \"Abuja\", \"Kingston\", \"Oslo\", \"Rabat\", \"Skopje\", \"Cairo\", \"Kyiv\", \"Montevideo\",\"Abu Dhabi\", \"Tehran\", \"Buenos Aires\", \"Berlin\", \"Amsterdam\", \"Astana\", \"Naypyidaw\", \"Lilongwe\", \"Kuala Lumpur\",\"Ulaanbaatar\", \"Bamako\", \"Nouakchott\", \"Vilnius\", \"Monrovia\", \"Riga\", \"Tripoli\", \"Beirut\", \"Jerusalem\"]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "neighborhood = {\n",
        "    \"Paris\": [\"Bangkok\", \"Stockholm\", \"Moscow\", \"Bucharest\", \"Kigali\", \"Zagreb\"],\n",
        "    \"Nicosia\": [\"Nairobi\", \"Ottawa\", \"Phnom Penh\", \"Bishkek\", \"Doha\", \"Seoul\", \"Havana\"]\n",
        "}"
      ],
      "metadata": {
        "id": "08joIeJdgBod"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def neighbors_probs(subject, prompt, ngbr_dict, target_idx):\n",
        "  neighbors = ngbr_dict[subject]\n",
        "  probs = []\n",
        "  for neighbor in neighbors:\n",
        "    probs.append(predict_by_idx(mt2, f\"{neighbor} {prompt}\", target_idx))\n",
        "  return probs\n",
        "\n",
        "def neighboring(probs1, probs2):\n",
        "  m = len(probs1)\n",
        "  f = []\n",
        "  for i in range(m):\n",
        "    numerator = abs(probs1[i]-probs2[i])\n",
        "    denominator = 0.5+abs(probs1[i]-0.5)\n",
        "    ngbring = 1 - numerator / denominator\n",
        "    f.append(ngbring)\n",
        "  return sum(f) / m"
      ],
      "metadata": {
        "id": "GQSmTxxJglrJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N43XmzUL_JAC"
      },
      "outputs": [],
      "source": [
        "def plot_all_flow(mt, prompt, subject=None, noise=0.1, modelname=None):\n",
        "    for kind in [\"mlp\"]:\n",
        "        plot_hidden_flow(\n",
        "            mt, prompt, subject, modelname=modelname, noise=noise, kind=kind\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-V5ngQq0-dw1"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "def return_map(\n",
        "    prompt,\n",
        "    subject,\n",
        "    mt=mt2,\n",
        "    samples=10,\n",
        "    noise=noise_level,\n",
        "    window=10,\n",
        "    kind=\"mlp\",\n",
        "    modelname=None,\n",
        "    savepdf=None,\n",
        "):\n",
        "    if subject is None:\n",
        "        subject = guess_subject(prompt)\n",
        "    result = calculate_hidden_flow(\n",
        "        mt, prompt, subject, samples=samples, noise=noise, window=window, kind=kind\n",
        "    )\n",
        "    return result\n",
        "\n",
        "\n",
        "def generate_city_prompt(city):\n",
        "  prompt = \"is the capital city of\"\n",
        "  word=naiv_predict(city, prompt)\n",
        "  while word in [\"the\", \"state\", \"State\", \"of\", \"Republic\", \"province\", \"Province\"]:\n",
        "    prompt = prompt+ \" \" + word\n",
        "    word=naiv_predict(city, prompt)\n",
        "  return prompt\n",
        "\n",
        "\n",
        "def entropy(tens):\n",
        "    tens_norm = tens / tens.sum()\n",
        "    logs = torch.log2(tens_norm)\n",
        "    logs = torch.where(logs==-float(\"inf\"),0,logs)\n",
        "    y = logs * tens_norm\n",
        "    return -y.sum().item() / math.log2(len(tens))\n",
        "\n",
        "\n",
        "def max_layer_and_entropy(prompt, subject, max_neighbors=[1], effect_idx=17):\n",
        "  result = return_map(prompt, subject)\n",
        "  scores = result['scores']\n",
        "  a, b = result['subject_range']\n",
        "  argmax = scores[a:b].argmax().item()\n",
        "\n",
        "  relevant_token_idx = int(argmax / len(scores[0])) + a\n",
        "  relevant_token = scores[relevant_token_idx]\n",
        "\n",
        "  _max = scores[a:b].max().item()\n",
        "  _min = scores[a:b].min().item()\n",
        "  avrg = relevant_token.sum().item() / (len(scores[0]))\n",
        "  eff = relevant_token[effect_idx].item()\n",
        "\n",
        "  layer = argmax % len(scores[0])\n",
        "  cent = []\n",
        "  for i in max_neighbors:\n",
        "    if layer+i>=0:\n",
        "      cent.append(((relevant_token[layer] - relevant_token[layer+1]) / relevant_token[layer]).item())\n",
        "    else:\n",
        "      cent.append(-1)\n",
        "  return layer, entropy(relevant_token), cent, _max, _min, avrg, eff\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oXegn1SrgXQA"
      },
      "outputs": [],
      "source": [
        "  \n",
        "def clean():\n",
        "  if \"orig_weights\" in M.keys():\n",
        "      with torch.no_grad():\n",
        "          for k, v in M[\"orig_weights\"].items():\n",
        "              nethook.get_parameter(mt2.model, k)[...] = v\n",
        "      print(\"Original model restored\")\n",
        "  else:\n",
        "      print(f\"No model weights to restore\")\n",
        "\n",
        "def change_and_chack(_subject, prompt, targets, affected, set_affected=None, count_flag=False):\n",
        "  clean()\n",
        "  \n",
        "  temp_name = \"orig_weights\"\n",
        "\n",
        "  if set_affected is not None:\n",
        "    print(\"Change affected:\")\n",
        "    for word in affected:\n",
        "      print(\"changing\", word)\n",
        "      random.seed(_seed)\n",
        "      numpy.random.seed(seed=_seed)\n",
        "      torch.manual_seed(_seed)\n",
        "\n",
        "      request = [\n",
        "        {\n",
        "            \"prompt\": f\"\\u007b\\u007d {prompt}\",\n",
        "            \"subject\": word,\n",
        "            \"target_new\": {\"str\": set_affected},\n",
        "        }\n",
        "      ]\n",
        "\n",
        "    \n",
        "      M[\"model_new\"], M[temp_name] = demo_model_editing(mt2.model, tok, request, [\"a\"], alg_name=ALG_NAME)\n",
        "      mt2.model = M[\"model_new\"]\n",
        "\n",
        "      temp_name = \"_\"\n",
        "\n",
        "  orig_object = predict(_subject, prompt)\n",
        "  print(f\"Pre check:\\n{_subject} {prompt} {orig_object}\")\n",
        "\n",
        "  change_index = 1\n",
        "\n",
        "  all_answers = []\n",
        "\n",
        "  if count_flag:\n",
        "    counts = []\n",
        "    prev_line = {}\n",
        "    for word in affected:\n",
        "      prev_line[word]=predict(word, prompt)\n",
        "\n",
        "  for t in targets:\n",
        "    target=orig_object if t==\"origin\" else t\n",
        "\n",
        "    random.seed(_seed)\n",
        "    numpy.random.seed(seed=_seed)\n",
        "    torch.manual_seed(_seed)\n",
        "\n",
        "    tok_id = mt2.tokenizer.encode(target)\n",
        "    pre_probs = neighbors_probs(_subject, prompt, neighborhood, tok_id)\n",
        "\n",
        "    if count_flag:\n",
        "      drag_count = 0\n",
        "      conf_count = 0\n",
        "\n",
        "    new_line = []\n",
        "    new_line.append(target)\n",
        "\n",
        "    print(\"CHANGE:\", change_index, \":\", target)\n",
        "    change_index+=1\n",
        "\n",
        "    request = [\n",
        "        {\n",
        "            \"prompt\": f\"\\u007b\\u007d {prompt}\",\n",
        "            \"subject\": _subject,\n",
        "            \"target_new\": {\"str\": target},\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    \n",
        "    M[\"model_new\"], M[temp_name] = demo_model_editing(mt2.model, tok, request, [\"a\"], alg_name=ALG_NAME)\n",
        "\n",
        "    mt2.model = M[\"model_new\"]\n",
        "\n",
        "    temp_name = \"_\"\n",
        "\n",
        "    # for word in affected:\n",
        "    #   new_line.append(predict(word, prompt))\n",
        "\n",
        "    #   if count_flag:\n",
        "    #     if new_line[-1]!=prev_line[word]:\n",
        "    #       if new_line[-1].split(\" \")[-1]==target:\n",
        "    #         drag_count+=1\n",
        "    #       else:\n",
        "    #         conf_count+=1\n",
        "    #       prev_line[word]=new_line[-1]\n",
        "    \n",
        "    # if count_flag:\n",
        "    #   counts.append((drag_count, conf_count))\n",
        "\n",
        "    # all_answers.append(new_line)\n",
        "\n",
        "    post_probs = neighbors_probs(_subject, prompt, neighborhood, tok_id)\n",
        "    counts.append(neighboring(pre_probs, post_probs))\n",
        "  \n",
        "  return counts\n",
        "\n",
        "\n",
        "def drag_animals(_subject, targets):\n",
        "  return change_and_chack(_subject,\"is a kind of\", targets, affected=animals)\n",
        "\n",
        "def drag_cities(_subject, targets, count_flag=False):\n",
        "  return change_and_chack(_subject,\"is the capital city of\", targets, affected=cities, count_flag=count_flag)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9LQLCjcb8IL8"
      },
      "outputs": [],
      "source": [
        "def print_drags(subjects, targets=[], print_map=True, cents = [-2,-1,1,2], idx=17):\n",
        "  clean()\n",
        "\n",
        "  all_counts = {}\n",
        "\n",
        "  if print_map:\n",
        "    for i in cents:\n",
        "      all_counts[f\"centralization {i}\"] = []\n",
        "    all_counts[\"layers\"] = []\n",
        "    all_counts[\"entropies\"] = []\n",
        "    all_counts[\"max value\"] = []\n",
        "    all_counts[\"min value\"] = []\n",
        "    all_counts[\"average\"] = []\n",
        "    all_counts[f\"effect in {idx}\"] = []\n",
        "\n",
        "    \n",
        "    for i in range(len(subjects)):\n",
        "      print(i, \": \", end=\"\")\n",
        "      subject = subjects[i]\n",
        "      layer_idx, entropy, cent, _max, _min, avrg, eff = max_layer_and_entropy(f\"{subject} {generate_city_prompt(subject)}\", subject, max_neighbors=cents)\n",
        "      all_counts[\"layers\"].append(layer_idx)\n",
        "      all_counts[\"entropies\"].append(entropy)\n",
        "      all_counts[\"max value\"].append(_max)\n",
        "      all_counts[\"min value\"].append(_min)\n",
        "      all_counts[\"average\"].append(avrg)\n",
        "      all_counts[f\"effect in {idx}\"].append(eff)\n",
        "\n",
        "      for i in range(len(cents)):\n",
        "        all_counts[f\"centralization {cents[i]}\"].append(cent[i])\n",
        "      print(\"done\")\n",
        "\n",
        "  for i in range(len(targets)):\n",
        "    all_counts[f\"drag_{i+1}\"] = []\n",
        "    all_counts[f\"change_{i+1}\"] = []\n",
        "\n",
        "  if len(targets)>0:\n",
        "    for subject in subjects:\n",
        "      counts = drag_cities(subject, targets, True)\n",
        "      for i in range(len(counts)):\n",
        "        all_counts[f\"drag_{i+1}\"].append(counts[i][0])\n",
        "        all_counts[f\"change_{i+1}\"].append(counts[i][0]+counts[i][1])\n",
        "      print(len(all_counts[\"drag_1\"]), \", until\", subject)\n",
        "      for key in all_counts.keys():\n",
        "        print(key, \"=\", all_counts[key])\n",
        "  else:\n",
        "    for key in all_counts.keys():\n",
        "      print(key, \"=\", all_counts[key])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_8EyxmfxTYQ8"
      },
      "outputs": [],
      "source": [
        "prcs = [\n",
        "    [\"Ghana\", \"China\", \"Algiers\", \"Greece\", \"Japan\", \"Ethiopia\", \"Niue\", \"Switzerland\", \"Jordan\", \"Turkey\", \"Samoa\"],\n",
        "    [\"China\", \"Greece\", \"Ethiopia\", \"Switzerland\", \"Turkey\", \"Ghana\", \"Algiers\", \"Japan\", \"Niue\", \"Samoa\", \"Jordan\"],\n",
        "    [\"Algiers\", \"Ethiopia\", \"Jordan\", \"China\", \"Switzerland\", \"Japan\", \"Samoa\", \"Ghana\", \"Greece\", \"Niue\", \"Turkey\"],\n",
        "    [\"Greece\", \"Switzerland\", \"Ghana\", \"Japan\", \"Jordan\", \"Niue\", \"China\", \"Samoa\", \"Turkey\", \"Ethiopia\", \"Algiers\"],\n",
        "    [\"Switzerland\", \"Niue\", \"Japan\", \"Ghana\", \"Ethiopia\", \"Turkey\", \"Greece\", \"Jordan\", \"Samoa\", \"Algiers\", \"China\"],\n",
        "    [\"Samoa\", \"Japan\", \"Switzerland\", \"Algiers\", \"Niue\", \"Greece\", \"Ghana\", \"Turkey\", \"China\", \"Jordan\", \"Ethiopia\"],\n",
        "    [\"Japan\", \"Algiers\", \"Turkey\", \"Jordan\", \"Greece\", \"Samoa\", \"Switzerland\", \"China\", \"Ethiopia\", \"Ghana\", \"Niue\"]\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mc18rq4W6xA-",
        "outputId": "f443988d-3992-4e99-fc52-1a31a7c6be95"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original model restored\n",
            "Original model restored\n",
            "Pre check:\n",
            "Paris is the capital city of France\n",
            "idx, p: 4881 0.8676778674125671\n",
            "CHANGE: 1 : China\n",
            "[{'prompt': '{} is the capital city of', 'subject': 'Paris', 'target_new': {'str': 'China'}}] \n",
            "\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Paris\n",
            "Computing right vector (v)\n",
            "Lookup index found: 0 | Sentence: Paris is the capital city of | Token: Paris\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 7.559 = 7.559 + 0.0 + 0.0 avg prob of [ China] 0.000852875760756433\n",
            "loss 5.702 = 5.698 + 0.003 + 0.001 avg prob of [ China] 0.005176021251827478\n",
            "loss 4.745 = 4.736 + 0.008 + 0.002 avg prob of [ China] 0.014469996094703674\n",
            "loss 3.949 = 3.934 + 0.012 + 0.002 avg prob of [ China] 0.03193957358598709\n",
            "loss 2.829 = 2.81 + 0.017 + 0.003 avg prob of [ China] 0.08889811486005783\n",
            "loss 1.739 = 1.714 + 0.021 + 0.003 avg prob of [ China] 0.24955996870994568\n",
            "loss 1.144 = 1.115 + 0.026 + 0.003 avg prob of [ China] 0.43234682083129883\n",
            "loss 0.806 = 0.773 + 0.03 + 0.004 avg prob of [ China] 0.6059199571609497\n",
            "loss 0.574 = 0.537 + 0.034 + 0.004 avg prob of [ China] 0.7652079463005066\n",
            "loss 0.462 = 0.421 + 0.037 + 0.004 avg prob of [ China] 0.8571210503578186\n",
            "loss 0.417 = 0.373 + 0.04 + 0.005 avg prob of [ China] 0.8972765803337097\n",
            "loss 0.397 = 0.35 + 0.042 + 0.005 avg prob of [ China] 0.9152124524116516\n",
            "loss 0.385 = 0.337 + 0.043 + 0.005 avg prob of [ China] 0.9243576526641846\n",
            "loss 0.378 = 0.328 + 0.044 + 0.005 avg prob of [ China] 0.9297278523445129\n",
            "loss 0.372 = 0.322 + 0.045 + 0.006 avg prob of [ China] 0.9332679510116577\n",
            "loss 0.367 = 0.316 + 0.045 + 0.006 avg prob of [ China] 0.935806930065155\n",
            "loss 0.362 = 0.311 + 0.045 + 0.006 avg prob of [ China] 0.9377374649047852\n",
            "loss 0.358 = 0.307 + 0.045 + 0.006 avg prob of [ China] 0.9392659664154053\n",
            "loss 0.354 = 0.303 + 0.044 + 0.006 avg prob of [ China] 0.9405114650726318\n",
            "loss 0.35 = 0.299 + 0.044 + 0.007 avg prob of [ China] 0.9415477514266968\n",
            "Delta norm: 156.4478759765625\n",
            "Change in target norm: 108.58200073242188 to 186.37112426757812 => 77.78912353515625\n",
            "Division Factor: 0.037106551229953766\n",
            "Right vector norm: 4216.17919921875\n",
            "CHANGE: 2 : T\n",
            "[{'prompt': '{} is the capital city of', 'subject': 'Paris', 'target_new': {'str': 'T'}}] \n",
            "\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Paris\n",
            "Computing right vector (v)\n",
            "Lookup index found: 0 | Sentence: Paris is the capital city of | Token: Paris\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 9.816 = 9.816 + 0.0 + 0.0 avg prob of [ T] 7.081366493366659e-05\n",
            "loss 9.791 = 9.79 + 0.001 + 0.0 avg prob of [ T] 7.229252514662221e-05\n",
            "loss 9.763 = 9.761 + 0.002 + 0.001 avg prob of [ T] 7.402959454338998e-05\n",
            "loss 9.735 = 9.731 + 0.004 + 0.001 avg prob of [ T] 7.620504038641229e-05\n",
            "loss 9.707 = 9.7 + 0.006 + 0.001 avg prob of [ T] 7.896935130702332e-05\n",
            "loss 9.681 = 9.671 + 0.009 + 0.001 avg prob of [ T] 8.232004620367661e-05\n",
            "loss 9.657 = 9.646 + 0.01 + 0.002 avg prob of [ T] 8.610879740444943e-05\n",
            "loss 9.633 = 9.622 + 0.01 + 0.002 avg prob of [ T] 9.040760050993413e-05\n",
            "loss 9.611 = 9.599 + 0.01 + 0.002 avg prob of [ T] 9.548719390295446e-05\n",
            "loss 9.589 = 9.577 + 0.01 + 0.002 avg prob of [ T] 0.00010164726700168103\n",
            "loss 9.568 = 9.555 + 0.011 + 0.002 avg prob of [ T] 0.00010922844376182184\n",
            "loss 9.547 = 9.532 + 0.012 + 0.003 avg prob of [ T] 0.00011865484702866524\n",
            "loss 9.526 = 9.51 + 0.013 + 0.003 avg prob of [ T] 0.00013047296670265496\n",
            "loss 9.504 = 9.487 + 0.014 + 0.003 avg prob of [ T] 0.00014539658150169998\n",
            "loss 9.482 = 9.464 + 0.015 + 0.003 avg prob of [ T] 0.0001643557334318757\n",
            "loss 9.46 = 9.441 + 0.016 + 0.003 avg prob of [ T] 0.0001885685633169487\n",
            "loss 9.438 = 9.417 + 0.017 + 0.004 avg prob of [ T] 0.00021965023188386112\n",
            "loss 9.415 = 9.394 + 0.018 + 0.004 avg prob of [ T] 0.0002597724087536335\n",
            "loss 9.392 = 9.37 + 0.018 + 0.004 avg prob of [ T] 0.00031183933606371284\n",
            "loss 9.368 = 9.345 + 0.018 + 0.004 avg prob of [ T] 0.0003796658420469612\n",
            "Delta norm: 301.8929443359375\n",
            "Change in target norm: 186.3716583251953 to 360.22393798828125 => 173.85227966308594\n",
            "Division Factor: 0.037106551229953766\n",
            "Right vector norm: 8135.83984375\n",
            "1 , until Paris\n",
            "drag_1 = [66]\n",
            "change_1 = [66]\n",
            "drag_2 = [66]\n",
            "change_2 = [66]\n",
            "Original model restored\n",
            "Pre check:\n",
            "Bangkok is the capital city of Thailand\n",
            "idx, p: 16952 0.8954664468765259\n",
            "CHANGE: 1 : China\n",
            "[{'prompt': '{} is the capital city of', 'subject': 'Bangkok', 'target_new': {'str': 'China'}}] \n",
            "\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Bangkok\n",
            "Computing right vector (v)\n",
            "Lookup index found: 1 | Sentence: Bangkok is the capital city of | Token: kok\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 9.081 = 9.081 + 0.0 + 0.0 avg prob of [ China] 0.00034506124211475253\n",
            "loss 5.489 = 5.459 + 0.003 + 0.028 avg prob of [ China] 0.008832165040075779\n",
            "loss 2.193 = 2.132 + 0.01 + 0.051 avg prob of [ China] 0.14311876893043518\n",
            "loss 1.165 = 1.076 + 0.017 + 0.072 avg prob of [ China] 0.3574540913105011\n",
            "loss 0.937 = 0.827 + 0.021 + 0.089 avg prob of [ China] 0.45099377632141113\n",
            "loss 0.75 = 0.623 + 0.022 + 0.104 avg prob of [ China] 0.5492075085639954\n",
            "loss 0.558 = 0.432 + 0.02 + 0.105 avg prob of [ China] 0.6594976186752319\n",
            "loss 0.429 = 0.305 + 0.018 + 0.105 avg prob of [ China] 0.7439948916435242\n",
            "loss 0.348 = 0.226 + 0.017 + 0.105 avg prob of [ China] 0.8018338680267334\n",
            "loss 0.298 = 0.177 + 0.016 + 0.105 avg prob of [ China] 0.8405477404594421\n",
            "loss 0.265 = 0.145 + 0.016 + 0.105 avg prob of [ China] 0.8669686317443848\n",
            "loss 0.243 = 0.123 + 0.015 + 0.105 avg prob of [ China] 0.8857153058052063\n",
            "loss 0.227 = 0.107 + 0.015 + 0.105 avg prob of [ China] 0.899646520614624\n",
            "loss 0.214 = 0.094 + 0.015 + 0.105 avg prob of [ China] 0.9104837775230408\n",
            "loss 0.205 = 0.085 + 0.015 + 0.105 avg prob of [ China] 0.9192644953727722\n",
            "loss 0.197 = 0.077 + 0.015 + 0.105 avg prob of [ China] 0.9266203045845032\n",
            "loss 0.19 = 0.07 + 0.015 + 0.105 avg prob of [ China] 0.9329434633255005\n",
            "loss 0.184 = 0.064 + 0.015 + 0.105 avg prob of [ China] 0.938481330871582\n",
            "loss 0.179 = 0.059 + 0.015 + 0.105 avg prob of [ China] 0.9433959126472473\n",
            "loss 0.174 = 0.054 + 0.015 + 0.105 avg prob of [ China] 0.9477958679199219\n",
            "Delta norm: 76.19134521484375\n",
            "Change in target norm: 19.047836303710938 to 78.5621337890625 => 59.51429748535156\n",
            "Division Factor: 3.7543535232543945\n",
            "Right vector norm: 20.294132232666016\n",
            "CHANGE: 2 : T\n",
            "[{'prompt': '{} is the capital city of', 'subject': 'Bangkok', 'target_new': {'str': 'T'}}] \n",
            "\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Bangkok\n",
            "Computing right vector (v)\n",
            "Lookup index found: 1 | Sentence: Bangkok is the capital city of | Token: kok\n",
            "Rewrite layer is 17\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 12.933 = 12.933 + 0.0 + 0.0 avg prob of [ T] 2.8178726552141597e-06\n",
            "loss 10.97 = 10.968 + 0.001 + 0.002 avg prob of [ T] 2.3242204406415112e-05\n",
            "loss 8.912 = 8.907 + 0.002 + 0.003 avg prob of [ T] 0.00022603216348215938\n",
            "loss 6.927 = 6.92 + 0.004 + 0.004 avg prob of [ T] 0.001820215373300016\n",
            "loss 5.157 = 5.146 + 0.006 + 0.006 avg prob of [ T] 0.009767838753759861\n",
            "loss 3.717 = 3.703 + 0.008 + 0.007 avg prob of [ T] 0.0344524048268795\n",
            "loss 2.674 = 2.657 + 0.01 + 0.008 avg prob of [ T] 0.0858009085059166\n",
            "loss 1.973 = 1.952 + 0.012 + 0.009 avg prob of [ T] 0.16031746566295624\n",
            "loss 1.465 = 1.442 + 0.013 + 0.01 avg prob of [ T] 0.2573537826538086\n",
            "loss 1.032 = 1.006 + 0.015 + 0.011 avg prob of [ T] 0.3876659870147705\n",
            "loss 0.65 = 0.623 + 0.016 + 0.012 avg prob of [ T] 0.5542624592781067\n",
            "loss 0.36 = 0.331 + 0.017 + 0.012 avg prob of [ T] 0.7273226380348206\n",
            "loss 0.183 = 0.153 + 0.017 + 0.013 avg prob of [ T] 0.8606382012367249\n",
            "loss 0.097 = 0.066 + 0.018 + 0.014 avg prob of [ T] 0.9370021224021912\n",
            "loss 0.061 = 0.028 + 0.018 + 0.014 avg prob of [ T] 0.9725223779678345\n",
            "loss 0.047 = 0.012 + 0.019 + 0.015 avg prob of [ T] 0.9877533912658691\n",
            "Delta norm: 185.61712646484375\n",
            "Change in target norm: 78.5621566772461 to 186.7441864013672 => 108.1820297241211\n",
            "Division Factor: 3.7543535232543945\n",
            "Right vector norm: 49.44049835205078\n",
            "2 , until Bangkok\n",
            "drag_1 = [66, 2]\n",
            "change_1 = [66, 16]\n",
            "drag_2 = [66, 6]\n",
            "change_2 = [66, 33]\n"
          ]
        }
      ],
      "source": [
        "print_drags(cities[:2], [\"China\", \"T\"], False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KZfL-UAPHQqU"
      },
      "source": [
        "## **Draft**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NlL2JkgXhjz3"
      },
      "outputs": [],
      "source": [
        "# def prdict_city()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6neInZLfKe5D"
      },
      "outputs": [],
      "source": [
        "# print(predict(\"corvus\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c8F2gS-fi1KJ"
      },
      "outputs": [],
      "source": [
        "# request = [\n",
        "#     {\n",
        "#         \"prompt\": \"{} is the capital city of\",\n",
        "#         \"subject\": \"Paris\",\n",
        "#         \"target_new\": {\"str\": \"China\"},\n",
        "#     }\n",
        "# ]\n",
        "\n",
        "# # Execute rewrite\n",
        "# model_new, orig_weights = demo_model_editing(model, tok, request, [\"a\"], alg_name=ALG_NAME)\n",
        "\n",
        "# mt2.model = model_new\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bMKJmzqzWFs3"
      },
      "outputs": [],
      "source": [
        "# for city in [\"Suva\", \"Lisbon\", \"Warsaw\", \"San Juan\", \"Riyadh\", \"Baghdad\", \"Muscat\", \"Belgrade\", \"Madrid\", \"Dakar\", \"Bratislava\", \"Ljubljana\", \"Freetown\", \"Damascus\", \"Mogadishu\"]:\n",
        "#   print(city)\n",
        "#   drag_cities(city, [\"Japan\", \"China\"], True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E3pJwGcn9414"
      },
      "outputs": [],
      "source": [
        "# for city in [\"Kigali\", \"Bishkek\",\"Nicosia\", \"Bucharest\", \"Paris\", \"Moscow\", \"Stockholm\", \"Bangkok\", \"Prague\"]:\n",
        "#   print(max_layer_and_entropy(f\"{city} {generate_city_prompt(city)}\", city))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0vXvO1mp12dZ"
      },
      "outputs": [],
      "source": [
        "# predict(\"Adamstown\", \"is the capital city of the state of\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PaUx3ertDikZ"
      },
      "outputs": [],
      "source": [
        "# print(generate_city_prompt(\"Moscow\"))\n",
        "# print(generate_city_prompt(\"Prague\"))\n",
        "# print(generate_city_prompt(\"Paris\"))\n",
        "# print(generate_city_prompt(\"Papeete\"))\n",
        "# print(generate_city_prompt(\"Adamstown\"))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-LuDUNPkFHHd"
      },
      "outputs": [],
      "source": [
        "# print(max_layer_and_entropy(\"Stockholm is the capital city of\", \"Stockholm\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "46Yq5X-zskpQ"
      },
      "outputs": [],
      "source": [
        "# for city in cities:\n",
        "#   print(city,\" | \", predict(city, \"is the capital city of\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hp6D_FRMcfF6"
      },
      "outputs": [],
      "source": [
        "# drag_animals(\"sparrow\", [\"dog\", \"lizard\", \"bird\"])\n",
        "# change_and_chack(\"TTTTT\", [\"JJ\", \"KK\", \"LL\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jhu-Hqd21zJH"
      },
      "outputs": [],
      "source": [
        "# drag_cities(\"Paris\", [\"Japan\", \"China\", \"France\"], True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tJ-y4eA1oGX-"
      },
      "outputs": [],
      "source": [
        "# nonsense = [\"kv\", \"fg\", \"de\", \"oj\", \"mdo\", \"mzv\", \"ahz\", \"zjx\", \"oxzz\", \"wdcp\", \"rfvn\", \"dwgq\", \"ofkcn\", \"krzrw\", \"zlaiq\", \"arzdp\", \"yraxjo\", \"edjxpa\", \"jdrhdq\", \"vjulqc\", \"iyapuql\", \"jglwuos\", \"bljjgzv\", \"ibryurx\", \"cxmvyvat\", \"twyzhcpr\", \"fnfvvluj\", \"vjrknbpp\", \"ftrbwywac\", \"swjwniqas\", \"ddssywine\", \"jgrpttwbn\", \"oybmpearnv\", \"vapkrtajcn\", \"coltptglwa\", \"mebtlpozkb\"]\n",
        "\n",
        "# def drag_nonsense(_subject, targets, _set_affected):\n",
        "#   change_and_chack(_subject, \"is a kind of\", targets, affected=nonsense, set_affected=_set_affected)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jgJlRm_MtdBv"
      },
      "outputs": [],
      "source": [
        "# plot_all_flow(mt2, f\"Suva is the capital city of the Republic of\", noise=noise_level, subject=\"Suva\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-czYzR5dvGaD"
      },
      "outputs": [],
      "source": [
        "# plot_all_flow(mt2, f\"Suva is the capital city of the Republic of the\", noise=noise_level, subject=\"Suva\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RgH5vzj8rY3D"
      },
      "outputs": [],
      "source": [
        "# for city in [ \"Lisbon\", \"Warsaw\", \"San Juan\", \"Riyadh\", \"Baghdad\", \"Muscat\", \"Belgrade\", \"Madrid\", \"Dakar\", \"Bratislava\", \"Ljubljana\", \"Freetown\", \"Damascus\", \"Mogadishu\"]:\n",
        "#   plot_all_flow(mt2, f\"{city} is the capital city of\", noise=noise_level, subject=city)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BZ3rXfrSv1Xz"
      },
      "outputs": [],
      "source": [
        "# plot_all_flow(mt2, f\"Beirut is the capital city of\", noise=noise_level, subject=\"Beirut\")\n",
        "# plot_all_flow(mt2, f\"Tripoli is the capital city of\", noise=noise_level, subject=\"Tripoli\")\n",
        "# plot_all_flow(mt2, f\"Oslo is the capital city of\", noise=noise_level, subject=\"Oslo\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oXtLcKqXDpzy"
      },
      "outputs": [],
      "source": [
        "# plot_all_flow(mt2, \"grizzly is a kind of\", noise=noise_level, subject=\"grizzly\")\n",
        "\n",
        "# plot_all_flow(mt2, \"poodle is a kind of\", noise=noise_level, subject=\"poodle\")\n",
        "# plot_all_flow(mt2, \"terrier is a kind of\", noise=noise_level, subject=\"terrier\")\n",
        "# plot_all_flow(mt2, \"collie is a kind of\", noise=noise_level, subject=\"collie\")\n",
        "# plot_all_flow(mt2, \"border collie is a kind of\", noise=noise_level, subject=\"border collie\")\n",
        "# plot_all_flow(mt2, \"Schnauzer is a kind of\", noise=noise_level, subject=\"Schnauzer\")\n",
        "\n",
        "# # texonomy:\n",
        "# ##### class\n",
        "# #### order\n",
        "# ### suborder\n",
        "# ## family\n",
        "\n",
        "# ##### birds\n",
        "# plot_all_flow(mt2, \"bird is a kind of\", noise=noise_level, subject=\"bird\")\n",
        "\n",
        "# #### Passerine\n",
        "\n",
        "# ### Songbird\n",
        "# ##\n",
        "# plot_all_flow(mt2, \"sparrow is a kind of\", noise=noise_level, subject=\"sparrow\")\n",
        "# plot_all_flow(mt2, \"pale rockfinch is a kind of\", noise=noise_level, subject=\"pale rockfinch\")\n",
        "# ##\n",
        "# plot_all_flow(mt2, \"corvus is a kind of\", noise=noise_level, subject=\"corvus\")\n",
        "# plot_all_flow(mt2, \"jackdaw is a kind of\", noise=noise_level, subject=\"jackdaw\")\n",
        "# plot_all_flow(mt2, \"magpie-jay is a kind of\", noise=noise_level, subject=\"magpie-jay\")\n",
        "# ##\n",
        "# plot_all_flow(mt2, \"european goldfinch is a kind of\", noise=noise_level, subject=\"european goldfinch\")\n",
        "# plot_all_flow(mt2, \"chaffinch is a kind of\", noise=noise_level, subject=\"chaffinch\")\n",
        "# plot_all_flow(mt2, \"pine grosbeak is a kind of\", noise=noise_level, subject=\"pine grosbeak\")\n",
        "\n",
        "# ### Tyranni\n",
        "# ##\n",
        "# plot_all_flow(mt2, \"carpornis is a kind of\", noise=noise_level, subject=\"carpornis\")\n",
        "# ##\n",
        "# plot_all_flow(mt2, \"atlantic royal flycatcher is a kind of\", noise=noise_level, subject=\"atlantic royal flycatcher\")\n",
        "# plot_all_flow(mt2, \"pacific royal flycatcher is a kind of\", noise=noise_level, subject=\"pacific royal flycatcher\")\n",
        "# plot_all_flow(mt2, \"northern royal flycatcher is a kind of\", noise=noise_level, subject=\"northern royal flycatcher\")\n",
        "\n",
        "\n",
        "# ####\n",
        "# ## Columbidae\n",
        "# plot_all_flow(mt2, \"pigeon is a kind of\", noise=noise_level, subject=\"pigeon\")\n",
        "\n",
        "# #### parrot\n",
        "# plot_all_flow(mt2, \"parrot is a kind of\", noise=noise_level, subject=\"parrot\")\n",
        "# ##\n",
        "# plot_all_flow(mt2, \"cockatiel is a kind of\", noise=noise_level, subject=\"cockatiel\")\n",
        "\n",
        "# ####\n",
        "# ## eagle\n",
        "# plot_all_flow(mt2, \"eagle is a kind of\", noise=noise_level, subject=\"eagle\")\n",
        "\n",
        "# plot_all_flow(mt2, \"owl is a kind of\", noise=noise_level, subject=\"owl\")\n",
        "\n",
        "# ####\n",
        "# ## Penguin\n",
        "# plot_all_flow(mt2, \"penguin is a kind of\", noise=noise_level, subject=\"penguin\")\n",
        "\n",
        "\n",
        "# plot_all_flow(mt2, \"chameleon is a kind of\", noise=noise_level, subject=\"chameleon\")\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3efIWnuWq4ty"
      },
      "outputs": [],
      "source": [
        "# drag_nonsense(\"sparrow\", [\"dog\", \"dog\", \"dog\", \"dog\"], \"bird\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kc5Gr6F5FPiQ"
      },
      "outputs": [],
      "source": [
        "# request = [\n",
        "#     {\n",
        "#         \"prompt\": \"{} is a kind of\",\n",
        "#         \"subject\": \"zjx\",\n",
        "#         \"target_new\": {\"str\": \"bird\"},\n",
        "#     }\n",
        "# ]\n",
        "\n",
        "# # Execute rewrite\n",
        "# model_new, orig_weights = demo_model_editing(model, tok, request, [\"a\"], alg_name=ALG_NAME)\n",
        "\n",
        "# mt2.model = model_new"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "neor9Ddedked"
      },
      "outputs": [],
      "source": [
        "# request = [\n",
        "#     {\n",
        "#         \"prompt\": \"{} is a kind of\",\n",
        "#         \"subject\": \"pigeon\",\n",
        "#         \"target_new\": {\"str\": \"bird\"},\n",
        "#     }\n",
        "# ]\n",
        "\n",
        "# # Execute rewrite\n",
        "# model_new, orig_weights = demo_model_editing(model, tok, request, [\"a\"], alg_name=ALG_NAME)\n",
        "\n",
        "# mt2.model = model_new\n",
        "# print(200)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k79wv-L8YcfP"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.9.7 ('rome')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "vscode": {
      "interpreter": {
        "hash": "2c3ec9f9cb0aa45979d92499665f4b05f2a3528d3b2ca0efacea2020d32b93f4"
      }
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "af78bd1c86b347159b74850a8271959b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_17e90624e9d24077b3c729f5cfb93a20",
              "IPY_MODEL_b13871f23365464ab24b4ceea4bb9c0b",
              "IPY_MODEL_85d559f8374346f0809b6d80a5e148f4"
            ],
            "layout": "IPY_MODEL_25c4106b50f54f73aca690a8b628c79b"
          }
        },
        "17e90624e9d24077b3c729f5cfb93a20": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_30072fb587f1425bb07cb1bb536a4119",
            "placeholder": "​",
            "style": "IPY_MODEL_9dd0a1a027294c0db5ffbe175179fa36",
            "value": "Downloading: 100%"
          }
        },
        "b13871f23365464ab24b4ceea4bb9c0b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cf4906c8c510479192b6a73cb9df474e",
            "max": 689,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_769736f6838f4743bd3ed92e05b7d244",
            "value": 689
          }
        },
        "85d559f8374346f0809b6d80a5e148f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bac7c63a1f084a4da2ec265de0d36442",
            "placeholder": "​",
            "style": "IPY_MODEL_da4eb14ba7bf4972bebf1f847a1bc0f3",
            "value": " 689/689 [00:00&lt;00:00, 40.8kB/s]"
          }
        },
        "25c4106b50f54f73aca690a8b628c79b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "30072fb587f1425bb07cb1bb536a4119": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9dd0a1a027294c0db5ffbe175179fa36": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cf4906c8c510479192b6a73cb9df474e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "769736f6838f4743bd3ed92e05b7d244": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bac7c63a1f084a4da2ec265de0d36442": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "da4eb14ba7bf4972bebf1f847a1bc0f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e8e27f89e1e94067ad0869b5299a4804": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_74a1898f2a8c44ab8535572d8e81e21e",
              "IPY_MODEL_8dd5198b1fec485aa8d772556633d29c",
              "IPY_MODEL_7211d18abf0c45e3988d358ac6300be7"
            ],
            "layout": "IPY_MODEL_cbfb83ba32b4409b93273431a019d30f"
          }
        },
        "74a1898f2a8c44ab8535572d8e81e21e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_22ae08b5fcde469ca7d740820aab49b6",
            "placeholder": "​",
            "style": "IPY_MODEL_fa65aa3d891c4e61a92d9eab4c96fb69",
            "value": "Downloading: 100%"
          }
        },
        "8dd5198b1fec485aa8d772556633d29c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_071d144d306b4443bec91ff3841b5513",
            "max": 1042301,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3a39f3b2150d49a7b2e0030714ea22ed",
            "value": 1042301
          }
        },
        "7211d18abf0c45e3988d358ac6300be7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_baa8e1f451764c8589b652b03be71cd3",
            "placeholder": "​",
            "style": "IPY_MODEL_2b5df00b2ba846f2925a6ba972dbc26a",
            "value": " 0.99M/0.99M [00:01&lt;00:00, 1.00MB/s]"
          }
        },
        "cbfb83ba32b4409b93273431a019d30f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "22ae08b5fcde469ca7d740820aab49b6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fa65aa3d891c4e61a92d9eab4c96fb69": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "071d144d306b4443bec91ff3841b5513": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3a39f3b2150d49a7b2e0030714ea22ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "baa8e1f451764c8589b652b03be71cd3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2b5df00b2ba846f2925a6ba972dbc26a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "273d3c74b0e6439aa3aeb762eafc24be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3dc029fb665e49648680c5ba6b096c6f",
              "IPY_MODEL_8323163ea5674103a6b1753a51b93a32",
              "IPY_MODEL_63e996fef9374984aa1f0ed0f2198291"
            ],
            "layout": "IPY_MODEL_9f410122763246ab86b334b605fa3244"
          }
        },
        "3dc029fb665e49648680c5ba6b096c6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ece5015842ce4fe3af9c60932c966e63",
            "placeholder": "​",
            "style": "IPY_MODEL_fd2b8b9d17c64ce3aea96d8de3b2bce3",
            "value": "Downloading: 100%"
          }
        },
        "8323163ea5674103a6b1753a51b93a32": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_38c0df56ef0d4482b9faaee4ea81f4a0",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_202adbfabea24012a84532f3bf791000",
            "value": 456318
          }
        },
        "63e996fef9374984aa1f0ed0f2198291": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dbf9021542774cef8ecd1e2910848224",
            "placeholder": "​",
            "style": "IPY_MODEL_7066e0cf65694216ab0f3195d1b19c34",
            "value": " 446k/446k [00:00&lt;00:00, 390kB/s]"
          }
        },
        "9f410122763246ab86b334b605fa3244": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ece5015842ce4fe3af9c60932c966e63": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fd2b8b9d17c64ce3aea96d8de3b2bce3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "38c0df56ef0d4482b9faaee4ea81f4a0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "202adbfabea24012a84532f3bf791000": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dbf9021542774cef8ecd1e2910848224": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7066e0cf65694216ab0f3195d1b19c34": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7bd0022ef39e47a09e18c68bb7bdcd8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ff49ba52d00245fcacdbe80b732c9992",
              "IPY_MODEL_fd3398da3bda49219b7cc79ffee67b1d",
              "IPY_MODEL_66191ef894f84f44a5a88ad04dfe522c"
            ],
            "layout": "IPY_MODEL_47309717772e46c7a01383e5bcc292e3"
          }
        },
        "ff49ba52d00245fcacdbe80b732c9992": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_09826ff535fd406ba50c5f0d1ef2168c",
            "placeholder": "​",
            "style": "IPY_MODEL_ca39da35c8ee4fe4841a50161715665c",
            "value": "Downloading: 100%"
          }
        },
        "fd3398da3bda49219b7cc79ffee67b1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e706965620274a8a9c5c23c704267afb",
            "max": 1355256,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_aed8d6e223b744aaa0e3e4886825b535",
            "value": 1355256
          }
        },
        "66191ef894f84f44a5a88ad04dfe522c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f52603e076af4deeb47c44611178e5f4",
            "placeholder": "​",
            "style": "IPY_MODEL_868c2b5cb90f4c5dbd2501227b258896",
            "value": " 1.29M/1.29M [00:01&lt;00:00, 1.00MB/s]"
          }
        },
        "47309717772e46c7a01383e5bcc292e3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "09826ff535fd406ba50c5f0d1ef2168c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ca39da35c8ee4fe4841a50161715665c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e706965620274a8a9c5c23c704267afb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aed8d6e223b744aaa0e3e4886825b535": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f52603e076af4deeb47c44611178e5f4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "868c2b5cb90f4c5dbd2501227b258896": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7dd30419e7d04ff78e782974a07e1b05": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8cfd1239e19a40e28faa9ace4f7c8458",
              "IPY_MODEL_1a3599c70464483bbc6d5c8233498983",
              "IPY_MODEL_36390357dc2a49ad92b1525efae20ba5"
            ],
            "layout": "IPY_MODEL_c664fdd45ce546e1a8fa41740e47ef69"
          }
        },
        "8cfd1239e19a40e28faa9ace4f7c8458": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_45cda447eeee410cbed69243af074721",
            "placeholder": "​",
            "style": "IPY_MODEL_9dceba6fef5a479281b378bca1b35489",
            "value": "Downloading: 100%"
          }
        },
        "1a3599c70464483bbc6d5c8233498983": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d77efc30a153430f853b192021598f73",
            "max": 6431878936,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_dc3b3492f76b49a7bb7c9d7c78376a7e",
            "value": 6431878936
          }
        },
        "36390357dc2a49ad92b1525efae20ba5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_be618fb7f904483fa4d53ead04e659a6",
            "placeholder": "​",
            "style": "IPY_MODEL_4dd9358ba7584ef48d2cdf93064d7e9b",
            "value": " 5.99G/5.99G [01:46&lt;00:00, 72.8MB/s]"
          }
        },
        "c664fdd45ce546e1a8fa41740e47ef69": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "45cda447eeee410cbed69243af074721": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9dceba6fef5a479281b378bca1b35489": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d77efc30a153430f853b192021598f73": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dc3b3492f76b49a7bb7c9d7c78376a7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "be618fb7f904483fa4d53ead04e659a6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4dd9358ba7584ef48d2cdf93064d7e9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "25fb0d1350f7470f856f421f10496e74": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a0c0fb435dab4fb9a6331475c0a81a17",
              "IPY_MODEL_9d744de0f7294291849046126c07069c",
              "IPY_MODEL_4b4037eb1a284719ad81368a8f0714f0"
            ],
            "layout": "IPY_MODEL_ba73f1b1df644716a914a1e2df358f1c"
          }
        },
        "a0c0fb435dab4fb9a6331475c0a81a17": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_47b52c878bff40f9b81e92160d770a7f",
            "placeholder": "​",
            "style": "IPY_MODEL_a183455bf3e44b2481d9e339611c6d97",
            "value": "100%"
          }
        },
        "9d744de0f7294291849046126c07069c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_36bce55c8166499d87352409934c5cef",
            "max": 343229,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d9169bb55f034a6997e4c1a3c70638ac",
            "value": 343229
          }
        },
        "4b4037eb1a284719ad81368a8f0714f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b8158c344a4046f3a2cdbac2a3f51309",
            "placeholder": "​",
            "style": "IPY_MODEL_56fe93b0ba54432095aca826e59417f4",
            "value": " 335k/335k [00:00&lt;00:00, 312kB/s]"
          }
        },
        "ba73f1b1df644716a914a1e2df358f1c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "47b52c878bff40f9b81e92160d770a7f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a183455bf3e44b2481d9e339611c6d97": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "36bce55c8166499d87352409934c5cef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d9169bb55f034a6997e4c1a3c70638ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b8158c344a4046f3a2cdbac2a3f51309": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "56fe93b0ba54432095aca826e59417f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}